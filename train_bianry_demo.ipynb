{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import random\n",
    "import json\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "sys.path.append('/home/hong/hc701/HC701-PROJECT')\n",
    "from VAL import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizontal_flip {'p': 0}\n"
     ]
    }
   ],
   "source": [
    "from hc701fed.dataset.dataset_list_transform import (\n",
    "    MESSIDOR_binary_pairs_train,\n",
    "    MESSIDOR_binary_pairs_test,\n",
    "    MESSIDOR_binary_Etienne_train,\n",
    "    MESSIDOR_binary_Etienne_test,\n",
    "    MESSIDOR_binary_Brest_train,\n",
    "    MESSIDOR_binary_Brest_test\n",
    ")\n",
    "\n",
    "centerlized_train = ConcatDataset([MESSIDOR_binary_pairs_train, MESSIDOR_binary_Etienne_train, MESSIDOR_binary_Brest_train])\n",
    "centerlized_test = ConcatDataset([MESSIDOR_binary_pairs_test, MESSIDOR_binary_Etienne_test, MESSIDOR_binary_Brest_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd5d28597d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.backends.cudnn as cudnn\n",
    "seed =44\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = True\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from timm.models import create_model\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# use resnet18 as the base model\n",
    "model = create_model('vgg16', pretrained=False, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the fix model\n",
    "model_name = 'vgg16'\n",
    "model_path = '/home/hong/hc701/random_init/{}.pth'.format(model_name)\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def test(model_, test_loader, device):\n",
    "    model_test = copy.deepcopy(model_)\n",
    "    model_test.to(device)\n",
    "    model_test.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model_test(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# define the loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Data loader\n",
    "train_loader_pairs = DataLoader(MESSIDOR_binary_pairs_train, batch_size=batch_size, shuffle=True)\n",
    "train_loader_Etienne = DataLoader(MESSIDOR_binary_Etienne_train, batch_size=batch_size, shuffle=True)\n",
    "train_loader_Brest = DataLoader(MESSIDOR_binary_Brest_train, batch_size=batch_size, shuffle=True)\n",
    "train_loader = DataLoader(centerlized_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader_pairs = DataLoader(MESSIDOR_binary_pairs_test, batch_size=1, shuffle=False)\n",
    "test_loader_Etienne = DataLoader(MESSIDOR_binary_Etienne_test, batch_size=1, shuffle=False)\n",
    "test_loader_Brest = DataLoader(MESSIDOR_binary_Brest_test, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(centerlized_test, batch_size=1, shuffle=False)\n",
    "\n",
    "train_list = [train_loader_pairs, train_loader_Etienne, train_loader_Brest]\n",
    "test_list = [test_loader_pairs, test_loader_Etienne, test_loader_Brest]\n",
    "\n",
    "model_list = [copy.deepcopy(model) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scale = 1\n",
    "\n",
    "mean = torch.tensor(0, dtype=torch.float)\n",
    "std = torch.tensor(0.0948*noise_scale, dtype=torch.float)\n",
    "lr=0.01\n",
    "clip_value=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_train(trains_loader_item, num_updates,model_init,client_id,rounds,lr=lr):\n",
    "    __model=copy.deepcopy(model_init)\n",
    "    __model.to(device)\n",
    "    # Local train\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    optimizer=torch.optim.SGD(__model.parameters(),lr=lr)\n",
    "    __model.train()\n",
    "    update_count = 0\n",
    "    for i, (X, y) in enumerate(trains_loader_item):\n",
    "        update_count += 1\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction and loss\n",
    "        pred = __model(X)\n",
    "        _loss = loss(pred,y)\n",
    "        # Backpropagation\n",
    "        _loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if update_count >= num_updates:\n",
    "            break\n",
    "    return __model,model_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_update(model_previous: torch.nn.modules,model_t: torch.nn.modules):\n",
    "    updates=torch.tensor([]).to(device).reshape(1,-1)\n",
    "    for p_t,p_pre in zip(model_t.parameters(),model_previous.parameters()):\n",
    "        updates=torch.cat((updates,torch.flatten(p_t-p_pre).reshape(1,-1)),1)\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dp(update_tensor,total_round,clip_threshold=clip_value,learn_rate=lr,dp_std=std,dp_mean=mean):\n",
    "    # clip gradient\n",
    "    updates_norm=torch.linalg.vector_norm(update_tensor)\n",
    "    clip_threshold=learn_rate*clip_threshold\n",
    "    # update_tensor_clip=update_tensor/torch.max(torch.tensor([1]).to(device),updates_norm/clip_threshold)\n",
    "    update_tensor_clip=update_tensor\n",
    "    # add noise\n",
    "    # update_tensor_clip+=torch.normal(mean=dp_mean, std=learn_rate*dp_std*clip_threshold*total_round,size=update_tensor_clip.shape).to('cuda')\n",
    "    return update_tensor_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model(dp_update_tensor: torch.Tensor(), model_pre: torch.nn.modules,model_t: torch.nn.modules):\n",
    "    dp_update_tensor=torch.flatten(dp_update_tensor)  # Flatten update make it to 1D\n",
    "    # Save model dict\n",
    "    pre_dict_model=model_pre.state_dict()\n",
    "    t_dict_model=model_t.state_dict()\n",
    "    #update by the DP guarantee delta\n",
    "    for name, param in model_t.named_parameters():\n",
    "        length_paramter=int((torch.flatten(param).shape)[0]) # Get the length of of paramter\n",
    "        delta=dp_update_tensor[:length_paramter].reshape(param.shape)  # Delta is the parameter grad times the lr\n",
    "        t_dict_model[name]=pre_dict_model[name]+delta  # update model\n",
    "        dp_update_tensor=dp_update_tensor[length_paramter:] # remove used\n",
    "    model_t.load_state_dict(t_dict_model) # update model\n",
    "    return model_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_dp_train(trains_loader_item, num_updates,model_init,client_id,rounds):\n",
    "    model_t,model_pre=local_train(trains_loader_item=trains_loader_item, num_updates=num_updates,model_init=model_init,client_id=client_id,rounds=rounds)\n",
    "    model_update=get_update(model_pre,model_t)\n",
    "    # print(model_update)\n",
    "    dp_update_tensor=apply_dp(update_tensor=model_update,total_round=rounds)\n",
    "    # print(dp_update_tensor)\n",
    "    model_t_dp=update_model(dp_update_tensor=dp_update_tensor,model_pre=model_pre,model_t=model_t)\n",
    "    return model_t_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_step(training_dataloaders_list,num_updates,model_init,rounds):\n",
    "    MODEL_LIST=[model_init for i in range(3)]\n",
    "    for i,j in zip(training_dataloaders_list,range(3)):\n",
    "        MODEL_LIST[j]=local_dp_train(trains_loader_item=i,num_updates=num_updates,model_init=model_init,client_id=j,rounds=rounds)\n",
    "    return MODEL_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregation_model(models_list):\n",
    "    _models_list=copy.deepcopy(models_list)\n",
    "    fed_state_dict=collections.OrderedDict()\n",
    "    weight_keys=models_list[0].state_dict().keys()\n",
    "    for key in weight_keys:\n",
    "        key_avg=0\n",
    "        for _model in _models_list:\n",
    "            key_avg=key_avg+_model.state_dict()[key]*1/3\n",
    "        fed_state_dict[key]=key_avg\n",
    "    for _model in _models_list:\n",
    "        _model.load_state_dict(fed_state_dict)\n",
    "    return _models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1 Accuracy: 0.522\n",
      "Round: 1 f1_score: 0.45527065527065536\n",
      "Round: 1 average_Acc_f1: 0.4886353276353277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:06<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 2 Accuracy: 0.652\n",
      "Round: 2 f1_score: 0.6507426736250501\n",
      "Round: 2 average_Acc_f1: 0.6513713368125251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:15<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 5 Accuracy: 0.562\n",
      "Round: 5 f1_score: 0.48342964972284463\n",
      "Round: 5 average_Acc_f1: 0.5227148248614224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:31<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 10 Accuracy: 0.744\n",
      "Round: 10 f1_score: 0.7436677934603245\n",
      "Round: 10 average_Acc_f1: 0.7438338967301623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:02<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 20 Accuracy: 0.814\n",
      "Round: 20 f1_score: 0.8118863550857434\n",
      "Round: 20 average_Acc_f1: 0.8129431775428717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:23<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 50 Accuracy: 0.892\n",
      "Round: 50 f1_score: 0.8919844457601895\n",
      "Round: 50 average_Acc_f1: 0.8919922228800947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:25<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 100 Accuracy: 0.808\n",
      "Round: 100 f1_score: 0.8045952679487387\n",
      "Round: 100 average_Acc_f1: 0.8062976339743694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/200 [00:18<01:12,  2.20it/s]"
     ]
    }
   ],
   "source": [
    "for com_round in [1,2,5,10,20,50,100,200,500,1000]:\n",
    "    global_models=[copy.deepcopy(model) for i in range(3)]\n",
    "    for rounds in tqdm(range(com_round)):\n",
    "        models=local_step(train_list,1000//com_round,global_models[0],com_round)\n",
    "        global_models=aggregation_model(models)\n",
    "    y_true,y_pred=test(global_models[0],test_loader,device)\n",
    "    print('Round: {} Accuracy: {}'.format(com_round,accuracy_score(y_true,y_pred)))\n",
    "    print('Round:',com_round,'f1_score:',f1_score(y_true,y_pred,average='macro'))\n",
    "    print('Round:',com_round,'average_Acc_f1:',(accuracy_score(y_true,y_pred)+f1_score(y_true,y_pred,average='macro'))/2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
