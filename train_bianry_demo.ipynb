{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import random\n",
    "import json\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "sys.path.append('/home/hong/hc701/HC701-PROJECT')\n",
    "from VAL import test\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import timm\n",
    "from timm.models import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizontal_flip {'p': 0}\n"
     ]
    }
   ],
   "source": [
    "from hc701fed.dataset.dataset_list_transform import (\n",
    "    MESSIDOR_binary_pairs_train,\n",
    "    MESSIDOR_binary_pairs_test,\n",
    "    MESSIDOR_binary_Etienne_train,\n",
    "    MESSIDOR_binary_Etienne_test,\n",
    "    MESSIDOR_binary_Brest_train,\n",
    "    MESSIDOR_binary_Brest_test\n",
    ")\n",
    "\n",
    "centerlized_train = ConcatDataset([MESSIDOR_binary_pairs_train, MESSIDOR_binary_Etienne_train, MESSIDOR_binary_Brest_train])\n",
    "centerlized_test = ConcatDataset([MESSIDOR_binary_pairs_test, MESSIDOR_binary_Etienne_test, MESSIDOR_binary_Brest_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def test(model_, test_loader, device):\n",
    "    model_test = copy.deepcopy(model_)\n",
    "    model_test.to(device)\n",
    "    model_test.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model_test(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 8\n",
    "# Data loader\n",
    "train_loader_pairs = DataLoader(MESSIDOR_binary_pairs_train, batch_size=batch_size, shuffle=True)\n",
    "train_loader_Etienne = DataLoader(MESSIDOR_binary_Etienne_train, batch_size=batch_size, shuffle=True)\n",
    "train_loader_Brest = DataLoader(MESSIDOR_binary_Brest_train, batch_size=batch_size, shuffle=True)\n",
    "train_loader = DataLoader(centerlized_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader_pairs = DataLoader(MESSIDOR_binary_pairs_test, batch_size=1, shuffle=False)\n",
    "test_loader_Etienne = DataLoader(MESSIDOR_binary_Etienne_test, batch_size=1, shuffle=False)\n",
    "test_loader_Brest = DataLoader(MESSIDOR_binary_Brest_test, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(centerlized_test, batch_size=1, shuffle=False)\n",
    "\n",
    "train_list = [train_loader_pairs, train_loader_Etienne, train_loader_Brest]\n",
    "test_list = [test_loader_pairs, test_loader_Etienne, test_loader_Brest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3ce47f87d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for noise_scale in [0.1,0.2,0.3,0.5,1,1.5,2]:\n",
    "    for seed in [42,43,44]:\n",
    "        print('seed: {}, noise_scale: {}'.format(seed, noise_scale))\n",
    "        cudnn.deterministic = True\n",
    "        cudnn.benchmark = True\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "\n",
    "        # use resnet18 as the base model\n",
    "        model = create_model('vgg16', pretrained=False, num_classes=2)\n",
    "\n",
    "        # load the fix model\n",
    "        model_name = 'vgg16'\n",
    "        model_path = '/home/hong/hc701/random_init/{}.pth'.format(model_name)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        mean = torch.tensor(0, dtype=torch.float)\n",
    "        std = torch.tensor(0.0948*noise_scale, dtype=torch.float)\n",
    "        lr=0.01\n",
    "        clip_value=30\n",
    "\n",
    "        def local_train(trains_loader_item, num_updates,model_init,client_id,rounds,lr=lr):\n",
    "            __model=copy.deepcopy(model_init)\n",
    "            __model.to(device)\n",
    "            # Local train\n",
    "            loss = torch.nn.CrossEntropyLoss()\n",
    "            optimizer=torch.optim.SGD(__model.parameters(),lr=lr)\n",
    "            __model.train()\n",
    "            update_count = 0\n",
    "            for i, (X, y) in enumerate(trains_loader_item):\n",
    "                update_count += 1\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                # Compute prediction and loss\n",
    "                pred = __model(X)\n",
    "                _loss = loss(pred,y)\n",
    "                # Backpropagation\n",
    "                _loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                if update_count >= num_updates:\n",
    "                    break\n",
    "            return __model,model_init\n",
    "        \n",
    "        def get_update(model_previous: torch.nn.modules,model_t: torch.nn.modules):\n",
    "            updates=torch.tensor([]).to(device).reshape(1,-1)\n",
    "            for p_t,p_pre in zip(model_t.parameters(),model_previous.parameters()):\n",
    "                updates=torch.cat((updates,torch.flatten(p_t-p_pre).reshape(1,-1)),1)\n",
    "            return updates\n",
    "        \n",
    "        def apply_dp(update_tensor,total_round,clip_threshold=clip_value,learn_rate=lr,dp_std=std,dp_mean=mean):\n",
    "            # clip gradient\n",
    "            updates_norm=torch.linalg.vector_norm(update_tensor)\n",
    "            clip_threshold=learn_rate*clip_threshold\n",
    "            update_tensor_clip=update_tensor/torch.max(torch.tensor([1]).to(device),updates_norm/clip_threshold)\n",
    "            # add noise\n",
    "            update_tensor_clip+=torch.normal(mean=dp_mean, std=learn_rate*dp_std*clip_threshold*total_round,size=update_tensor_clip.shape).to('cuda')\n",
    "            return update_tensor_clip\n",
    "        \n",
    "        def update_model(dp_update_tensor: torch.Tensor(), model_pre: torch.nn.modules,model_t: torch.nn.modules):\n",
    "            dp_update_tensor=torch.flatten(dp_update_tensor)  # Flatten update make it to 1D\n",
    "            # Save model dict\n",
    "            pre_dict_model=model_pre.state_dict()\n",
    "            t_dict_model=model_t.state_dict()\n",
    "            #update by the DP guarantee delta\n",
    "            for name, param in model_t.named_parameters():\n",
    "                length_paramter=int((torch.flatten(param).shape)[0]) # Get the length of of paramter\n",
    "                delta=dp_update_tensor[:length_paramter].reshape(param.shape)  # Delta is the parameter grad times the lr\n",
    "                t_dict_model[name]=pre_dict_model[name]+delta  # update model\n",
    "                dp_update_tensor=dp_update_tensor[length_paramter:] # remove used\n",
    "            model_t.load_state_dict(t_dict_model) # update model\n",
    "            return model_t\n",
    "        \n",
    "        def local_dp_train(trains_loader_item, num_updates,model_init,client_id,rounds):\n",
    "            model_t,model_pre=local_train(trains_loader_item=trains_loader_item, num_updates=num_updates,model_init=model_init,client_id=client_id,rounds=rounds)\n",
    "            model_update=get_update(model_pre,model_t)\n",
    "            # print(model_update)\n",
    "            dp_update_tensor=apply_dp(update_tensor=model_update,total_round=rounds)\n",
    "            # print(dp_update_tensor)\n",
    "            model_t_dp=update_model(dp_update_tensor=dp_update_tensor,model_pre=model_pre,model_t=model_t)\n",
    "            return model_t_dp\n",
    "        \n",
    "        def local_step(training_dataloaders_list,num_updates,model_init,rounds):\n",
    "            MODEL_LIST=[model_init for i in range(3)]\n",
    "            for i,j in zip(training_dataloaders_list,range(3)):\n",
    "                MODEL_LIST[j]=local_dp_train(trains_loader_item=i,num_updates=num_updates,model_init=model_init,client_id=j,rounds=rounds)\n",
    "            return MODEL_LIST\n",
    "        \n",
    "        def aggregation_model(models_list):\n",
    "            _models_list=copy.deepcopy(models_list)\n",
    "            fed_state_dict=collections.OrderedDict()\n",
    "            weight_keys=models_list[0].state_dict().keys()\n",
    "            for key in weight_keys:\n",
    "                key_avg=0\n",
    "                for _model in _models_list:\n",
    "                    key_avg=key_avg+_model.state_dict()[key]*1/3\n",
    "                fed_state_dict[key]=key_avg\n",
    "            for _model in _models_list:\n",
    "                _model.load_state_dict(fed_state_dict)\n",
    "            return _models_list\n",
    "        \n",
    "        for com_round in [1,2,5,10,20,50,100,200,500,1000]:\n",
    "            global_models=[copy.deepcopy(model) for i in range(3)]\n",
    "            for rounds in tqdm(range(com_round)):\n",
    "                models=local_step(train_list,1000//com_round,global_models[0],com_round)\n",
    "                global_models=aggregation_model(models)\n",
    "            y_true,y_pred=test(global_models[0],test_loader,device)\n",
    "            print('Round: {} Accuracy: {}'.format(com_round,accuracy_score(y_true,y_pred)))\n",
    "            print('Round:',com_round,'f1_score:',f1_score(y_true,y_pred,average='macro'))\n",
    "            print('Round:',com_round,'average_Acc_f1:',(accuracy_score(y_true,y_pred)+f1_score(y_true,y_pred,average='macro'))/2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
