{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import random\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "sys.path.append('/home/hong/hc701/HC701-PROJECT')\n",
    "from VAL import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizontal_flip {'p': 0.5}\n",
      "random_rotation {'degrees': [-10, 10]}\n"
     ]
    }
   ],
   "source": [
    "from hc701fed.dataset.dataset_list_transform import (\n",
    "    MESSIDOR_binary_pairs_train,\n",
    "    MESSIDOR_binary_pairs_test,\n",
    "    MESSIDOR_binary_Etienne_train,\n",
    "    MESSIDOR_binary_Etienne_test,\n",
    "    MESSIDOR_binary_Brest_train,\n",
    "    MESSIDOR_binary_Brest_test\n",
    ")\n",
    "\n",
    "centerlized_train = ConcatDataset([MESSIDOR_binary_pairs_train, MESSIDOR_binary_Etienne_train, MESSIDOR_binary_Brest_train])\n",
    "centerlized_test = ConcatDataset([MESSIDOR_binary_pairs_test, MESSIDOR_binary_Etienne_test, MESSIDOR_binary_Brest_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/hong/.conda/envs/py38/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:184: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  return torch.tensor(batch)\n",
      " 10%|█         | 1/10 [00:04<00:40,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27083333333333337 this is the average of acc and f1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:06<00:23,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1875 this is the average of acc and f1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:08<00:18,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09375 this is the average of acc and f1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:10<00:14,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 this is the average of acc and f1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:13<00:11,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 this is the average of acc and f1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:15<00:09,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21875 this is the average of acc and f1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:17<00:06,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125 this is the average of acc and f1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:19<00:04,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 this is the average of acc and f1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:21<00:02,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3125 this is the average of acc and f1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3125 this is the average of acc and f1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from timm.models import create_model\n",
    "\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "# use resnet18 as the base model\n",
    "model = create_model('resnet50', pretrained=True, num_classes=2)\n",
    "\n",
    "# use the GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# define the loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Data loader\n",
    "train_loader_pairs = DataLoader(MESSIDOR_binary_pairs_train, batch_size=batch_size, shuffle=True)\n",
    "train_loader_Etienne = DataLoader(MESSIDOR_binary_Etienne_train, batch_size=batch_size, shuffle=True)\n",
    "train_loader_Brest = DataLoader(MESSIDOR_binary_Brest_train, batch_size=batch_size, shuffle=True)\n",
    "train_loader = DataLoader(centerlized_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader_pairs = DataLoader(MESSIDOR_binary_pairs_test, batch_size=batch_size, shuffle=True)\n",
    "test_loader_Etienne = DataLoader(MESSIDOR_binary_Etienne_test, batch_size=batch_size, shuffle=True)\n",
    "test_loader_Brest = DataLoader(MESSIDOR_binary_Brest_test, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(centerlized_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define the scheduler make the learning rate linear decay to zero\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 1 - epoch / num_epochs)\n",
    "\n",
    "# train the model\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
    "            \n",
    "    # Test the model\n",
    "    # We need f1_score and accuracy_score\n",
    "    # In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "    with torch.no_grad():\n",
    "        pred_labels = []\n",
    "        true_labels = []\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            pred_labels.append(predicted.cpu().numpy().tolist()[0])\n",
    "            true_labels.append(labels.cpu().numpy().tolist()[0])\n",
    "        f1 = f1_score(true_labels, pred_labels)\n",
    "        acc = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "        # print('Test Accuracy of the model on the test images: {} %'.format(100 * acc))\n",
    "        # print('Test F1 of the model on the test images: {}'.format(f1))\n",
    "\n",
    "        print((acc+f1)/2, 'this is the average of acc and f1')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
