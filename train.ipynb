{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "\n",
    "from hc701fed.dataset.EyePACS_and_APTOS import Eye_APTOS\n",
    "from hc701fed.dataset.messidor import MESSIDOR\n",
    "\n",
    "# Which GPU to use\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eye_APTOS_data_dir_options = {\n",
    "    'EyePACS': '/home/xiangjianhou/hc701-fed/preprocessed/eyepacs',\n",
    "    'APTOS': '/home/xiangjianhou/hc701-fed/preprocessed/aptos',\n",
    "}\n",
    "MESSIDOR_data_dir_options = {\n",
    "    'messidor2': '/home/xiangjianhou/hc701-fed/preprocessed/messidor2',\n",
    "    'messidor_pairs' : '/home/xiangjianhou/hc701-fed/preprocessed/messidor/messidor_pairs',\n",
    "    'messidor_Etienne' : '/home/xiangjianhou/hc701-fed/preprocessed/messidor/messidor_Etienne',\n",
    "    'messidor_Brest-without_dilation' : '/home/xiangjianhou/hc701-fed/preprocessed/messidor/messidor_Brest-without_dilation'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSIDOR_pairs_train = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_pairs'], train=True, transform=None)\n",
    "MESSIDOR_Etienne_train = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_Etienne'], train=True, transform=None)\n",
    "MESSIDOR_Brest_train = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_Brest-without_dilation'], train=True, transform=None)\n",
    "MESSIDOR_Centerlized_train = ConcatDataset([MESSIDOR_pairs_train, MESSIDOR_Etienne_train,MESSIDOR_Brest_train])\n",
    "\n",
    "MESSIDOR_pairs_test = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_pairs'], train=False, transform=None)\n",
    "MESSIDOR_Etienne_test = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_Etienne'], train=False, transform=None)\n",
    "MESSIDOR_Brest_test = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_Brest-without_dilation'], train=False, transform=None)\n",
    "MESSIDOR_Centerlized_test = ConcatDataset([MESSIDOR_pairs_test, MESSIDOR_Etienne_test,MESSIDOR_Brest_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSIDOR_Centerlized_train_loader = DataLoader(MESSIDOR_Centerlized_train, batch_size=32, shuffle=True, num_workers=0)\n",
    "MESSIDOR_Centerlized_test_loader = DataLoader(MESSIDOR_Centerlized_test, batch_size=32, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hc701fed.model.baseline import Baseline\n",
    "model_demo = Baseline(backbone='densenet121',num_classes=4,pretrained=True)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_demo.parameters(), lr=0.001)\n",
    "model_save_path = '/home/xiangjianhou/hc701-fed/checkpoint/MESSIDOR_3_hosptial_4class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss: 1.44024658203125\n",
      "epoch: 0, batch: 1, loss: 1.361745834350586\n",
      "epoch: 0, batch: 2, loss: 1.026029348373413\n",
      "epoch: 0, batch: 3, loss: 1.1484640836715698\n",
      "epoch: 0, batch: 4, loss: 1.4625872373580933\n",
      "epoch: 0, batch: 5, loss: 1.7400227785110474\n",
      "epoch: 0, batch: 6, loss: 1.3524588346481323\n",
      "epoch: 0, batch: 7, loss: 1.223073124885559\n",
      "epoch: 0, batch: 8, loss: 1.291237235069275\n",
      "epoch: 0, batch: 9, loss: 1.183354377746582\n",
      "epoch: 0, batch: 10, loss: 1.2781695127487183\n",
      "epoch: 0, batch: 11, loss: 1.1489821672439575\n",
      "epoch: 0, batch: 12, loss: 1.2569248676300049\n",
      "epoch: 0, batch: 13, loss: 1.255894422531128\n",
      "epoch: 0, batch: 14, loss: 1.2994041442871094\n",
      "epoch: 0, batch: 15, loss: 1.2678431272506714\n",
      "epoch: 0, batch: 16, loss: 1.0039314031600952\n",
      "epoch: 0, batch: 17, loss: 1.0960462093353271\n",
      "epoch: 0, batch: 18, loss: 1.2995574474334717\n",
      "epoch: 0, batch: 19, loss: 1.064724087715149\n",
      "epoch: 0, batch: 20, loss: 1.1173396110534668\n",
      "epoch: 0, batch: 21, loss: 1.2939146757125854\n",
      "epoch: 0, batch: 22, loss: 1.2188847064971924\n",
      "epoch: 0, batch: 23, loss: 1.3033785820007324\n",
      "epoch: 0, batch: 24, loss: 1.0150164365768433\n",
      "epoch: 0, batch: 25, loss: 1.1687562465667725\n",
      "epoch: 0, batch: 26, loss: 1.410035252571106\n",
      "epoch: 0, batch: 27, loss: 1.1931782960891724\n",
      "epoch: 0, batch: 28, loss: 1.152086615562439\n",
      "epoch: 1, batch: 0, loss: 0.8685596585273743\n",
      "epoch: 1, batch: 1, loss: 0.9787852764129639\n",
      "epoch: 1, batch: 2, loss: 1.2788201570510864\n",
      "epoch: 1, batch: 3, loss: 0.9677216410636902\n",
      "epoch: 1, batch: 4, loss: 0.9129472970962524\n",
      "epoch: 1, batch: 5, loss: 0.9128916263580322\n",
      "epoch: 1, batch: 6, loss: 1.4321287870407104\n",
      "epoch: 1, batch: 7, loss: 1.0865397453308105\n",
      "epoch: 1, batch: 8, loss: 0.9301804304122925\n",
      "epoch: 1, batch: 9, loss: 0.9677129983901978\n",
      "epoch: 1, batch: 10, loss: 1.0251179933547974\n",
      "epoch: 1, batch: 11, loss: 0.9126459956169128\n",
      "epoch: 1, batch: 12, loss: 1.3098552227020264\n",
      "epoch: 1, batch: 13, loss: 0.970106840133667\n",
      "epoch: 1, batch: 14, loss: 0.9230461716651917\n",
      "epoch: 1, batch: 15, loss: 1.4099369049072266\n",
      "epoch: 1, batch: 16, loss: 1.6827619075775146\n",
      "epoch: 1, batch: 17, loss: 1.1488523483276367\n",
      "epoch: 1, batch: 18, loss: 1.0917445421218872\n",
      "epoch: 1, batch: 19, loss: 0.8693682551383972\n",
      "epoch: 1, batch: 20, loss: 1.1923519372940063\n",
      "epoch: 1, batch: 21, loss: 0.8405296802520752\n",
      "epoch: 1, batch: 22, loss: 1.0927886962890625\n",
      "epoch: 1, batch: 23, loss: 1.0630582571029663\n",
      "epoch: 1, batch: 24, loss: 1.3192087411880493\n",
      "epoch: 1, batch: 25, loss: 0.977616548538208\n",
      "epoch: 1, batch: 26, loss: 0.868071436882019\n",
      "epoch: 1, batch: 27, loss: 1.032239556312561\n",
      "epoch: 1, batch: 28, loss: 1.2396109104156494\n",
      "epoch: 2, batch: 0, loss: 0.7455302476882935\n",
      "epoch: 2, batch: 1, loss: 0.7730427980422974\n",
      "epoch: 2, batch: 2, loss: 0.7637790441513062\n",
      "epoch: 2, batch: 3, loss: 0.9806908965110779\n",
      "epoch: 2, batch: 4, loss: 1.1395349502563477\n",
      "epoch: 2, batch: 5, loss: 0.9105033278465271\n",
      "epoch: 2, batch: 6, loss: 0.9419456124305725\n",
      "epoch: 2, batch: 7, loss: 0.7832484245300293\n",
      "epoch: 2, batch: 8, loss: 0.8725947737693787\n",
      "epoch: 2, batch: 9, loss: 1.1033040285110474\n",
      "epoch: 2, batch: 10, loss: 0.8789178729057312\n",
      "epoch: 2, batch: 11, loss: 1.0187394618988037\n",
      "epoch: 2, batch: 12, loss: 0.885968029499054\n",
      "epoch: 2, batch: 13, loss: 0.8432067632675171\n",
      "epoch: 2, batch: 14, loss: 1.2061171531677246\n",
      "epoch: 2, batch: 15, loss: 1.0810089111328125\n",
      "epoch: 2, batch: 16, loss: 0.6679337024688721\n",
      "epoch: 2, batch: 17, loss: 1.0861737728118896\n",
      "epoch: 2, batch: 18, loss: 0.6634641885757446\n",
      "epoch: 2, batch: 19, loss: 0.716090738773346\n",
      "epoch: 2, batch: 20, loss: 0.943740963935852\n",
      "epoch: 2, batch: 21, loss: 1.0976896286010742\n",
      "epoch: 2, batch: 22, loss: 0.9239431619644165\n",
      "epoch: 2, batch: 23, loss: 0.763002336025238\n",
      "epoch: 2, batch: 24, loss: 0.7899147272109985\n",
      "epoch: 2, batch: 25, loss: 0.8737211227416992\n",
      "epoch: 2, batch: 26, loss: 0.7719869613647461\n",
      "epoch: 2, batch: 27, loss: 0.7373916506767273\n",
      "epoch: 2, batch: 28, loss: 0.9608662724494934\n",
      "epoch: 3, batch: 0, loss: 0.7392391562461853\n",
      "epoch: 3, batch: 1, loss: 0.6957185864448547\n",
      "epoch: 3, batch: 2, loss: 0.7081252932548523\n",
      "epoch: 3, batch: 3, loss: 0.5979836583137512\n",
      "epoch: 3, batch: 4, loss: 0.8576315641403198\n",
      "epoch: 3, batch: 5, loss: 0.7354320287704468\n",
      "epoch: 3, batch: 6, loss: 0.9108952283859253\n",
      "epoch: 3, batch: 7, loss: 0.5805550217628479\n",
      "epoch: 3, batch: 8, loss: 0.6282868385314941\n",
      "epoch: 3, batch: 9, loss: 0.910061240196228\n",
      "epoch: 3, batch: 10, loss: 0.824459969997406\n",
      "epoch: 3, batch: 11, loss: 0.6136616468429565\n",
      "epoch: 3, batch: 12, loss: 1.1322654485702515\n",
      "epoch: 3, batch: 13, loss: 0.8992167115211487\n",
      "epoch: 3, batch: 14, loss: 0.8619394898414612\n",
      "epoch: 3, batch: 15, loss: 0.5990396738052368\n",
      "epoch: 3, batch: 16, loss: 0.8033730983734131\n",
      "epoch: 3, batch: 17, loss: 0.6251425743103027\n",
      "epoch: 3, batch: 18, loss: 0.5970640182495117\n",
      "epoch: 3, batch: 19, loss: 0.6310237646102905\n",
      "epoch: 3, batch: 20, loss: 0.42320892214775085\n",
      "epoch: 3, batch: 21, loss: 0.6883207559585571\n",
      "epoch: 3, batch: 22, loss: 0.8752481937408447\n",
      "epoch: 3, batch: 23, loss: 0.6697373390197754\n",
      "epoch: 3, batch: 24, loss: 0.897472083568573\n",
      "epoch: 3, batch: 25, loss: 0.7925896644592285\n",
      "epoch: 3, batch: 26, loss: 0.6045241951942444\n",
      "epoch: 3, batch: 27, loss: 0.6849546432495117\n",
      "epoch: 3, batch: 28, loss: 0.9881690740585327\n",
      "epoch: 4, batch: 0, loss: 0.5339701771736145\n",
      "epoch: 4, batch: 1, loss: 0.9538849592208862\n",
      "epoch: 4, batch: 2, loss: 0.5941752195358276\n",
      "epoch: 4, batch: 3, loss: 0.5760628581047058\n",
      "epoch: 4, batch: 4, loss: 1.0941232442855835\n",
      "epoch: 4, batch: 5, loss: 0.5742426514625549\n",
      "epoch: 4, batch: 6, loss: 0.6067463755607605\n",
      "epoch: 4, batch: 7, loss: 1.0162276029586792\n",
      "epoch: 4, batch: 8, loss: 0.5200189352035522\n",
      "epoch: 4, batch: 9, loss: 0.5992116928100586\n",
      "epoch: 4, batch: 10, loss: 1.091856837272644\n",
      "epoch: 4, batch: 11, loss: 0.5322515368461609\n",
      "epoch: 4, batch: 12, loss: 0.6419006586074829\n",
      "epoch: 4, batch: 13, loss: 0.49875327944755554\n",
      "epoch: 4, batch: 14, loss: 0.7617374062538147\n",
      "epoch: 4, batch: 15, loss: 0.7689058184623718\n",
      "epoch: 4, batch: 16, loss: 0.758338987827301\n",
      "epoch: 4, batch: 17, loss: 0.8529808521270752\n",
      "epoch: 4, batch: 18, loss: 0.4443798065185547\n",
      "epoch: 4, batch: 19, loss: 0.5315434336662292\n",
      "epoch: 4, batch: 20, loss: 0.6603069305419922\n",
      "epoch: 4, batch: 21, loss: 0.7586555480957031\n",
      "epoch: 4, batch: 22, loss: 0.661244809627533\n",
      "epoch: 4, batch: 23, loss: 0.9505290389060974\n",
      "epoch: 4, batch: 24, loss: 0.5813037157058716\n",
      "epoch: 4, batch: 25, loss: 0.5457873940467834\n",
      "epoch: 4, batch: 26, loss: 0.6009051203727722\n",
      "epoch: 4, batch: 27, loss: 0.7388045191764832\n",
      "epoch: 4, batch: 28, loss: 0.9943904876708984\n",
      "epoch: 5, batch: 0, loss: 0.505304217338562\n",
      "epoch: 5, batch: 1, loss: 0.5849335789680481\n",
      "epoch: 5, batch: 2, loss: 0.8394684791564941\n",
      "epoch: 5, batch: 3, loss: 0.571537971496582\n",
      "epoch: 5, batch: 4, loss: 0.44220659136772156\n",
      "epoch: 5, batch: 5, loss: 0.50331711769104\n",
      "epoch: 5, batch: 6, loss: 0.6429802775382996\n",
      "epoch: 5, batch: 7, loss: 0.6770346760749817\n",
      "epoch: 5, batch: 8, loss: 0.5467779636383057\n",
      "epoch: 5, batch: 9, loss: 0.3586062788963318\n",
      "epoch: 5, batch: 10, loss: 0.5035884976387024\n",
      "epoch: 5, batch: 11, loss: 0.26988670229911804\n",
      "epoch: 5, batch: 12, loss: 0.5418450236320496\n",
      "epoch: 5, batch: 13, loss: 0.4548335373401642\n",
      "epoch: 5, batch: 14, loss: 0.35336756706237793\n",
      "epoch: 5, batch: 15, loss: 0.5896011590957642\n",
      "epoch: 5, batch: 16, loss: 0.6287521123886108\n",
      "epoch: 5, batch: 17, loss: 0.3826523721218109\n",
      "epoch: 5, batch: 18, loss: 0.5891917943954468\n",
      "epoch: 5, batch: 19, loss: 0.7717353105545044\n",
      "epoch: 5, batch: 20, loss: 0.4500885009765625\n",
      "epoch: 5, batch: 21, loss: 0.8915205001831055\n",
      "epoch: 5, batch: 22, loss: 0.35179099440574646\n",
      "epoch: 5, batch: 23, loss: 0.7305269241333008\n",
      "epoch: 5, batch: 24, loss: 0.6078670024871826\n",
      "epoch: 5, batch: 25, loss: 0.45312047004699707\n",
      "epoch: 5, batch: 26, loss: 0.5927092432975769\n",
      "epoch: 5, batch: 27, loss: 0.7736545205116272\n",
      "epoch: 5, batch: 28, loss: 1.8621103763580322\n",
      "epoch: 6, batch: 0, loss: 0.43131086230278015\n",
      "epoch: 6, batch: 1, loss: 0.4425511658191681\n",
      "epoch: 6, batch: 2, loss: 0.9838761687278748\n",
      "epoch: 6, batch: 3, loss: 0.6605393290519714\n",
      "epoch: 6, batch: 4, loss: 0.6766132712364197\n",
      "epoch: 6, batch: 5, loss: 0.7905110120773315\n",
      "epoch: 6, batch: 6, loss: 0.5824517607688904\n",
      "epoch: 6, batch: 7, loss: 0.5574954152107239\n",
      "epoch: 6, batch: 8, loss: 0.8588536381721497\n",
      "epoch: 6, batch: 9, loss: 0.8951042294502258\n",
      "epoch: 6, batch: 10, loss: 0.5214252471923828\n",
      "epoch: 6, batch: 11, loss: 0.6635808944702148\n",
      "epoch: 6, batch: 12, loss: 0.526833713054657\n",
      "epoch: 6, batch: 13, loss: 0.2837250828742981\n",
      "epoch: 6, batch: 14, loss: 0.7398679256439209\n",
      "epoch: 6, batch: 15, loss: 0.8627990484237671\n",
      "epoch: 6, batch: 16, loss: 0.5399024486541748\n",
      "epoch: 6, batch: 17, loss: 0.9069819450378418\n",
      "epoch: 6, batch: 18, loss: 0.5379132032394409\n",
      "epoch: 6, batch: 19, loss: 0.5822382569313049\n",
      "epoch: 6, batch: 20, loss: 0.625786542892456\n",
      "epoch: 6, batch: 21, loss: 0.5699489116668701\n",
      "epoch: 6, batch: 22, loss: 0.8145615458488464\n",
      "epoch: 6, batch: 23, loss: 0.42800241708755493\n",
      "epoch: 6, batch: 24, loss: 0.710595428943634\n",
      "epoch: 6, batch: 25, loss: 0.8568598031997681\n",
      "epoch: 6, batch: 26, loss: 0.3359403610229492\n",
      "epoch: 6, batch: 27, loss: 0.49669894576072693\n",
      "epoch: 6, batch: 28, loss: 0.8896371722221375\n",
      "epoch: 7, batch: 0, loss: 0.45805320143699646\n",
      "epoch: 7, batch: 1, loss: 0.4709959030151367\n",
      "epoch: 7, batch: 2, loss: 0.419697642326355\n",
      "epoch: 7, batch: 3, loss: 0.6775474548339844\n",
      "epoch: 7, batch: 4, loss: 0.677643358707428\n",
      "epoch: 7, batch: 5, loss: 0.44679924845695496\n",
      "epoch: 7, batch: 6, loss: 0.3394797742366791\n",
      "epoch: 7, batch: 7, loss: 0.6474354267120361\n",
      "epoch: 7, batch: 8, loss: 0.32516345381736755\n",
      "epoch: 7, batch: 9, loss: 0.4465879797935486\n",
      "epoch: 7, batch: 10, loss: 0.3528013825416565\n",
      "epoch: 7, batch: 11, loss: 0.3643316924571991\n",
      "epoch: 7, batch: 12, loss: 0.6548020839691162\n",
      "epoch: 7, batch: 13, loss: 0.5412297248840332\n",
      "epoch: 7, batch: 14, loss: 0.3064485192298889\n",
      "epoch: 7, batch: 15, loss: 0.4415165185928345\n",
      "epoch: 7, batch: 16, loss: 0.762539267539978\n",
      "epoch: 7, batch: 17, loss: 0.3897748291492462\n",
      "epoch: 7, batch: 18, loss: 0.47542905807495117\n",
      "epoch: 7, batch: 19, loss: 0.7932942509651184\n",
      "epoch: 7, batch: 20, loss: 0.748842716217041\n",
      "epoch: 7, batch: 21, loss: 0.5710439085960388\n",
      "epoch: 7, batch: 22, loss: 0.6015698909759521\n",
      "epoch: 7, batch: 23, loss: 0.3331851661205292\n",
      "epoch: 7, batch: 24, loss: 0.5605907440185547\n",
      "epoch: 7, batch: 25, loss: 0.312928169965744\n",
      "epoch: 7, batch: 26, loss: 0.5536386370658875\n",
      "epoch: 7, batch: 27, loss: 0.32221323251724243\n",
      "epoch: 7, batch: 28, loss: 0.10555973649024963\n",
      "epoch: 8, batch: 0, loss: 0.3930254578590393\n",
      "epoch: 8, batch: 1, loss: 0.22453898191452026\n",
      "epoch: 8, batch: 2, loss: 0.368596613407135\n",
      "epoch: 8, batch: 3, loss: 0.24323615431785583\n",
      "epoch: 8, batch: 4, loss: 0.5238544344902039\n",
      "epoch: 8, batch: 5, loss: 0.2082907259464264\n",
      "epoch: 8, batch: 6, loss: 0.37297379970550537\n",
      "epoch: 8, batch: 7, loss: 0.19890929758548737\n",
      "epoch: 8, batch: 8, loss: 0.20296721160411835\n",
      "epoch: 8, batch: 9, loss: 0.5619344711303711\n",
      "epoch: 8, batch: 10, loss: 0.20753178000450134\n",
      "epoch: 8, batch: 11, loss: 0.22386661171913147\n",
      "epoch: 8, batch: 12, loss: 0.17939400672912598\n",
      "epoch: 8, batch: 13, loss: 0.1902538388967514\n",
      "epoch: 8, batch: 14, loss: 0.24450910091400146\n",
      "epoch: 8, batch: 15, loss: 0.39112845063209534\n",
      "epoch: 8, batch: 16, loss: 0.27142125368118286\n",
      "epoch: 8, batch: 17, loss: 0.33920028805732727\n",
      "epoch: 8, batch: 18, loss: 0.20209833979606628\n",
      "epoch: 8, batch: 19, loss: 0.15869677066802979\n",
      "epoch: 8, batch: 20, loss: 0.19488142430782318\n",
      "epoch: 8, batch: 21, loss: 0.14572839438915253\n",
      "epoch: 8, batch: 22, loss: 0.3562543988227844\n",
      "epoch: 8, batch: 23, loss: 0.2844085991382599\n",
      "epoch: 8, batch: 24, loss: 0.32938966155052185\n",
      "epoch: 8, batch: 25, loss: 0.1148112341761589\n",
      "epoch: 8, batch: 26, loss: 0.22084331512451172\n",
      "epoch: 8, batch: 27, loss: 0.34838807582855225\n",
      "epoch: 8, batch: 28, loss: 1.2756750583648682\n",
      "epoch: 9, batch: 0, loss: 0.1742009073495865\n",
      "epoch: 9, batch: 1, loss: 0.16995854675769806\n",
      "epoch: 9, batch: 2, loss: 0.15785841643810272\n",
      "epoch: 9, batch: 3, loss: 0.5292813181877136\n",
      "epoch: 9, batch: 4, loss: 0.19894592463970184\n",
      "epoch: 9, batch: 5, loss: 0.38581323623657227\n",
      "epoch: 9, batch: 6, loss: 0.37657538056373596\n",
      "epoch: 9, batch: 7, loss: 0.5901280641555786\n",
      "epoch: 9, batch: 8, loss: 0.1948300004005432\n",
      "epoch: 9, batch: 9, loss: 0.3057977855205536\n",
      "epoch: 9, batch: 10, loss: 0.3239195942878723\n",
      "epoch: 9, batch: 11, loss: 0.22485417127609253\n",
      "epoch: 9, batch: 12, loss: 0.4478163719177246\n",
      "epoch: 9, batch: 13, loss: 0.5924623012542725\n",
      "epoch: 9, batch: 14, loss: 0.2845229506492615\n",
      "epoch: 9, batch: 15, loss: 0.3507046401500702\n",
      "epoch: 9, batch: 16, loss: 0.5104891061782837\n",
      "epoch: 9, batch: 17, loss: 0.20977263152599335\n",
      "epoch: 9, batch: 18, loss: 0.3132122755050659\n",
      "epoch: 9, batch: 19, loss: 0.25302761793136597\n",
      "epoch: 9, batch: 20, loss: 0.26424258947372437\n",
      "epoch: 9, batch: 21, loss: 0.2059873640537262\n",
      "epoch: 9, batch: 22, loss: 0.25953465700149536\n",
      "epoch: 9, batch: 23, loss: 0.6863020658493042\n",
      "epoch: 9, batch: 24, loss: 0.5194668769836426\n",
      "epoch: 9, batch: 25, loss: 0.3465329706668854\n",
      "epoch: 9, batch: 26, loss: 0.3840877413749695\n",
      "epoch: 9, batch: 27, loss: 0.26653996109962463\n",
      "epoch: 9, batch: 28, loss: 0.31372785568237305\n",
      "epoch: 10, batch: 0, loss: 0.13321638107299805\n",
      "epoch: 10, batch: 1, loss: 0.16252176463603973\n",
      "epoch: 10, batch: 2, loss: 0.08789236098527908\n",
      "epoch: 10, batch: 3, loss: 0.12576571106910706\n",
      "epoch: 10, batch: 4, loss: 0.28893187642097473\n",
      "epoch: 10, batch: 5, loss: 0.11124610900878906\n",
      "epoch: 10, batch: 6, loss: 0.14827683568000793\n",
      "epoch: 10, batch: 7, loss: 0.14876548945903778\n",
      "epoch: 10, batch: 8, loss: 0.1923704892396927\n",
      "epoch: 10, batch: 9, loss: 0.41253575682640076\n",
      "epoch: 10, batch: 10, loss: 0.1899695098400116\n",
      "epoch: 10, batch: 11, loss: 0.2839323580265045\n",
      "epoch: 10, batch: 12, loss: 0.5759677886962891\n",
      "epoch: 10, batch: 13, loss: 0.3042760193347931\n",
      "epoch: 10, batch: 14, loss: 0.17618542909622192\n",
      "epoch: 10, batch: 15, loss: 0.28126126527786255\n",
      "epoch: 10, batch: 16, loss: 0.32212021946907043\n",
      "epoch: 10, batch: 17, loss: 0.24238221347332\n",
      "epoch: 10, batch: 18, loss: 0.17927603423595428\n",
      "epoch: 10, batch: 19, loss: 0.2038864940404892\n",
      "epoch: 10, batch: 20, loss: 0.1920711100101471\n",
      "epoch: 10, batch: 21, loss: 0.20270220935344696\n",
      "epoch: 10, batch: 22, loss: 0.17332454025745392\n",
      "epoch: 10, batch: 23, loss: 0.1874588131904602\n",
      "epoch: 10, batch: 24, loss: 0.11965464055538177\n",
      "epoch: 10, batch: 25, loss: 0.3213399648666382\n",
      "epoch: 10, batch: 26, loss: 0.07359696179628372\n",
      "epoch: 10, batch: 27, loss: 0.20950894057750702\n",
      "epoch: 10, batch: 28, loss: 0.02414558082818985\n",
      "epoch: 11, batch: 0, loss: 0.14012208580970764\n",
      "epoch: 11, batch: 1, loss: 0.10964236408472061\n",
      "epoch: 11, batch: 2, loss: 0.11868344247341156\n",
      "epoch: 11, batch: 3, loss: 0.12546466290950775\n",
      "epoch: 11, batch: 4, loss: 0.09651637822389603\n",
      "epoch: 11, batch: 5, loss: 0.10824912786483765\n",
      "epoch: 11, batch: 6, loss: 0.06496582180261612\n",
      "epoch: 11, batch: 7, loss: 0.06919953227043152\n",
      "epoch: 11, batch: 8, loss: 0.07099126279354095\n",
      "epoch: 11, batch: 9, loss: 0.14360807836055756\n",
      "epoch: 11, batch: 10, loss: 0.11787505447864532\n",
      "epoch: 11, batch: 11, loss: 0.12525178492069244\n",
      "epoch: 11, batch: 12, loss: 0.2734397351741791\n",
      "epoch: 11, batch: 13, loss: 0.08434959501028061\n",
      "epoch: 11, batch: 14, loss: 0.10426782816648483\n",
      "epoch: 11, batch: 15, loss: 0.13299117982387543\n",
      "epoch: 11, batch: 16, loss: 0.16940893232822418\n",
      "epoch: 11, batch: 17, loss: 0.18383312225341797\n",
      "epoch: 11, batch: 18, loss: 0.05887967720627785\n",
      "epoch: 11, batch: 19, loss: 0.08285009115934372\n",
      "epoch: 11, batch: 20, loss: 0.08958104997873306\n",
      "epoch: 11, batch: 21, loss: 0.2592707872390747\n",
      "epoch: 11, batch: 22, loss: 0.09059973061084747\n",
      "epoch: 11, batch: 23, loss: 0.06394846737384796\n",
      "epoch: 11, batch: 24, loss: 0.059404708445072174\n",
      "epoch: 11, batch: 25, loss: 0.27178746461868286\n",
      "epoch: 11, batch: 26, loss: 0.13039956986904144\n",
      "epoch: 11, batch: 27, loss: 0.10139479488134384\n",
      "epoch: 11, batch: 28, loss: 0.1589721441268921\n",
      "epoch: 12, batch: 0, loss: 0.1537153720855713\n",
      "epoch: 12, batch: 1, loss: 0.06618600338697433\n",
      "epoch: 12, batch: 2, loss: 0.21219788491725922\n",
      "epoch: 12, batch: 3, loss: 0.18747828900814056\n",
      "epoch: 12, batch: 4, loss: 0.11154679208993912\n",
      "epoch: 12, batch: 5, loss: 0.30724257230758667\n",
      "epoch: 12, batch: 6, loss: 0.18255314230918884\n",
      "epoch: 12, batch: 7, loss: 0.28912732005119324\n",
      "epoch: 12, batch: 8, loss: 0.04670466482639313\n",
      "epoch: 12, batch: 9, loss: 0.04503967985510826\n",
      "epoch: 12, batch: 10, loss: 0.10474248975515366\n",
      "epoch: 12, batch: 11, loss: 0.3412652313709259\n",
      "epoch: 12, batch: 12, loss: 0.14153894782066345\n",
      "epoch: 12, batch: 13, loss: 0.12522822618484497\n",
      "epoch: 12, batch: 14, loss: 0.0552077516913414\n",
      "epoch: 12, batch: 15, loss: 0.07007444649934769\n",
      "epoch: 12, batch: 16, loss: 0.08655454218387604\n",
      "epoch: 12, batch: 17, loss: 0.13009138405323029\n",
      "epoch: 12, batch: 18, loss: 0.20674435794353485\n",
      "epoch: 12, batch: 19, loss: 0.026087649166584015\n",
      "epoch: 12, batch: 20, loss: 0.03650747612118721\n",
      "epoch: 12, batch: 21, loss: 0.062280237674713135\n",
      "epoch: 12, batch: 22, loss: 0.07687655091285706\n",
      "epoch: 12, batch: 23, loss: 0.024258993566036224\n",
      "epoch: 12, batch: 24, loss: 0.4208888113498688\n",
      "epoch: 12, batch: 25, loss: 0.11089026182889938\n",
      "epoch: 12, batch: 26, loss: 0.09255844354629517\n",
      "epoch: 12, batch: 27, loss: 0.10975001752376556\n",
      "epoch: 12, batch: 28, loss: 0.2958255410194397\n",
      "epoch: 13, batch: 0, loss: 0.06179752200841904\n",
      "epoch: 13, batch: 1, loss: 0.09600614756345749\n",
      "epoch: 13, batch: 2, loss: 0.1419791728258133\n",
      "epoch: 13, batch: 3, loss: 0.19766150414943695\n",
      "epoch: 13, batch: 4, loss: 0.12590454518795013\n",
      "epoch: 13, batch: 5, loss: 0.14734143018722534\n",
      "epoch: 13, batch: 6, loss: 0.0769311711192131\n",
      "epoch: 13, batch: 7, loss: 0.08286424726247787\n",
      "epoch: 13, batch: 8, loss: 0.03937144577503204\n",
      "epoch: 13, batch: 9, loss: 0.10413198918104172\n",
      "epoch: 13, batch: 10, loss: 0.17727456986904144\n",
      "epoch: 13, batch: 11, loss: 0.15002579987049103\n",
      "epoch: 13, batch: 12, loss: 0.12539391219615936\n",
      "epoch: 13, batch: 13, loss: 0.0931510329246521\n",
      "epoch: 13, batch: 14, loss: 0.11599297821521759\n",
      "epoch: 13, batch: 15, loss: 0.10220034420490265\n",
      "epoch: 13, batch: 16, loss: 0.11691432446241379\n",
      "epoch: 13, batch: 17, loss: 0.05506310984492302\n",
      "epoch: 13, batch: 18, loss: 0.17511139810085297\n",
      "epoch: 13, batch: 19, loss: 0.06199829280376434\n",
      "epoch: 13, batch: 20, loss: 0.05100050941109657\n",
      "epoch: 13, batch: 21, loss: 0.08054758608341217\n",
      "epoch: 13, batch: 22, loss: 0.06977220624685287\n",
      "epoch: 13, batch: 23, loss: 0.045673955231904984\n",
      "epoch: 13, batch: 24, loss: 0.08336486667394638\n",
      "epoch: 13, batch: 25, loss: 0.2497117668390274\n",
      "epoch: 13, batch: 26, loss: 0.15429434180259705\n",
      "epoch: 13, batch: 27, loss: 0.022071020677685738\n",
      "epoch: 13, batch: 28, loss: 0.13990968465805054\n",
      "epoch: 14, batch: 0, loss: 0.0835757851600647\n",
      "epoch: 14, batch: 1, loss: 0.0794067308306694\n",
      "epoch: 14, batch: 2, loss: 0.08762598782777786\n",
      "epoch: 14, batch: 3, loss: 0.09113895148038864\n",
      "epoch: 14, batch: 4, loss: 0.0373946875333786\n",
      "epoch: 14, batch: 5, loss: 0.11200261861085892\n",
      "epoch: 14, batch: 6, loss: 0.04577341303229332\n",
      "epoch: 14, batch: 7, loss: 0.07510159909725189\n",
      "epoch: 14, batch: 8, loss: 0.042433276772499084\n",
      "epoch: 14, batch: 9, loss: 0.02930154837667942\n",
      "epoch: 14, batch: 10, loss: 0.20389719307422638\n",
      "epoch: 14, batch: 11, loss: 0.2572977542877197\n",
      "epoch: 14, batch: 12, loss: 0.10989873111248016\n",
      "epoch: 14, batch: 13, loss: 0.07990463078022003\n",
      "epoch: 14, batch: 14, loss: 0.05239960551261902\n",
      "epoch: 14, batch: 15, loss: 0.05629462003707886\n",
      "epoch: 14, batch: 16, loss: 0.13164563477039337\n",
      "epoch: 14, batch: 17, loss: 0.028711605817079544\n",
      "epoch: 14, batch: 18, loss: 0.12019182741641998\n",
      "epoch: 14, batch: 19, loss: 0.12540344893932343\n",
      "epoch: 14, batch: 20, loss: 0.042538322508335114\n",
      "epoch: 14, batch: 21, loss: 0.032883018255233765\n",
      "epoch: 14, batch: 22, loss: 0.1449507474899292\n",
      "epoch: 14, batch: 23, loss: 0.04039276763796806\n",
      "epoch: 14, batch: 24, loss: 0.2384277731180191\n",
      "epoch: 14, batch: 25, loss: 0.07618867605924606\n",
      "epoch: 14, batch: 26, loss: 0.220770925283432\n",
      "epoch: 14, batch: 27, loss: 0.22529441118240356\n",
      "epoch: 14, batch: 28, loss: 0.006958846002817154\n",
      "epoch: 15, batch: 0, loss: 0.16916151344776154\n",
      "epoch: 15, batch: 1, loss: 0.10904476046562195\n",
      "epoch: 15, batch: 2, loss: 0.02463441528379917\n",
      "epoch: 15, batch: 3, loss: 0.021065426990389824\n",
      "epoch: 15, batch: 4, loss: 0.18547090888023376\n",
      "epoch: 15, batch: 5, loss: 0.09196798503398895\n",
      "epoch: 15, batch: 6, loss: 0.193814218044281\n",
      "epoch: 15, batch: 7, loss: 0.20228137075901031\n",
      "epoch: 15, batch: 8, loss: 0.107719786465168\n",
      "epoch: 15, batch: 9, loss: 0.06365904211997986\n",
      "epoch: 15, batch: 10, loss: 0.0628427118062973\n",
      "epoch: 15, batch: 11, loss: 0.23679707944393158\n",
      "epoch: 15, batch: 12, loss: 0.1720200926065445\n",
      "epoch: 15, batch: 13, loss: 0.02436927706003189\n",
      "epoch: 15, batch: 14, loss: 0.15136650204658508\n",
      "epoch: 15, batch: 15, loss: 0.05517948418855667\n",
      "epoch: 15, batch: 16, loss: 0.021030422300100327\n",
      "epoch: 15, batch: 17, loss: 0.1500764638185501\n",
      "epoch: 15, batch: 18, loss: 0.12173663079738617\n",
      "epoch: 15, batch: 19, loss: 0.08534468710422516\n",
      "epoch: 15, batch: 20, loss: 0.07444079220294952\n",
      "epoch: 15, batch: 21, loss: 0.12807005643844604\n",
      "epoch: 15, batch: 22, loss: 0.1975431591272354\n",
      "epoch: 15, batch: 23, loss: 0.0458575077354908\n",
      "epoch: 15, batch: 24, loss: 0.3023010194301605\n",
      "epoch: 15, batch: 25, loss: 0.026598287746310234\n",
      "epoch: 15, batch: 26, loss: 0.10408978909254074\n",
      "epoch: 15, batch: 27, loss: 0.04862957447767258\n",
      "epoch: 15, batch: 28, loss: 0.019905967637896538\n",
      "epoch: 16, batch: 0, loss: 0.04650655761361122\n",
      "epoch: 16, batch: 1, loss: 0.09316900372505188\n",
      "epoch: 16, batch: 2, loss: 0.24117325246334076\n",
      "epoch: 16, batch: 3, loss: 0.05206392705440521\n",
      "epoch: 16, batch: 4, loss: 0.2173154056072235\n",
      "epoch: 16, batch: 5, loss: 0.3571174740791321\n",
      "epoch: 16, batch: 6, loss: 0.31898295879364014\n",
      "epoch: 16, batch: 7, loss: 0.019755776971578598\n",
      "epoch: 16, batch: 8, loss: 0.11105772107839584\n",
      "epoch: 16, batch: 9, loss: 0.11702971160411835\n",
      "epoch: 16, batch: 10, loss: 0.02391236089169979\n",
      "epoch: 16, batch: 11, loss: 0.15417316555976868\n",
      "epoch: 16, batch: 12, loss: 0.032326821237802505\n",
      "epoch: 16, batch: 13, loss: 0.12861621379852295\n",
      "epoch: 16, batch: 14, loss: 0.13781698048114777\n",
      "epoch: 16, batch: 15, loss: 0.08311324566602707\n",
      "epoch: 16, batch: 16, loss: 0.1499660760164261\n",
      "epoch: 16, batch: 17, loss: 0.07493935525417328\n",
      "epoch: 16, batch: 18, loss: 0.09536450356245041\n",
      "epoch: 16, batch: 19, loss: 0.11870106309652328\n",
      "epoch: 16, batch: 20, loss: 0.21858122944831848\n",
      "epoch: 16, batch: 21, loss: 0.1266842484474182\n",
      "epoch: 16, batch: 22, loss: 0.09770642220973969\n",
      "epoch: 16, batch: 23, loss: 0.10295713692903519\n",
      "epoch: 16, batch: 24, loss: 0.11974428594112396\n",
      "epoch: 16, batch: 25, loss: 0.17201316356658936\n",
      "epoch: 16, batch: 26, loss: 0.03741521015763283\n",
      "epoch: 16, batch: 27, loss: 0.11305604875087738\n",
      "epoch: 16, batch: 28, loss: 0.035002872347831726\n",
      "epoch: 17, batch: 0, loss: 0.07176674157381058\n",
      "epoch: 17, batch: 1, loss: 0.03266974911093712\n",
      "epoch: 17, batch: 2, loss: 0.14659924805164337\n",
      "epoch: 17, batch: 3, loss: 0.13489703834056854\n",
      "epoch: 17, batch: 4, loss: 0.03723208233714104\n",
      "epoch: 17, batch: 5, loss: 0.041845813393592834\n",
      "epoch: 17, batch: 6, loss: 0.10284905135631561\n",
      "epoch: 17, batch: 7, loss: 0.014998228289186954\n",
      "epoch: 17, batch: 8, loss: 0.2266586571931839\n",
      "epoch: 17, batch: 9, loss: 0.04373938962817192\n",
      "epoch: 17, batch: 10, loss: 0.032017242163419724\n",
      "epoch: 17, batch: 11, loss: 0.30098074674606323\n",
      "epoch: 17, batch: 12, loss: 0.05471805855631828\n",
      "epoch: 17, batch: 13, loss: 0.0510617159307003\n",
      "epoch: 17, batch: 14, loss: 0.09493956714868546\n",
      "epoch: 17, batch: 15, loss: 0.05571451783180237\n",
      "epoch: 17, batch: 16, loss: 0.011824325658380985\n",
      "epoch: 17, batch: 17, loss: 0.0393984392285347\n",
      "epoch: 17, batch: 18, loss: 0.1878872513771057\n",
      "epoch: 17, batch: 19, loss: 0.02664538100361824\n",
      "epoch: 17, batch: 20, loss: 0.17523102462291718\n",
      "epoch: 17, batch: 21, loss: 0.13954704999923706\n",
      "epoch: 17, batch: 22, loss: 0.028715329244732857\n",
      "epoch: 17, batch: 23, loss: 0.01235253270715475\n",
      "epoch: 17, batch: 24, loss: 0.024212298914790154\n",
      "epoch: 17, batch: 25, loss: 0.09038031846284866\n",
      "epoch: 17, batch: 26, loss: 0.020858071744441986\n",
      "epoch: 17, batch: 27, loss: 0.2048078328371048\n",
      "epoch: 17, batch: 28, loss: 0.022916480898857117\n",
      "epoch: 18, batch: 0, loss: 0.008365119807422161\n",
      "epoch: 18, batch: 1, loss: 0.050881750881671906\n",
      "epoch: 18, batch: 2, loss: 0.11098553985357285\n",
      "epoch: 18, batch: 3, loss: 0.06566045433282852\n",
      "epoch: 18, batch: 4, loss: 0.023047244176268578\n",
      "epoch: 18, batch: 5, loss: 0.08139590173959732\n",
      "epoch: 18, batch: 6, loss: 0.07049866020679474\n",
      "epoch: 18, batch: 7, loss: 0.015120934695005417\n",
      "epoch: 18, batch: 8, loss: 0.01482882909476757\n",
      "epoch: 18, batch: 9, loss: 0.02224196121096611\n",
      "epoch: 18, batch: 10, loss: 0.03006821498274803\n",
      "epoch: 18, batch: 11, loss: 0.06437419354915619\n",
      "epoch: 18, batch: 12, loss: 0.08654331415891647\n",
      "epoch: 18, batch: 13, loss: 0.023242883384227753\n",
      "epoch: 18, batch: 14, loss: 0.17077487707138062\n",
      "epoch: 18, batch: 15, loss: 0.00693705677986145\n",
      "epoch: 18, batch: 16, loss: 0.01128574088215828\n",
      "epoch: 18, batch: 17, loss: 0.03079213760793209\n",
      "epoch: 18, batch: 18, loss: 0.1857178807258606\n",
      "epoch: 18, batch: 19, loss: 0.049839965999126434\n",
      "epoch: 18, batch: 20, loss: 0.0067501068115234375\n",
      "epoch: 18, batch: 21, loss: 0.006441939622163773\n",
      "epoch: 18, batch: 22, loss: 0.04812277853488922\n",
      "epoch: 18, batch: 23, loss: 0.05424358323216438\n",
      "epoch: 18, batch: 24, loss: 0.31459909677505493\n",
      "epoch: 18, batch: 25, loss: 0.1314123570919037\n",
      "epoch: 18, batch: 26, loss: 0.07926665246486664\n",
      "epoch: 18, batch: 27, loss: 0.013744576834142208\n",
      "epoch: 18, batch: 28, loss: 0.7045490741729736\n",
      "epoch: 19, batch: 0, loss: 0.02383890561759472\n",
      "epoch: 19, batch: 1, loss: 0.08683706074953079\n",
      "epoch: 19, batch: 2, loss: 0.1410534828901291\n",
      "epoch: 19, batch: 3, loss: 0.26055458188056946\n",
      "epoch: 19, batch: 4, loss: 0.6543293595314026\n",
      "epoch: 19, batch: 5, loss: 0.3485620319843292\n",
      "epoch: 19, batch: 6, loss: 0.1255098283290863\n",
      "epoch: 19, batch: 7, loss: 0.16539865732192993\n",
      "epoch: 19, batch: 8, loss: 0.27511149644851685\n",
      "epoch: 19, batch: 9, loss: 0.23745156824588776\n",
      "epoch: 19, batch: 10, loss: 0.11276692152023315\n",
      "epoch: 19, batch: 11, loss: 0.21505425870418549\n",
      "epoch: 19, batch: 12, loss: 0.3106037378311157\n",
      "epoch: 19, batch: 13, loss: 0.30944111943244934\n",
      "epoch: 19, batch: 14, loss: 0.2576085031032562\n",
      "epoch: 19, batch: 15, loss: 0.35889729857444763\n",
      "epoch: 19, batch: 16, loss: 0.7882707118988037\n",
      "epoch: 19, batch: 17, loss: 0.14109937846660614\n",
      "epoch: 19, batch: 18, loss: 0.10712320357561111\n",
      "epoch: 19, batch: 19, loss: 0.44123566150665283\n",
      "epoch: 19, batch: 20, loss: 0.5103271007537842\n",
      "epoch: 19, batch: 21, loss: 0.20493443310260773\n",
      "epoch: 19, batch: 22, loss: 0.41987723112106323\n",
      "epoch: 19, batch: 23, loss: 0.3169170022010803\n",
      "epoch: 19, batch: 24, loss: 0.3128117024898529\n",
      "epoch: 19, batch: 25, loss: 0.305591344833374\n",
      "epoch: 19, batch: 26, loss: 0.7102886438369751\n",
      "epoch: 19, batch: 27, loss: 0.35413530468940735\n",
      "epoch: 19, batch: 28, loss: 1.1336045265197754\n",
      "epoch: 20, batch: 0, loss: 0.1126992329955101\n",
      "epoch: 20, batch: 1, loss: 0.41180992126464844\n",
      "epoch: 20, batch: 2, loss: 0.5885406136512756\n",
      "epoch: 20, batch: 3, loss: 0.42943745851516724\n",
      "epoch: 20, batch: 4, loss: 0.7950021624565125\n",
      "epoch: 20, batch: 5, loss: 0.4183017611503601\n",
      "epoch: 20, batch: 6, loss: 0.6674801111221313\n",
      "epoch: 20, batch: 7, loss: 1.01093327999115\n",
      "epoch: 20, batch: 8, loss: 0.3516715168952942\n",
      "epoch: 20, batch: 9, loss: 0.2735285460948944\n",
      "epoch: 20, batch: 10, loss: 0.4715428948402405\n",
      "epoch: 20, batch: 11, loss: 0.5073757767677307\n",
      "epoch: 20, batch: 12, loss: 0.6231056451797485\n",
      "epoch: 20, batch: 13, loss: 0.4449828565120697\n",
      "epoch: 20, batch: 14, loss: 0.389972984790802\n",
      "epoch: 20, batch: 15, loss: 0.6535068154335022\n",
      "epoch: 20, batch: 16, loss: 0.32931244373321533\n",
      "epoch: 20, batch: 17, loss: 0.45356351137161255\n",
      "epoch: 20, batch: 18, loss: 0.26506009697914124\n",
      "epoch: 20, batch: 19, loss: 0.4503353238105774\n",
      "epoch: 20, batch: 20, loss: 0.38209110498428345\n",
      "epoch: 20, batch: 21, loss: 0.31428608298301697\n",
      "epoch: 20, batch: 22, loss: 0.7835680246353149\n",
      "epoch: 20, batch: 23, loss: 0.4272710680961609\n",
      "epoch: 20, batch: 24, loss: 0.41660186648368835\n",
      "epoch: 20, batch: 25, loss: 0.4245951175689697\n",
      "epoch: 20, batch: 26, loss: 0.25892990827560425\n",
      "epoch: 20, batch: 27, loss: 0.403656542301178\n",
      "epoch: 20, batch: 28, loss: 0.04960400611162186\n",
      "epoch: 21, batch: 0, loss: 0.3944048285484314\n",
      "epoch: 21, batch: 1, loss: 0.09382860362529755\n",
      "epoch: 21, batch: 2, loss: 0.11454544216394424\n",
      "epoch: 21, batch: 3, loss: 0.3343546688556671\n",
      "epoch: 21, batch: 4, loss: 0.17935504019260406\n",
      "epoch: 21, batch: 5, loss: 0.06601375341415405\n",
      "epoch: 21, batch: 6, loss: 0.21276994049549103\n",
      "epoch: 21, batch: 7, loss: 0.21432718634605408\n",
      "epoch: 21, batch: 8, loss: 0.1678682118654251\n",
      "epoch: 21, batch: 9, loss: 0.2452973872423172\n",
      "epoch: 21, batch: 10, loss: 0.15678977966308594\n",
      "epoch: 21, batch: 11, loss: 0.21673105657100677\n",
      "epoch: 21, batch: 12, loss: 0.13895326852798462\n",
      "epoch: 21, batch: 13, loss: 0.1423562616109848\n",
      "epoch: 21, batch: 14, loss: 0.16358040273189545\n",
      "epoch: 21, batch: 15, loss: 0.14877203106880188\n",
      "epoch: 21, batch: 16, loss: 0.10486631840467453\n",
      "epoch: 21, batch: 17, loss: 0.18092595040798187\n",
      "epoch: 21, batch: 18, loss: 0.0659041628241539\n",
      "epoch: 21, batch: 19, loss: 0.2677015960216522\n",
      "epoch: 21, batch: 20, loss: 0.03658381849527359\n",
      "epoch: 21, batch: 21, loss: 0.16364160180091858\n",
      "epoch: 21, batch: 22, loss: 0.22137005627155304\n",
      "epoch: 21, batch: 23, loss: 0.18668660521507263\n",
      "epoch: 21, batch: 24, loss: 0.0949048399925232\n",
      "epoch: 21, batch: 25, loss: 0.1252071112394333\n",
      "epoch: 21, batch: 26, loss: 0.20979538559913635\n",
      "epoch: 21, batch: 27, loss: 0.052795276045799255\n",
      "epoch: 21, batch: 28, loss: 0.1220829039812088\n",
      "epoch: 22, batch: 0, loss: 0.03370904549956322\n",
      "epoch: 22, batch: 1, loss: 0.20453204214572906\n",
      "epoch: 22, batch: 2, loss: 0.04182547703385353\n",
      "epoch: 22, batch: 3, loss: 0.14801841974258423\n",
      "epoch: 22, batch: 4, loss: 0.06213301420211792\n",
      "epoch: 22, batch: 5, loss: 0.07551919668912888\n",
      "epoch: 22, batch: 6, loss: 0.220676988363266\n",
      "epoch: 22, batch: 7, loss: 0.0947750136256218\n",
      "epoch: 22, batch: 8, loss: 0.02494589053094387\n",
      "epoch: 22, batch: 9, loss: 0.14409570395946503\n",
      "epoch: 22, batch: 10, loss: 0.06521615386009216\n",
      "epoch: 22, batch: 11, loss: 0.048297375440597534\n",
      "epoch: 22, batch: 12, loss: 0.04876716807484627\n",
      "epoch: 22, batch: 13, loss: 0.0850241631269455\n",
      "epoch: 22, batch: 14, loss: 0.10599786043167114\n",
      "epoch: 22, batch: 15, loss: 0.14390933513641357\n",
      "epoch: 22, batch: 16, loss: 0.211477592587471\n",
      "epoch: 22, batch: 17, loss: 0.04713781550526619\n",
      "epoch: 22, batch: 18, loss: 0.023148030042648315\n",
      "epoch: 22, batch: 19, loss: 0.11912575364112854\n",
      "epoch: 22, batch: 20, loss: 0.04803482070565224\n",
      "epoch: 22, batch: 21, loss: 0.0367596335709095\n",
      "epoch: 22, batch: 22, loss: 0.17525705695152283\n",
      "epoch: 22, batch: 23, loss: 0.17349372804164886\n",
      "epoch: 22, batch: 24, loss: 0.0381651446223259\n",
      "epoch: 22, batch: 25, loss: 0.047533728182315826\n",
      "epoch: 22, batch: 26, loss: 0.02668944001197815\n",
      "epoch: 22, batch: 27, loss: 0.10312365740537643\n",
      "epoch: 22, batch: 28, loss: 0.13232557475566864\n",
      "epoch: 23, batch: 0, loss: 0.02192986197769642\n",
      "epoch: 23, batch: 1, loss: 0.03132476657629013\n",
      "epoch: 23, batch: 2, loss: 0.07446915656328201\n",
      "epoch: 23, batch: 3, loss: 0.016347961500287056\n",
      "epoch: 23, batch: 4, loss: 0.11186974495649338\n",
      "epoch: 23, batch: 5, loss: 0.037328459322452545\n",
      "epoch: 23, batch: 6, loss: 0.03365626186132431\n",
      "epoch: 23, batch: 7, loss: 0.290878564119339\n",
      "epoch: 23, batch: 8, loss: 0.06135285273194313\n",
      "epoch: 23, batch: 9, loss: 0.011771002784371376\n",
      "epoch: 23, batch: 10, loss: 0.07499385625123978\n",
      "epoch: 23, batch: 11, loss: 0.007793076802045107\n",
      "epoch: 23, batch: 12, loss: 0.05413486436009407\n",
      "epoch: 23, batch: 13, loss: 0.06354830414056778\n",
      "epoch: 23, batch: 14, loss: 0.022323498502373695\n",
      "epoch: 23, batch: 15, loss: 0.03255520015954971\n",
      "epoch: 23, batch: 16, loss: 0.11744362115859985\n",
      "epoch: 23, batch: 17, loss: 0.02831915020942688\n",
      "epoch: 23, batch: 18, loss: 0.19113969802856445\n",
      "epoch: 23, batch: 19, loss: 0.0718846470117569\n",
      "epoch: 23, batch: 20, loss: 0.017748668789863586\n",
      "epoch: 23, batch: 21, loss: 0.014587814919650555\n",
      "epoch: 23, batch: 22, loss: 0.03723612055182457\n",
      "epoch: 23, batch: 23, loss: 0.10318799316883087\n",
      "epoch: 23, batch: 24, loss: 0.03062327951192856\n",
      "epoch: 23, batch: 25, loss: 0.028250649571418762\n",
      "epoch: 23, batch: 26, loss: 0.017746232450008392\n",
      "epoch: 23, batch: 27, loss: 0.14764489233493805\n",
      "epoch: 23, batch: 28, loss: 0.5295591354370117\n",
      "epoch: 24, batch: 0, loss: 0.00703783705830574\n",
      "epoch: 24, batch: 1, loss: 0.020825885236263275\n",
      "epoch: 24, batch: 2, loss: 0.023413801565766335\n",
      "epoch: 24, batch: 3, loss: 0.07135887444019318\n",
      "epoch: 24, batch: 4, loss: 0.11507758498191833\n",
      "epoch: 24, batch: 5, loss: 0.23122051358222961\n",
      "epoch: 24, batch: 6, loss: 0.39662882685661316\n",
      "epoch: 24, batch: 7, loss: 0.2386973351240158\n",
      "epoch: 24, batch: 8, loss: 0.2650267779827118\n",
      "epoch: 24, batch: 9, loss: 0.2218071073293686\n",
      "epoch: 24, batch: 10, loss: 0.05732639133930206\n",
      "epoch: 24, batch: 11, loss: 0.27297067642211914\n",
      "epoch: 24, batch: 12, loss: 0.39400121569633484\n",
      "epoch: 24, batch: 13, loss: 0.24807193875312805\n",
      "epoch: 24, batch: 14, loss: 0.11370859295129776\n",
      "epoch: 24, batch: 15, loss: 0.08882716298103333\n",
      "epoch: 24, batch: 16, loss: 0.2267889827489853\n",
      "epoch: 24, batch: 17, loss: 0.5712289214134216\n",
      "epoch: 24, batch: 18, loss: 0.17918065190315247\n",
      "epoch: 24, batch: 19, loss: 0.033574819564819336\n",
      "epoch: 24, batch: 20, loss: 0.21102023124694824\n",
      "epoch: 24, batch: 21, loss: 0.07268079370260239\n",
      "epoch: 24, batch: 22, loss: 0.09726125746965408\n",
      "epoch: 24, batch: 23, loss: 0.2513245940208435\n",
      "epoch: 24, batch: 24, loss: 0.25404226779937744\n",
      "epoch: 24, batch: 25, loss: 0.07442188262939453\n",
      "epoch: 24, batch: 26, loss: 0.26158612966537476\n",
      "epoch: 24, batch: 27, loss: 0.1919005811214447\n",
      "epoch: 24, batch: 28, loss: 0.8228014707565308\n",
      "epoch: 25, batch: 0, loss: 0.050998054444789886\n",
      "epoch: 25, batch: 1, loss: 0.2963625490665436\n",
      "epoch: 25, batch: 2, loss: 0.43649011850357056\n",
      "epoch: 25, batch: 3, loss: 0.6015071272850037\n",
      "epoch: 25, batch: 4, loss: 0.3415389060974121\n",
      "epoch: 25, batch: 5, loss: 0.2920437753200531\n",
      "epoch: 25, batch: 6, loss: 0.5336398482322693\n",
      "epoch: 25, batch: 7, loss: 0.2081652134656906\n",
      "epoch: 25, batch: 8, loss: 0.6774863004684448\n",
      "epoch: 25, batch: 9, loss: 0.25214019417762756\n",
      "epoch: 25, batch: 10, loss: 0.3154233396053314\n",
      "epoch: 25, batch: 11, loss: 0.19201697409152985\n",
      "epoch: 25, batch: 12, loss: 0.21874849498271942\n",
      "epoch: 25, batch: 13, loss: 0.26307234168052673\n",
      "epoch: 25, batch: 14, loss: 0.25056740641593933\n",
      "epoch: 25, batch: 15, loss: 0.2839156687259674\n",
      "epoch: 25, batch: 16, loss: 0.35328924655914307\n",
      "epoch: 25, batch: 17, loss: 0.20681707561016083\n",
      "epoch: 25, batch: 18, loss: 0.2078694999217987\n",
      "epoch: 25, batch: 19, loss: 0.23364409804344177\n",
      "epoch: 25, batch: 20, loss: 0.16145536303520203\n",
      "epoch: 25, batch: 21, loss: 0.11362747102975845\n",
      "epoch: 25, batch: 22, loss: 0.10011544823646545\n",
      "epoch: 25, batch: 23, loss: 0.16536593437194824\n",
      "epoch: 25, batch: 24, loss: 0.14681999385356903\n",
      "epoch: 25, batch: 25, loss: 0.08101986348628998\n",
      "epoch: 25, batch: 26, loss: 0.26827168464660645\n",
      "epoch: 25, batch: 27, loss: 0.10127726942300797\n",
      "epoch: 25, batch: 28, loss: 0.006581628229469061\n",
      "epoch: 26, batch: 0, loss: 0.10092069208621979\n",
      "epoch: 26, batch: 1, loss: 0.06024748086929321\n",
      "epoch: 26, batch: 2, loss: 0.09430395811796188\n",
      "epoch: 26, batch: 3, loss: 0.11217591166496277\n",
      "epoch: 26, batch: 4, loss: 0.15241937339305878\n",
      "epoch: 26, batch: 5, loss: 0.26437950134277344\n",
      "epoch: 26, batch: 6, loss: 0.12582612037658691\n",
      "epoch: 26, batch: 7, loss: 0.0368785597383976\n",
      "epoch: 26, batch: 8, loss: 0.03172890096902847\n",
      "epoch: 26, batch: 9, loss: 0.03619955852627754\n",
      "epoch: 26, batch: 10, loss: 0.05062228441238403\n",
      "epoch: 26, batch: 11, loss: 0.06661425530910492\n",
      "epoch: 26, batch: 12, loss: 0.044231414794921875\n",
      "epoch: 26, batch: 13, loss: 0.15833766758441925\n",
      "epoch: 26, batch: 14, loss: 0.11715109646320343\n",
      "epoch: 26, batch: 15, loss: 0.07076912373304367\n",
      "epoch: 26, batch: 16, loss: 0.21557515859603882\n",
      "epoch: 26, batch: 17, loss: 0.03647398576140404\n",
      "epoch: 26, batch: 18, loss: 0.08176496624946594\n",
      "epoch: 26, batch: 19, loss: 0.09007791429758072\n",
      "epoch: 26, batch: 20, loss: 0.07663768529891968\n",
      "epoch: 26, batch: 21, loss: 0.16671788692474365\n",
      "epoch: 26, batch: 22, loss: 0.07519397884607315\n",
      "epoch: 26, batch: 23, loss: 0.41789180040359497\n",
      "epoch: 26, batch: 24, loss: 0.08174672722816467\n",
      "epoch: 26, batch: 25, loss: 0.044973406940698624\n",
      "epoch: 26, batch: 26, loss: 0.0500316359102726\n",
      "epoch: 26, batch: 27, loss: 0.02788911759853363\n",
      "epoch: 26, batch: 28, loss: 0.062332216650247574\n",
      "epoch: 27, batch: 0, loss: 0.012573642656207085\n",
      "epoch: 27, batch: 1, loss: 0.031374137848615646\n",
      "epoch: 27, batch: 2, loss: 0.00754875922575593\n",
      "epoch: 27, batch: 3, loss: 0.03451406583189964\n",
      "epoch: 27, batch: 4, loss: 0.06852342188358307\n",
      "epoch: 27, batch: 5, loss: 0.010459075681865215\n",
      "epoch: 27, batch: 6, loss: 0.013343649916350842\n",
      "epoch: 27, batch: 7, loss: 0.14580458402633667\n",
      "epoch: 27, batch: 8, loss: 0.022105971351265907\n",
      "epoch: 27, batch: 9, loss: 0.2325906902551651\n",
      "epoch: 27, batch: 10, loss: 0.03319905325770378\n",
      "epoch: 27, batch: 11, loss: 0.02673402801156044\n",
      "epoch: 27, batch: 12, loss: 0.06966235488653183\n",
      "epoch: 27, batch: 13, loss: 0.15695910155773163\n",
      "epoch: 27, batch: 14, loss: 0.06994185596704483\n",
      "epoch: 27, batch: 15, loss: 0.021185588091611862\n",
      "epoch: 27, batch: 16, loss: 0.012919564731419086\n",
      "epoch: 27, batch: 17, loss: 0.07936030626296997\n",
      "epoch: 27, batch: 18, loss: 0.09024975448846817\n",
      "epoch: 27, batch: 19, loss: 0.06709279119968414\n",
      "epoch: 27, batch: 20, loss: 0.022670084610581398\n",
      "epoch: 27, batch: 21, loss: 0.037602875381708145\n",
      "epoch: 27, batch: 22, loss: 0.0376252681016922\n",
      "epoch: 27, batch: 23, loss: 0.002554163569584489\n",
      "epoch: 27, batch: 24, loss: 0.014398301020264626\n",
      "epoch: 27, batch: 25, loss: 0.00265043624676764\n",
      "epoch: 27, batch: 26, loss: 0.006631684955209494\n",
      "epoch: 27, batch: 27, loss: 0.004127002786844969\n",
      "epoch: 27, batch: 28, loss: 0.525546669960022\n",
      "epoch: 28, batch: 0, loss: 0.006265285890549421\n",
      "epoch: 28, batch: 1, loss: 0.014705471694469452\n",
      "epoch: 28, batch: 2, loss: 0.015386088751256466\n",
      "epoch: 28, batch: 3, loss: 0.08467479795217514\n",
      "epoch: 28, batch: 4, loss: 0.383400022983551\n",
      "epoch: 28, batch: 5, loss: 0.14613774418830872\n",
      "epoch: 28, batch: 6, loss: 0.16031628847122192\n",
      "epoch: 28, batch: 7, loss: 0.17269758880138397\n",
      "epoch: 28, batch: 8, loss: 0.043303392827510834\n",
      "epoch: 28, batch: 9, loss: 0.3343065679073334\n",
      "epoch: 28, batch: 10, loss: 0.48664671182632446\n",
      "epoch: 28, batch: 11, loss: 0.43804338574409485\n",
      "epoch: 28, batch: 12, loss: 0.2330338954925537\n",
      "epoch: 28, batch: 13, loss: 0.03270886093378067\n",
      "epoch: 28, batch: 14, loss: 0.030892008915543556\n",
      "epoch: 28, batch: 15, loss: 0.07016598433256149\n",
      "epoch: 28, batch: 16, loss: 0.0360049307346344\n",
      "epoch: 28, batch: 17, loss: 0.14214548468589783\n",
      "epoch: 28, batch: 18, loss: 0.09117323160171509\n",
      "epoch: 28, batch: 19, loss: 0.19953446090221405\n",
      "epoch: 28, batch: 20, loss: 0.07685507088899612\n",
      "epoch: 28, batch: 21, loss: 0.04443678632378578\n",
      "epoch: 28, batch: 22, loss: 0.09720451384782791\n",
      "epoch: 28, batch: 23, loss: 0.2724645137786865\n",
      "epoch: 28, batch: 24, loss: 0.1475774645805359\n",
      "epoch: 28, batch: 25, loss: 0.1380796581506729\n",
      "epoch: 28, batch: 26, loss: 0.08844003081321716\n",
      "epoch: 28, batch: 27, loss: 0.1836002916097641\n",
      "epoch: 28, batch: 28, loss: 0.4093365967273712\n",
      "epoch: 29, batch: 0, loss: 0.07846866548061371\n",
      "epoch: 29, batch: 1, loss: 0.021564621478319168\n",
      "epoch: 29, batch: 2, loss: 0.11862204968929291\n",
      "epoch: 29, batch: 3, loss: 0.055857617408037186\n",
      "epoch: 29, batch: 4, loss: 0.17084093391895294\n",
      "epoch: 29, batch: 5, loss: 0.18204611539840698\n",
      "epoch: 29, batch: 6, loss: 0.07839354127645493\n",
      "epoch: 29, batch: 7, loss: 0.3510547876358032\n",
      "epoch: 29, batch: 8, loss: 0.02410225197672844\n",
      "epoch: 29, batch: 9, loss: 0.060444433242082596\n",
      "epoch: 29, batch: 10, loss: 0.047481756657361984\n",
      "epoch: 29, batch: 11, loss: 0.06769848614931107\n",
      "epoch: 29, batch: 12, loss: 0.029327761381864548\n",
      "epoch: 29, batch: 13, loss: 0.04572989046573639\n",
      "epoch: 29, batch: 14, loss: 0.07949216663837433\n",
      "epoch: 29, batch: 15, loss: 0.10073822736740112\n",
      "epoch: 29, batch: 16, loss: 0.02507915161550045\n",
      "epoch: 29, batch: 17, loss: 0.16683727502822876\n",
      "epoch: 29, batch: 18, loss: 0.006717478856444359\n",
      "epoch: 29, batch: 19, loss: 0.12911973893642426\n",
      "epoch: 29, batch: 20, loss: 0.007362145930528641\n",
      "epoch: 29, batch: 21, loss: 0.016981784254312515\n",
      "epoch: 29, batch: 22, loss: 0.07104261219501495\n",
      "epoch: 29, batch: 23, loss: 0.08751502633094788\n",
      "epoch: 29, batch: 24, loss: 0.035369884222745895\n",
      "epoch: 29, batch: 25, loss: 0.08356163650751114\n",
      "epoch: 29, batch: 26, loss: 0.01785130240023136\n",
      "epoch: 29, batch: 27, loss: 0.05214182287454605\n",
      "epoch: 29, batch: 28, loss: 0.20001837611198425\n",
      "epoch: 30, batch: 0, loss: 0.004257363732904196\n",
      "epoch: 30, batch: 1, loss: 0.06763394922018051\n",
      "epoch: 30, batch: 2, loss: 0.14923234283924103\n",
      "epoch: 30, batch: 3, loss: 0.09159400314092636\n",
      "epoch: 30, batch: 4, loss: 0.5270447731018066\n",
      "epoch: 30, batch: 5, loss: 0.3002455532550812\n",
      "epoch: 30, batch: 6, loss: 0.06961631774902344\n",
      "epoch: 30, batch: 7, loss: 0.18532629311084747\n",
      "epoch: 30, batch: 8, loss: 0.1267826110124588\n",
      "epoch: 30, batch: 9, loss: 0.01979895681142807\n",
      "epoch: 30, batch: 10, loss: 0.08774962276220322\n",
      "epoch: 30, batch: 11, loss: 0.1952943205833435\n",
      "epoch: 30, batch: 12, loss: 0.12684887647628784\n",
      "epoch: 30, batch: 13, loss: 0.1458618938922882\n",
      "epoch: 30, batch: 14, loss: 0.13065068423748016\n",
      "epoch: 30, batch: 15, loss: 0.173052579164505\n",
      "epoch: 30, batch: 16, loss: 0.07644093781709671\n",
      "epoch: 30, batch: 17, loss: 0.11164219677448273\n",
      "epoch: 30, batch: 18, loss: 0.07635941356420517\n",
      "epoch: 30, batch: 19, loss: 0.06256404519081116\n",
      "epoch: 30, batch: 20, loss: 0.3241276144981384\n",
      "epoch: 30, batch: 21, loss: 0.1316756010055542\n",
      "epoch: 30, batch: 22, loss: 0.031204070895910263\n",
      "epoch: 30, batch: 23, loss: 0.0773894190788269\n",
      "epoch: 30, batch: 24, loss: 0.04977063089609146\n",
      "epoch: 30, batch: 25, loss: 0.06035732105374336\n",
      "epoch: 30, batch: 26, loss: 0.023947736248373985\n",
      "epoch: 30, batch: 27, loss: 0.14528368413448334\n",
      "epoch: 30, batch: 28, loss: 0.9503185153007507\n",
      "epoch: 31, batch: 0, loss: 0.0442909337580204\n",
      "epoch: 31, batch: 1, loss: 0.07130751758813858\n",
      "epoch: 31, batch: 2, loss: 0.08563323318958282\n",
      "epoch: 31, batch: 3, loss: 0.12086016684770584\n",
      "epoch: 31, batch: 4, loss: 0.14238671958446503\n",
      "epoch: 31, batch: 5, loss: 0.4866914451122284\n",
      "epoch: 31, batch: 6, loss: 0.4465749263763428\n",
      "epoch: 31, batch: 7, loss: 0.29311156272888184\n",
      "epoch: 31, batch: 8, loss: 0.3311593234539032\n",
      "epoch: 31, batch: 9, loss: 0.14178261160850525\n",
      "epoch: 31, batch: 10, loss: 0.26663443446159363\n",
      "epoch: 31, batch: 11, loss: 0.18742240965366364\n",
      "epoch: 31, batch: 12, loss: 0.11962679773569107\n",
      "epoch: 31, batch: 13, loss: 0.2656398415565491\n",
      "epoch: 31, batch: 14, loss: 0.072614386677742\n",
      "epoch: 31, batch: 15, loss: 0.16074246168136597\n",
      "epoch: 31, batch: 16, loss: 0.27193015813827515\n",
      "epoch: 31, batch: 17, loss: 0.23901353776454926\n",
      "epoch: 31, batch: 18, loss: 0.06174980476498604\n",
      "epoch: 31, batch: 19, loss: 0.07955893129110336\n",
      "epoch: 31, batch: 20, loss: 0.11882252991199493\n",
      "epoch: 31, batch: 21, loss: 0.33824437856674194\n",
      "epoch: 31, batch: 22, loss: 0.28559648990631104\n",
      "epoch: 31, batch: 23, loss: 0.027442093938589096\n",
      "epoch: 31, batch: 24, loss: 0.09706071019172668\n",
      "epoch: 31, batch: 25, loss: 0.13686637580394745\n",
      "epoch: 31, batch: 26, loss: 0.19906942546367645\n",
      "epoch: 31, batch: 27, loss: 0.3147563338279724\n",
      "epoch: 31, batch: 28, loss: 0.016569126397371292\n",
      "epoch: 32, batch: 0, loss: 0.05696457251906395\n",
      "epoch: 32, batch: 1, loss: 0.17936411499977112\n",
      "epoch: 32, batch: 2, loss: 0.02589186280965805\n",
      "epoch: 32, batch: 3, loss: 0.030150625854730606\n",
      "epoch: 32, batch: 4, loss: 0.010370752774178982\n",
      "epoch: 32, batch: 5, loss: 0.06575889885425568\n",
      "epoch: 32, batch: 6, loss: 0.22137421369552612\n",
      "epoch: 32, batch: 7, loss: 0.05132266506552696\n",
      "epoch: 32, batch: 8, loss: 0.04093708470463753\n",
      "epoch: 32, batch: 9, loss: 0.0880516842007637\n",
      "epoch: 32, batch: 10, loss: 0.1058536022901535\n",
      "epoch: 32, batch: 11, loss: 0.12764616310596466\n",
      "epoch: 32, batch: 12, loss: 0.007340027019381523\n",
      "epoch: 32, batch: 13, loss: 0.04075268656015396\n",
      "epoch: 32, batch: 14, loss: 0.02216867357492447\n",
      "epoch: 32, batch: 15, loss: 0.05057699605822563\n",
      "epoch: 32, batch: 16, loss: 0.06268501281738281\n",
      "epoch: 32, batch: 17, loss: 0.022548332810401917\n",
      "epoch: 32, batch: 18, loss: 0.22654488682746887\n",
      "epoch: 32, batch: 19, loss: 0.08677269518375397\n",
      "epoch: 32, batch: 20, loss: 0.08324113488197327\n",
      "epoch: 32, batch: 21, loss: 0.039697062224149704\n",
      "epoch: 32, batch: 22, loss: 0.20453616976737976\n",
      "epoch: 32, batch: 23, loss: 0.08162987232208252\n",
      "epoch: 32, batch: 24, loss: 0.1045367494225502\n",
      "epoch: 32, batch: 25, loss: 0.021795455366373062\n",
      "epoch: 32, batch: 26, loss: 0.027208292856812477\n",
      "epoch: 32, batch: 27, loss: 0.0191633403301239\n",
      "epoch: 32, batch: 28, loss: 0.6705420017242432\n",
      "epoch: 33, batch: 0, loss: 0.061625007539987564\n",
      "epoch: 33, batch: 1, loss: 0.07911407202482224\n",
      "epoch: 33, batch: 2, loss: 0.3487967848777771\n",
      "epoch: 33, batch: 3, loss: 0.024734165519475937\n",
      "epoch: 33, batch: 4, loss: 0.08988594263792038\n",
      "epoch: 33, batch: 5, loss: 0.03851241618394852\n",
      "epoch: 33, batch: 6, loss: 0.10763613134622574\n",
      "epoch: 33, batch: 7, loss: 0.14591242372989655\n",
      "epoch: 33, batch: 8, loss: 0.15074196457862854\n",
      "epoch: 33, batch: 9, loss: 0.08793768286705017\n",
      "epoch: 33, batch: 10, loss: 0.13181225955486298\n",
      "epoch: 33, batch: 11, loss: 0.3146611154079437\n",
      "epoch: 33, batch: 12, loss: 0.20453761518001556\n",
      "epoch: 33, batch: 13, loss: 0.21811623871326447\n",
      "epoch: 33, batch: 14, loss: 0.248988538980484\n",
      "epoch: 33, batch: 15, loss: 0.8645484447479248\n",
      "epoch: 33, batch: 16, loss: 0.18532730638980865\n",
      "epoch: 33, batch: 17, loss: 0.14276590943336487\n",
      "epoch: 33, batch: 18, loss: 0.4970777928829193\n",
      "epoch: 33, batch: 19, loss: 0.0442037507891655\n",
      "epoch: 33, batch: 20, loss: 0.06329905986785889\n",
      "epoch: 33, batch: 21, loss: 0.0630834698677063\n",
      "epoch: 33, batch: 22, loss: 0.1932641863822937\n",
      "epoch: 33, batch: 23, loss: 0.07593623548746109\n",
      "epoch: 33, batch: 24, loss: 0.2557414770126343\n",
      "epoch: 33, batch: 25, loss: 0.04954765364527702\n",
      "epoch: 33, batch: 26, loss: 0.0352468304336071\n",
      "epoch: 33, batch: 27, loss: 0.09128283709287643\n",
      "epoch: 33, batch: 28, loss: 0.3278411328792572\n",
      "epoch: 34, batch: 0, loss: 0.135818749666214\n",
      "epoch: 34, batch: 1, loss: 0.061754386872053146\n",
      "epoch: 34, batch: 2, loss: 0.017185188829898834\n",
      "epoch: 34, batch: 3, loss: 0.03314577043056488\n",
      "epoch: 34, batch: 4, loss: 0.0803527683019638\n",
      "epoch: 34, batch: 5, loss: 0.2426385134458542\n",
      "epoch: 34, batch: 6, loss: 0.3241543769836426\n",
      "epoch: 34, batch: 7, loss: 0.1435122787952423\n",
      "epoch: 34, batch: 8, loss: 0.1809782087802887\n",
      "epoch: 34, batch: 9, loss: 0.013320529833436012\n",
      "epoch: 34, batch: 10, loss: 0.07598169147968292\n",
      "epoch: 34, batch: 11, loss: 0.09517829120159149\n",
      "epoch: 34, batch: 12, loss: 0.05110881105065346\n",
      "epoch: 34, batch: 13, loss: 0.16593560576438904\n",
      "epoch: 34, batch: 14, loss: 0.0695648193359375\n",
      "epoch: 34, batch: 15, loss: 0.11513223499059677\n",
      "epoch: 34, batch: 16, loss: 0.15538425743579865\n",
      "epoch: 34, batch: 17, loss: 0.08886785060167313\n",
      "epoch: 34, batch: 18, loss: 0.038369495421648026\n",
      "epoch: 34, batch: 19, loss: 0.0531730055809021\n",
      "epoch: 34, batch: 20, loss: 0.07625994086265564\n",
      "epoch: 34, batch: 21, loss: 0.03006369061768055\n",
      "epoch: 34, batch: 22, loss: 0.09770454466342926\n",
      "epoch: 34, batch: 23, loss: 0.019027940928936005\n",
      "epoch: 34, batch: 24, loss: 0.05472110956907272\n",
      "epoch: 34, batch: 25, loss: 0.03210616484284401\n",
      "epoch: 34, batch: 26, loss: 0.04963686689734459\n",
      "epoch: 34, batch: 27, loss: 0.07395385205745697\n",
      "epoch: 34, batch: 28, loss: 1.3202431201934814\n",
      "epoch: 35, batch: 0, loss: 0.030156508088111877\n",
      "epoch: 35, batch: 1, loss: 0.0594019815325737\n",
      "epoch: 35, batch: 2, loss: 0.01903373934328556\n",
      "epoch: 35, batch: 3, loss: 0.3660676181316376\n",
      "epoch: 35, batch: 4, loss: 0.4525437355041504\n",
      "epoch: 35, batch: 5, loss: 0.38214030861854553\n",
      "epoch: 35, batch: 6, loss: 0.48394903540611267\n",
      "epoch: 35, batch: 7, loss: 0.38931676745414734\n",
      "epoch: 35, batch: 8, loss: 0.12997306883335114\n",
      "epoch: 35, batch: 9, loss: 0.48309090733528137\n",
      "epoch: 35, batch: 10, loss: 0.18419282138347626\n",
      "epoch: 35, batch: 11, loss: 0.14958162605762482\n",
      "epoch: 35, batch: 12, loss: 0.10209605097770691\n",
      "epoch: 35, batch: 13, loss: 0.05919579416513443\n",
      "epoch: 35, batch: 14, loss: 0.2806377708911896\n",
      "epoch: 35, batch: 15, loss: 0.20854227244853973\n",
      "epoch: 35, batch: 16, loss: 0.06191718578338623\n",
      "epoch: 35, batch: 17, loss: 0.06745824962854385\n",
      "epoch: 35, batch: 18, loss: 0.19984573125839233\n",
      "epoch: 35, batch: 19, loss: 0.1869065910577774\n",
      "epoch: 35, batch: 20, loss: 0.11365517228841782\n",
      "epoch: 35, batch: 21, loss: 0.36974000930786133\n",
      "epoch: 35, batch: 22, loss: 0.19169336557388306\n",
      "epoch: 35, batch: 23, loss: 0.12088403105735779\n",
      "epoch: 35, batch: 24, loss: 0.14209780097007751\n",
      "epoch: 35, batch: 25, loss: 0.048618994653224945\n",
      "epoch: 35, batch: 26, loss: 0.09682993590831757\n",
      "epoch: 35, batch: 27, loss: 0.022668160498142242\n",
      "epoch: 35, batch: 28, loss: 0.16095763444900513\n",
      "epoch: 36, batch: 0, loss: 0.04749974235892296\n",
      "epoch: 36, batch: 1, loss: 0.061252411454916\n",
      "epoch: 36, batch: 2, loss: 0.13573499023914337\n",
      "epoch: 36, batch: 3, loss: 0.07569872587919235\n",
      "epoch: 36, batch: 4, loss: 0.09196814149618149\n",
      "epoch: 36, batch: 5, loss: 0.24341751635074615\n",
      "epoch: 36, batch: 6, loss: 0.1626916229724884\n",
      "epoch: 36, batch: 7, loss: 0.12798450887203217\n",
      "epoch: 36, batch: 8, loss: 0.11443474888801575\n",
      "epoch: 36, batch: 9, loss: 0.08871401846408844\n",
      "epoch: 36, batch: 10, loss: 0.037008073180913925\n",
      "epoch: 36, batch: 11, loss: 0.10017003118991852\n",
      "epoch: 36, batch: 12, loss: 0.03831653296947479\n",
      "epoch: 36, batch: 13, loss: 0.022751502692699432\n",
      "epoch: 36, batch: 14, loss: 0.09048416465520859\n",
      "epoch: 36, batch: 15, loss: 0.13549576699733734\n",
      "epoch: 36, batch: 16, loss: 0.06775452941656113\n",
      "epoch: 36, batch: 17, loss: 0.011999419890344143\n",
      "epoch: 36, batch: 18, loss: 0.06801386177539825\n",
      "epoch: 36, batch: 19, loss: 0.020845536142587662\n",
      "epoch: 36, batch: 20, loss: 0.22069714963436127\n",
      "epoch: 36, batch: 21, loss: 0.036707065999507904\n",
      "epoch: 36, batch: 22, loss: 0.03394664078950882\n",
      "epoch: 36, batch: 23, loss: 0.042339202016592026\n",
      "epoch: 36, batch: 24, loss: 0.004899824503809214\n",
      "epoch: 36, batch: 25, loss: 0.12964685261249542\n",
      "epoch: 36, batch: 26, loss: 0.01732456311583519\n",
      "epoch: 36, batch: 27, loss: 0.11518438160419464\n",
      "epoch: 36, batch: 28, loss: 0.01833140105009079\n",
      "epoch: 37, batch: 0, loss: 0.010325676761567593\n",
      "epoch: 37, batch: 1, loss: 0.06614099442958832\n",
      "epoch: 37, batch: 2, loss: 0.01181412860751152\n",
      "epoch: 37, batch: 3, loss: 0.009047944098711014\n",
      "epoch: 37, batch: 4, loss: 0.036676809191703796\n",
      "epoch: 37, batch: 5, loss: 0.011203578673303127\n",
      "epoch: 37, batch: 6, loss: 0.0183773934841156\n",
      "epoch: 37, batch: 7, loss: 0.01348439697176218\n",
      "epoch: 37, batch: 8, loss: 0.05134313553571701\n",
      "epoch: 37, batch: 9, loss: 0.05938861891627312\n",
      "epoch: 37, batch: 10, loss: 0.0066026053391397\n",
      "epoch: 37, batch: 11, loss: 0.029584888368844986\n",
      "epoch: 37, batch: 12, loss: 0.009298648685216904\n",
      "epoch: 37, batch: 13, loss: 0.0040211728774011135\n",
      "epoch: 37, batch: 14, loss: 0.00589918764308095\n",
      "epoch: 37, batch: 15, loss: 0.007095466833561659\n",
      "epoch: 37, batch: 16, loss: 0.0412551686167717\n",
      "epoch: 37, batch: 17, loss: 0.015460659749805927\n",
      "epoch: 37, batch: 18, loss: 0.003463496221229434\n",
      "epoch: 37, batch: 19, loss: 0.020729446783661842\n",
      "epoch: 37, batch: 20, loss: 0.00913907214999199\n",
      "epoch: 37, batch: 21, loss: 0.002847521100193262\n",
      "epoch: 37, batch: 22, loss: 0.014375150203704834\n",
      "epoch: 37, batch: 23, loss: 0.010639818385243416\n",
      "epoch: 37, batch: 24, loss: 0.007156200706958771\n",
      "epoch: 37, batch: 25, loss: 0.014758734963834286\n",
      "epoch: 37, batch: 26, loss: 0.005504246335476637\n",
      "epoch: 37, batch: 27, loss: 0.09850849211215973\n",
      "epoch: 37, batch: 28, loss: 0.03180577605962753\n",
      "epoch: 38, batch: 0, loss: 0.0017713219858705997\n",
      "epoch: 38, batch: 1, loss: 0.0026786404196172953\n",
      "epoch: 38, batch: 2, loss: 0.0038802316412329674\n",
      "epoch: 38, batch: 3, loss: 0.0032704207114875317\n",
      "epoch: 38, batch: 4, loss: 0.016657501459121704\n",
      "epoch: 38, batch: 5, loss: 0.014456147328019142\n",
      "epoch: 38, batch: 6, loss: 0.009230634197592735\n",
      "epoch: 38, batch: 7, loss: 0.0131373917683959\n",
      "epoch: 38, batch: 8, loss: 0.0033822180703282356\n",
      "epoch: 38, batch: 9, loss: 0.002547669457271695\n",
      "epoch: 38, batch: 10, loss: 0.016493868082761765\n",
      "epoch: 38, batch: 11, loss: 0.0025956544559448957\n",
      "epoch: 38, batch: 12, loss: 0.001788723049685359\n",
      "epoch: 38, batch: 13, loss: 0.027293860912322998\n",
      "epoch: 38, batch: 14, loss: 0.004240346606820822\n",
      "epoch: 38, batch: 15, loss: 0.006117657292634249\n",
      "epoch: 38, batch: 16, loss: 0.0026891061570495367\n",
      "epoch: 38, batch: 17, loss: 0.005627432372421026\n",
      "epoch: 38, batch: 18, loss: 0.06155265122652054\n",
      "epoch: 38, batch: 19, loss: 0.0036590425297617912\n",
      "epoch: 38, batch: 20, loss: 0.002790355822071433\n",
      "epoch: 38, batch: 21, loss: 0.0010970430448651314\n",
      "epoch: 38, batch: 22, loss: 0.01312720961868763\n",
      "epoch: 38, batch: 23, loss: 0.0050597842782735825\n",
      "epoch: 38, batch: 24, loss: 0.008381764404475689\n",
      "epoch: 38, batch: 25, loss: 0.031542375683784485\n",
      "epoch: 38, batch: 26, loss: 0.0020170200150460005\n",
      "epoch: 38, batch: 27, loss: 0.0027643984649330378\n",
      "epoch: 38, batch: 28, loss: 0.0013639936223626137\n",
      "epoch: 39, batch: 0, loss: 0.0037933094426989555\n",
      "epoch: 39, batch: 1, loss: 0.023106688633561134\n",
      "epoch: 39, batch: 2, loss: 0.002598009305074811\n",
      "epoch: 39, batch: 3, loss: 0.0015048072673380375\n",
      "epoch: 39, batch: 4, loss: 0.006059184670448303\n",
      "epoch: 39, batch: 5, loss: 0.045624990016222\n",
      "epoch: 39, batch: 6, loss: 0.0011062046978622675\n",
      "epoch: 39, batch: 7, loss: 0.004506422206759453\n",
      "epoch: 39, batch: 8, loss: 0.002277600346133113\n",
      "epoch: 39, batch: 9, loss: 0.006631447467952967\n",
      "epoch: 39, batch: 10, loss: 0.009204426780343056\n",
      "epoch: 39, batch: 11, loss: 0.000580574618652463\n",
      "epoch: 39, batch: 12, loss: 0.0014847659040242434\n",
      "epoch: 39, batch: 13, loss: 0.004428086802363396\n",
      "epoch: 39, batch: 14, loss: 0.0015888041816651821\n",
      "epoch: 39, batch: 15, loss: 0.0013899533078074455\n",
      "epoch: 39, batch: 16, loss: 0.002114838222041726\n",
      "epoch: 39, batch: 17, loss: 0.0013569403672590852\n",
      "epoch: 39, batch: 18, loss: 0.0013785972259938717\n",
      "epoch: 39, batch: 19, loss: 0.05218438431620598\n",
      "epoch: 39, batch: 20, loss: 0.0013339694123715162\n",
      "epoch: 39, batch: 21, loss: 0.0015010203933343291\n",
      "epoch: 39, batch: 22, loss: 0.003727512201294303\n",
      "epoch: 39, batch: 23, loss: 0.020614251494407654\n",
      "epoch: 39, batch: 24, loss: 0.0015850684139877558\n",
      "epoch: 39, batch: 25, loss: 0.0019335609395056963\n",
      "epoch: 39, batch: 26, loss: 0.0022162487730383873\n",
      "epoch: 39, batch: 27, loss: 0.004492768086493015\n",
      "epoch: 39, batch: 28, loss: 1.2080914974212646\n",
      "epoch: 40, batch: 0, loss: 0.0011067730374634266\n",
      "epoch: 40, batch: 1, loss: 0.014210551977157593\n",
      "epoch: 40, batch: 2, loss: 0.028650816529989243\n",
      "epoch: 40, batch: 3, loss: 0.19867637753486633\n",
      "epoch: 40, batch: 4, loss: 0.18585574626922607\n",
      "epoch: 40, batch: 5, loss: 0.10635067522525787\n",
      "epoch: 40, batch: 6, loss: 0.2710384130477905\n",
      "epoch: 40, batch: 7, loss: 0.3547509014606476\n",
      "epoch: 40, batch: 8, loss: 0.12677612900733948\n",
      "epoch: 40, batch: 9, loss: 0.2019035667181015\n",
      "epoch: 40, batch: 10, loss: 0.16992667317390442\n",
      "epoch: 40, batch: 11, loss: 0.11289332807064056\n",
      "epoch: 40, batch: 12, loss: 0.13350747525691986\n",
      "epoch: 40, batch: 13, loss: 0.1939144730567932\n",
      "epoch: 40, batch: 14, loss: 0.17362907528877258\n",
      "epoch: 40, batch: 15, loss: 0.19300976395606995\n",
      "epoch: 40, batch: 16, loss: 0.38461339473724365\n",
      "epoch: 40, batch: 17, loss: 0.3874516487121582\n",
      "epoch: 40, batch: 18, loss: 0.084114208817482\n",
      "epoch: 40, batch: 19, loss: 0.045165471732616425\n",
      "epoch: 40, batch: 20, loss: 0.4115501344203949\n",
      "epoch: 40, batch: 21, loss: 0.24654634296894073\n",
      "epoch: 40, batch: 22, loss: 0.25372835993766785\n",
      "epoch: 40, batch: 23, loss: 0.4033469259738922\n",
      "epoch: 40, batch: 24, loss: 0.17650264501571655\n",
      "epoch: 40, batch: 25, loss: 0.16301345825195312\n",
      "epoch: 40, batch: 26, loss: 0.36772528290748596\n",
      "epoch: 40, batch: 27, loss: 0.1455295979976654\n",
      "epoch: 40, batch: 28, loss: 1.1415618658065796\n",
      "epoch: 41, batch: 0, loss: 0.2802918255329132\n",
      "epoch: 41, batch: 1, loss: 0.09123207628726959\n",
      "epoch: 41, batch: 2, loss: 0.25353342294692993\n",
      "epoch: 41, batch: 3, loss: 1.1146036386489868\n",
      "epoch: 41, batch: 4, loss: 0.2051464319229126\n",
      "epoch: 41, batch: 5, loss: 0.0698692724108696\n",
      "epoch: 41, batch: 6, loss: 0.30199524760246277\n",
      "epoch: 41, batch: 7, loss: 0.08239424973726273\n",
      "epoch: 41, batch: 8, loss: 0.2765940725803375\n",
      "epoch: 41, batch: 9, loss: 0.2634330093860626\n",
      "epoch: 41, batch: 10, loss: 0.19917821884155273\n",
      "epoch: 41, batch: 11, loss: 0.44427934288978577\n",
      "epoch: 41, batch: 12, loss: 0.14148814976215363\n",
      "epoch: 41, batch: 13, loss: 0.06162939593195915\n",
      "epoch: 41, batch: 14, loss: 0.19856968522071838\n",
      "epoch: 41, batch: 15, loss: 0.12503790855407715\n",
      "epoch: 41, batch: 16, loss: 0.35357901453971863\n",
      "epoch: 41, batch: 17, loss: 0.2614232897758484\n",
      "epoch: 41, batch: 18, loss: 0.11404972523450851\n",
      "epoch: 41, batch: 19, loss: 0.370788037776947\n",
      "epoch: 41, batch: 20, loss: 0.29287517070770264\n",
      "epoch: 41, batch: 21, loss: 0.2144743651151657\n",
      "epoch: 41, batch: 22, loss: 0.16015860438346863\n",
      "epoch: 41, batch: 23, loss: 0.08683054149150848\n",
      "epoch: 41, batch: 24, loss: 0.24314075708389282\n",
      "epoch: 41, batch: 25, loss: 0.22970770299434662\n",
      "epoch: 41, batch: 26, loss: 0.23275388777256012\n",
      "epoch: 41, batch: 27, loss: 0.15549390017986298\n",
      "epoch: 41, batch: 28, loss: 0.1210809201002121\n",
      "epoch: 42, batch: 0, loss: 0.05517878755927086\n",
      "epoch: 42, batch: 1, loss: 0.08477094024419785\n",
      "epoch: 42, batch: 2, loss: 0.12623053789138794\n",
      "epoch: 42, batch: 3, loss: 0.039987727999687195\n",
      "epoch: 42, batch: 4, loss: 0.26827165484428406\n",
      "epoch: 42, batch: 5, loss: 0.019962439313530922\n",
      "epoch: 42, batch: 6, loss: 0.1277138739824295\n",
      "epoch: 42, batch: 7, loss: 0.13714221119880676\n",
      "epoch: 42, batch: 8, loss: 0.007919604890048504\n",
      "epoch: 42, batch: 9, loss: 0.022704049944877625\n",
      "epoch: 42, batch: 10, loss: 0.024330688640475273\n",
      "epoch: 42, batch: 11, loss: 0.01545713096857071\n",
      "epoch: 42, batch: 12, loss: 0.061878103762865067\n",
      "epoch: 42, batch: 13, loss: 0.15567553043365479\n",
      "epoch: 42, batch: 14, loss: 0.15670286118984222\n",
      "epoch: 42, batch: 15, loss: 0.08140227198600769\n",
      "epoch: 42, batch: 16, loss: 0.12890085577964783\n",
      "epoch: 42, batch: 17, loss: 0.006870653480291367\n",
      "epoch: 42, batch: 18, loss: 0.12525004148483276\n",
      "epoch: 42, batch: 19, loss: 0.14785537123680115\n",
      "epoch: 42, batch: 20, loss: 0.15131038427352905\n",
      "epoch: 42, batch: 21, loss: 0.20080646872520447\n",
      "epoch: 42, batch: 22, loss: 0.020145265385508537\n",
      "epoch: 42, batch: 23, loss: 0.11074427515268326\n",
      "epoch: 42, batch: 24, loss: 0.11328249424695969\n",
      "epoch: 42, batch: 25, loss: 0.009669255465269089\n",
      "epoch: 42, batch: 26, loss: 0.06221494451165199\n",
      "epoch: 42, batch: 27, loss: 0.03836999461054802\n",
      "epoch: 42, batch: 28, loss: 0.05638212338089943\n",
      "epoch: 43, batch: 0, loss: 0.04820772260427475\n",
      "epoch: 43, batch: 1, loss: 0.012990837916731834\n",
      "epoch: 43, batch: 2, loss: 0.02655203454196453\n",
      "epoch: 43, batch: 3, loss: 0.09616999328136444\n",
      "epoch: 43, batch: 4, loss: 0.0979107916355133\n",
      "epoch: 43, batch: 5, loss: 0.009741033427417278\n",
      "epoch: 43, batch: 6, loss: 0.017099782824516296\n",
      "epoch: 43, batch: 7, loss: 0.023786334320902824\n",
      "epoch: 43, batch: 8, loss: 0.012836135923862457\n",
      "epoch: 43, batch: 9, loss: 0.01096371840685606\n",
      "epoch: 43, batch: 10, loss: 0.43457773327827454\n",
      "epoch: 43, batch: 11, loss: 0.04151158407330513\n",
      "epoch: 43, batch: 12, loss: 0.01236511766910553\n",
      "epoch: 43, batch: 13, loss: 0.02665158361196518\n",
      "epoch: 43, batch: 14, loss: 0.023435449227690697\n",
      "epoch: 43, batch: 15, loss: 0.013749607838690281\n",
      "epoch: 43, batch: 16, loss: 0.02066025882959366\n",
      "epoch: 43, batch: 17, loss: 0.017177041620016098\n",
      "epoch: 43, batch: 18, loss: 0.05273126810789108\n",
      "epoch: 43, batch: 19, loss: 0.021686330437660217\n",
      "epoch: 43, batch: 20, loss: 0.011711942963302135\n",
      "epoch: 43, batch: 21, loss: 0.020185329020023346\n",
      "epoch: 43, batch: 22, loss: 0.018093783408403397\n",
      "epoch: 43, batch: 23, loss: 0.024499211460351944\n",
      "epoch: 43, batch: 24, loss: 0.014087751507759094\n",
      "epoch: 43, batch: 25, loss: 0.007985733449459076\n",
      "epoch: 43, batch: 26, loss: 0.010314910672605038\n",
      "epoch: 43, batch: 27, loss: 0.01796279475092888\n",
      "epoch: 43, batch: 28, loss: 0.0686715692281723\n",
      "epoch: 44, batch: 0, loss: 0.0022380962036550045\n",
      "epoch: 44, batch: 1, loss: 0.007080633193254471\n",
      "epoch: 44, batch: 2, loss: 0.003637410933151841\n",
      "epoch: 44, batch: 3, loss: 0.04773486405611038\n",
      "epoch: 44, batch: 4, loss: 0.005580384284257889\n",
      "epoch: 44, batch: 5, loss: 0.0048178257420659065\n",
      "epoch: 44, batch: 6, loss: 0.010095708072185516\n",
      "epoch: 44, batch: 7, loss: 0.0023404350504279137\n",
      "epoch: 44, batch: 8, loss: 0.005722090136259794\n",
      "epoch: 44, batch: 9, loss: 0.0104295639321208\n",
      "epoch: 44, batch: 10, loss: 0.0036151320673525333\n",
      "epoch: 44, batch: 11, loss: 0.0612511970102787\n",
      "epoch: 44, batch: 12, loss: 0.0043501597829163074\n",
      "epoch: 44, batch: 13, loss: 0.005106593016535044\n",
      "epoch: 44, batch: 14, loss: 0.011800535023212433\n",
      "epoch: 44, batch: 15, loss: 0.09328379482030869\n",
      "epoch: 44, batch: 16, loss: 0.004740849137306213\n",
      "epoch: 44, batch: 17, loss: 0.039992235600948334\n",
      "epoch: 44, batch: 18, loss: 0.02626200206577778\n",
      "epoch: 44, batch: 19, loss: 0.002936638193204999\n",
      "epoch: 44, batch: 20, loss: 0.01638546958565712\n",
      "epoch: 44, batch: 21, loss: 0.07180541008710861\n",
      "epoch: 44, batch: 22, loss: 0.04222427308559418\n",
      "epoch: 44, batch: 23, loss: 0.005664374679327011\n",
      "epoch: 44, batch: 24, loss: 0.1328902393579483\n",
      "epoch: 44, batch: 25, loss: 0.010998520068824291\n",
      "epoch: 44, batch: 26, loss: 0.07802646607160568\n",
      "epoch: 44, batch: 27, loss: 0.03155339136719704\n",
      "epoch: 44, batch: 28, loss: 0.018624909222126007\n",
      "epoch: 45, batch: 0, loss: 0.009299365803599358\n",
      "epoch: 45, batch: 1, loss: 0.00759916752576828\n",
      "epoch: 45, batch: 2, loss: 0.006319335661828518\n",
      "epoch: 45, batch: 3, loss: 0.019129397347569466\n",
      "epoch: 45, batch: 4, loss: 0.015457021072506905\n",
      "epoch: 45, batch: 5, loss: 0.0016102185472846031\n",
      "epoch: 45, batch: 6, loss: 0.002565574599429965\n",
      "epoch: 45, batch: 7, loss: 0.002568321768194437\n",
      "epoch: 45, batch: 8, loss: 0.0037716792430728674\n",
      "epoch: 45, batch: 9, loss: 0.0032614890951663256\n",
      "epoch: 45, batch: 10, loss: 0.0071760243736207485\n",
      "epoch: 45, batch: 11, loss: 0.042494866997003555\n",
      "epoch: 45, batch: 12, loss: 0.028759067878127098\n",
      "epoch: 45, batch: 13, loss: 0.006361340172588825\n",
      "epoch: 45, batch: 14, loss: 0.001849150168709457\n",
      "epoch: 45, batch: 15, loss: 0.006932904478162527\n",
      "epoch: 45, batch: 16, loss: 0.005817863624542952\n",
      "epoch: 45, batch: 17, loss: 0.00505798077210784\n",
      "epoch: 45, batch: 18, loss: 0.008102376945316792\n",
      "epoch: 45, batch: 19, loss: 0.0030305192340165377\n",
      "epoch: 45, batch: 20, loss: 0.007073029410094023\n",
      "epoch: 45, batch: 21, loss: 0.011866862885653973\n",
      "epoch: 45, batch: 22, loss: 0.00845287274569273\n",
      "epoch: 45, batch: 23, loss: 0.002140990225598216\n",
      "epoch: 45, batch: 24, loss: 0.001962079433724284\n",
      "epoch: 45, batch: 25, loss: 0.002239028923213482\n",
      "epoch: 45, batch: 26, loss: 0.003463541157543659\n",
      "epoch: 45, batch: 27, loss: 0.003580833086743951\n",
      "epoch: 45, batch: 28, loss: 0.7183190584182739\n",
      "epoch: 46, batch: 0, loss: 0.002956424141302705\n",
      "epoch: 46, batch: 1, loss: 0.06279197335243225\n",
      "epoch: 46, batch: 2, loss: 0.03602048382163048\n",
      "epoch: 46, batch: 3, loss: 0.23823902010917664\n",
      "epoch: 46, batch: 4, loss: 0.07319754362106323\n",
      "epoch: 46, batch: 5, loss: 0.0409940704703331\n",
      "epoch: 46, batch: 6, loss: 0.053315531462430954\n",
      "epoch: 46, batch: 7, loss: 0.19514624774456024\n",
      "epoch: 46, batch: 8, loss: 0.24903956055641174\n",
      "epoch: 46, batch: 9, loss: 0.20725102722644806\n",
      "epoch: 46, batch: 10, loss: 0.5175800323486328\n",
      "epoch: 46, batch: 11, loss: 0.05970132723450661\n",
      "epoch: 46, batch: 12, loss: 0.16510064899921417\n",
      "epoch: 46, batch: 13, loss: 0.19015030562877655\n",
      "epoch: 46, batch: 14, loss: 0.1427438110113144\n",
      "epoch: 46, batch: 15, loss: 0.08073985576629639\n",
      "epoch: 46, batch: 16, loss: 0.211360901594162\n",
      "epoch: 46, batch: 17, loss: 0.3225443661212921\n",
      "epoch: 46, batch: 18, loss: 0.08616528660058975\n",
      "epoch: 46, batch: 19, loss: 0.06738630682229996\n",
      "epoch: 46, batch: 20, loss: 0.14626021683216095\n",
      "epoch: 46, batch: 21, loss: 0.13808687031269073\n",
      "epoch: 46, batch: 22, loss: 0.0830019935965538\n",
      "epoch: 46, batch: 23, loss: 0.08707700669765472\n",
      "epoch: 46, batch: 24, loss: 0.033186428248882294\n",
      "epoch: 46, batch: 25, loss: 0.07758631557226181\n",
      "epoch: 46, batch: 26, loss: 0.04986778646707535\n",
      "epoch: 46, batch: 27, loss: 0.29323631525039673\n",
      "epoch: 46, batch: 28, loss: 0.09282868355512619\n",
      "epoch: 47, batch: 0, loss: 0.026214132085442543\n",
      "epoch: 47, batch: 1, loss: 0.007233540993183851\n",
      "epoch: 47, batch: 2, loss: 0.06993330270051956\n",
      "epoch: 47, batch: 3, loss: 0.045908309519290924\n",
      "epoch: 47, batch: 4, loss: 0.1471450924873352\n",
      "epoch: 47, batch: 5, loss: 0.0966302752494812\n",
      "epoch: 47, batch: 6, loss: 0.02283773571252823\n",
      "epoch: 47, batch: 7, loss: 0.06625376641750336\n",
      "epoch: 47, batch: 8, loss: 0.03685693442821503\n",
      "epoch: 47, batch: 9, loss: 0.02821497432887554\n",
      "epoch: 47, batch: 10, loss: 0.02133329026401043\n",
      "epoch: 47, batch: 11, loss: 0.01369114127010107\n",
      "epoch: 47, batch: 12, loss: 0.02318667620420456\n",
      "epoch: 47, batch: 13, loss: 0.07344003021717072\n",
      "epoch: 47, batch: 14, loss: 0.14377714693546295\n",
      "epoch: 47, batch: 15, loss: 0.07534963637590408\n",
      "epoch: 47, batch: 16, loss: 0.10583564639091492\n",
      "epoch: 47, batch: 17, loss: 0.03389820083975792\n",
      "epoch: 47, batch: 18, loss: 0.09452581405639648\n",
      "epoch: 47, batch: 19, loss: 0.10626770555973053\n",
      "epoch: 47, batch: 20, loss: 0.03407340124249458\n",
      "epoch: 47, batch: 21, loss: 0.05751625820994377\n",
      "epoch: 47, batch: 22, loss: 0.05856584385037422\n",
      "epoch: 47, batch: 23, loss: 0.003952282480895519\n",
      "epoch: 47, batch: 24, loss: 0.03029879741370678\n",
      "epoch: 47, batch: 25, loss: 0.007278005592525005\n",
      "epoch: 47, batch: 26, loss: 0.0436442531645298\n",
      "epoch: 47, batch: 27, loss: 0.10105499625205994\n",
      "epoch: 47, batch: 28, loss: 0.011050384491682053\n",
      "epoch: 48, batch: 0, loss: 0.02209608443081379\n",
      "epoch: 48, batch: 1, loss: 0.004430292174220085\n",
      "epoch: 48, batch: 2, loss: 0.018717575818300247\n",
      "epoch: 48, batch: 3, loss: 0.004813346546143293\n",
      "epoch: 48, batch: 4, loss: 0.01906621642410755\n",
      "epoch: 48, batch: 5, loss: 0.028213046491146088\n",
      "epoch: 48, batch: 6, loss: 0.0955086350440979\n",
      "epoch: 48, batch: 7, loss: 0.03381611034274101\n",
      "epoch: 48, batch: 8, loss: 0.0136434156447649\n",
      "epoch: 48, batch: 9, loss: 0.041681814938783646\n",
      "epoch: 48, batch: 10, loss: 0.0022159854415804148\n",
      "epoch: 48, batch: 11, loss: 0.009243747219443321\n",
      "epoch: 48, batch: 12, loss: 0.09164219349622726\n",
      "epoch: 48, batch: 13, loss: 0.013638266362249851\n",
      "epoch: 48, batch: 14, loss: 0.004753423389047384\n",
      "epoch: 48, batch: 15, loss: 0.008486264385282993\n",
      "epoch: 48, batch: 16, loss: 0.0032757276203483343\n",
      "epoch: 48, batch: 17, loss: 0.038627706468105316\n",
      "epoch: 48, batch: 18, loss: 0.007896257564425468\n",
      "epoch: 48, batch: 19, loss: 0.005894472822546959\n",
      "epoch: 48, batch: 20, loss: 0.005257148761302233\n",
      "epoch: 48, batch: 21, loss: 0.002695100149139762\n",
      "epoch: 48, batch: 22, loss: 0.016772815957665443\n",
      "epoch: 48, batch: 23, loss: 0.003095647320151329\n",
      "epoch: 48, batch: 24, loss: 0.003911204170435667\n",
      "epoch: 48, batch: 25, loss: 0.003966385032981634\n",
      "epoch: 48, batch: 26, loss: 0.046118833124637604\n",
      "epoch: 48, batch: 27, loss: 0.01619490422308445\n",
      "epoch: 48, batch: 28, loss: 0.3180864155292511\n",
      "epoch: 49, batch: 0, loss: 0.0018794495845213532\n",
      "epoch: 49, batch: 1, loss: 0.049717050045728683\n",
      "epoch: 49, batch: 2, loss: 0.0027204786892980337\n",
      "epoch: 49, batch: 3, loss: 0.005877088755369186\n",
      "epoch: 49, batch: 4, loss: 0.008267411030828953\n",
      "epoch: 49, batch: 5, loss: 0.2849344313144684\n",
      "epoch: 49, batch: 6, loss: 0.10329069942235947\n",
      "epoch: 49, batch: 7, loss: 0.20796805620193481\n",
      "epoch: 49, batch: 8, loss: 0.01801532693207264\n",
      "epoch: 49, batch: 9, loss: 0.023898016661405563\n",
      "epoch: 49, batch: 10, loss: 0.08925604820251465\n",
      "epoch: 49, batch: 11, loss: 0.0084457416087389\n",
      "epoch: 49, batch: 12, loss: 0.004971867427229881\n",
      "epoch: 49, batch: 13, loss: 0.08714116364717484\n",
      "epoch: 49, batch: 14, loss: 0.005897401832044125\n",
      "epoch: 49, batch: 15, loss: 0.07570058107376099\n",
      "epoch: 49, batch: 16, loss: 0.021607425063848495\n",
      "epoch: 49, batch: 17, loss: 0.023526696488261223\n",
      "epoch: 49, batch: 18, loss: 0.01598607562482357\n",
      "epoch: 49, batch: 19, loss: 0.15330277383327484\n",
      "epoch: 49, batch: 20, loss: 0.06611371040344238\n",
      "epoch: 49, batch: 21, loss: 0.06823088228702545\n",
      "epoch: 49, batch: 22, loss: 0.095430888235569\n",
      "epoch: 49, batch: 23, loss: 0.04554562270641327\n",
      "epoch: 49, batch: 24, loss: 0.057952433824539185\n",
      "epoch: 49, batch: 25, loss: 0.073841392993927\n",
      "epoch: 49, batch: 26, loss: 0.08383433520793915\n",
      "epoch: 49, batch: 27, loss: 0.017970535904169083\n",
      "epoch: 49, batch: 28, loss: 0.3159930109977722\n",
      "epoch: 50, batch: 0, loss: 0.011289102956652641\n",
      "epoch: 50, batch: 1, loss: 0.02381882257759571\n",
      "epoch: 50, batch: 2, loss: 0.0037387986667454243\n",
      "epoch: 50, batch: 3, loss: 0.2226468026638031\n",
      "epoch: 50, batch: 4, loss: 0.20431774854660034\n",
      "epoch: 50, batch: 5, loss: 0.164663165807724\n",
      "epoch: 50, batch: 6, loss: 0.4682427942752838\n",
      "epoch: 50, batch: 7, loss: 0.04571833461523056\n",
      "epoch: 50, batch: 8, loss: 0.018867308273911476\n",
      "epoch: 50, batch: 9, loss: 0.0432344488799572\n",
      "epoch: 50, batch: 10, loss: 0.4183059334754944\n",
      "epoch: 50, batch: 11, loss: 0.09315519034862518\n",
      "epoch: 50, batch: 12, loss: 0.106104277074337\n",
      "epoch: 50, batch: 13, loss: 0.10511032491922379\n",
      "epoch: 50, batch: 14, loss: 0.20088492333889008\n",
      "epoch: 50, batch: 15, loss: 0.12845855951309204\n",
      "epoch: 50, batch: 16, loss: 0.05917459726333618\n",
      "epoch: 50, batch: 17, loss: 0.07534544169902802\n",
      "epoch: 50, batch: 18, loss: 0.38788825273513794\n",
      "epoch: 50, batch: 19, loss: 0.13557738065719604\n",
      "epoch: 50, batch: 20, loss: 0.28437671065330505\n",
      "epoch: 50, batch: 21, loss: 0.3347230851650238\n",
      "epoch: 50, batch: 22, loss: 0.04420303925871849\n",
      "epoch: 50, batch: 23, loss: 0.04766023904085159\n",
      "epoch: 50, batch: 24, loss: 0.05120176076889038\n",
      "epoch: 50, batch: 25, loss: 0.06862905621528625\n",
      "epoch: 50, batch: 26, loss: 0.1402422934770584\n",
      "epoch: 50, batch: 27, loss: 0.06379591673612595\n",
      "epoch: 50, batch: 28, loss: 0.022886021062731743\n",
      "epoch: 51, batch: 0, loss: 0.01825249195098877\n",
      "epoch: 51, batch: 1, loss: 0.15331144630908966\n",
      "epoch: 51, batch: 2, loss: 0.04876469075679779\n",
      "epoch: 51, batch: 3, loss: 0.10305041074752808\n",
      "epoch: 51, batch: 4, loss: 0.03337135910987854\n",
      "epoch: 51, batch: 5, loss: 0.05436696484684944\n",
      "epoch: 51, batch: 6, loss: 0.03191707655787468\n",
      "epoch: 51, batch: 7, loss: 0.04130052775144577\n",
      "epoch: 51, batch: 8, loss: 0.03721703216433525\n",
      "epoch: 51, batch: 9, loss: 0.030075376853346825\n",
      "epoch: 51, batch: 10, loss: 0.0041363537311553955\n",
      "epoch: 51, batch: 11, loss: 0.021439187228679657\n",
      "epoch: 51, batch: 12, loss: 0.05403094366192818\n",
      "epoch: 51, batch: 13, loss: 0.012658575549721718\n",
      "epoch: 51, batch: 14, loss: 0.008028390817344189\n",
      "epoch: 51, batch: 15, loss: 0.056529104709625244\n",
      "epoch: 51, batch: 16, loss: 0.12555311620235443\n",
      "epoch: 51, batch: 17, loss: 0.02605854719877243\n",
      "epoch: 51, batch: 18, loss: 0.006210928782820702\n",
      "epoch: 51, batch: 19, loss: 0.0073906369507312775\n",
      "epoch: 51, batch: 20, loss: 0.04276307299733162\n",
      "epoch: 51, batch: 21, loss: 0.009415517561137676\n",
      "epoch: 51, batch: 22, loss: 0.006933131255209446\n",
      "epoch: 51, batch: 23, loss: 0.07440214604139328\n",
      "epoch: 51, batch: 24, loss: 0.044762127101421356\n",
      "epoch: 51, batch: 25, loss: 0.005640511400997639\n",
      "epoch: 51, batch: 26, loss: 0.033640116453170776\n",
      "epoch: 51, batch: 27, loss: 0.0031835283152759075\n",
      "epoch: 51, batch: 28, loss: 0.28854289650917053\n",
      "epoch: 52, batch: 0, loss: 0.003618083195760846\n",
      "epoch: 52, batch: 1, loss: 0.0026002791710197926\n",
      "epoch: 52, batch: 2, loss: 0.0643036887049675\n",
      "epoch: 52, batch: 3, loss: 0.01261513214558363\n",
      "epoch: 52, batch: 4, loss: 0.0373971052467823\n",
      "epoch: 52, batch: 5, loss: 0.06797776371240616\n",
      "epoch: 52, batch: 6, loss: 0.06631265580654144\n",
      "epoch: 52, batch: 7, loss: 0.15660318732261658\n",
      "epoch: 52, batch: 8, loss: 0.005861365236341953\n",
      "epoch: 52, batch: 9, loss: 0.03493758291006088\n",
      "epoch: 52, batch: 10, loss: 0.02496504969894886\n",
      "epoch: 52, batch: 11, loss: 0.007832355797290802\n",
      "epoch: 52, batch: 12, loss: 0.060580577701330185\n",
      "epoch: 52, batch: 13, loss: 0.05259360000491142\n",
      "epoch: 52, batch: 14, loss: 0.26771119236946106\n",
      "epoch: 52, batch: 15, loss: 0.08342237770557404\n",
      "epoch: 52, batch: 16, loss: 0.004965342115610838\n",
      "epoch: 52, batch: 17, loss: 0.07036352157592773\n",
      "epoch: 52, batch: 18, loss: 0.0552067831158638\n",
      "epoch: 52, batch: 19, loss: 0.008861355483531952\n",
      "epoch: 52, batch: 20, loss: 0.005102099385112524\n",
      "epoch: 52, batch: 21, loss: 0.051723841577768326\n",
      "epoch: 52, batch: 22, loss: 0.12189185619354248\n",
      "epoch: 52, batch: 23, loss: 0.02518455684185028\n",
      "epoch: 52, batch: 24, loss: 0.004394561052322388\n",
      "epoch: 52, batch: 25, loss: 0.10195234417915344\n",
      "epoch: 52, batch: 26, loss: 0.011034974828362465\n",
      "epoch: 52, batch: 27, loss: 0.005518245045095682\n",
      "epoch: 52, batch: 28, loss: 0.0006892804522067308\n",
      "epoch: 53, batch: 0, loss: 0.0029210401698946953\n",
      "epoch: 53, batch: 1, loss: 0.005890283267945051\n",
      "epoch: 53, batch: 2, loss: 0.0019409933593124151\n",
      "epoch: 53, batch: 3, loss: 0.005943604279309511\n",
      "epoch: 53, batch: 4, loss: 0.006066884379833937\n",
      "epoch: 53, batch: 5, loss: 0.005619705189019442\n",
      "epoch: 53, batch: 6, loss: 0.00497504323720932\n",
      "epoch: 53, batch: 7, loss: 0.004669510759413242\n",
      "epoch: 53, batch: 8, loss: 0.005692634265869856\n",
      "epoch: 53, batch: 9, loss: 0.008137261494994164\n",
      "epoch: 53, batch: 10, loss: 0.006608685478568077\n",
      "epoch: 53, batch: 11, loss: 0.0023100844118744135\n",
      "epoch: 53, batch: 12, loss: 0.011020167730748653\n",
      "epoch: 53, batch: 13, loss: 0.023835811764001846\n",
      "epoch: 53, batch: 14, loss: 0.0015972880646586418\n",
      "epoch: 53, batch: 15, loss: 0.0048842765390872955\n",
      "epoch: 53, batch: 16, loss: 0.007105145137757063\n",
      "epoch: 53, batch: 17, loss: 0.004542277194559574\n",
      "epoch: 53, batch: 18, loss: 0.0035134463105350733\n",
      "epoch: 53, batch: 19, loss: 0.023367704823613167\n",
      "epoch: 53, batch: 20, loss: 0.12748408317565918\n",
      "epoch: 53, batch: 21, loss: 0.015696492046117783\n",
      "epoch: 53, batch: 22, loss: 0.0018068761564791203\n",
      "epoch: 53, batch: 23, loss: 0.0013980596559122205\n",
      "epoch: 53, batch: 24, loss: 0.01620936207473278\n",
      "epoch: 53, batch: 25, loss: 0.023448267951607704\n",
      "epoch: 53, batch: 26, loss: 0.0031595216132700443\n",
      "epoch: 53, batch: 27, loss: 0.0055104517377913\n",
      "epoch: 53, batch: 28, loss: 0.6660029888153076\n",
      "epoch: 54, batch: 0, loss: 0.0006668849964626133\n",
      "epoch: 54, batch: 1, loss: 0.02080756612122059\n",
      "epoch: 54, batch: 2, loss: 0.01518941018730402\n",
      "epoch: 54, batch: 3, loss: 0.1336955726146698\n",
      "epoch: 54, batch: 4, loss: 0.007205364294350147\n",
      "epoch: 54, batch: 5, loss: 0.020843707025051117\n",
      "epoch: 54, batch: 6, loss: 0.08619038015604019\n",
      "epoch: 54, batch: 7, loss: 0.03609985485672951\n",
      "epoch: 54, batch: 8, loss: 0.057760342955589294\n",
      "epoch: 54, batch: 9, loss: 0.4301770329475403\n",
      "epoch: 54, batch: 10, loss: 0.09583619982004166\n",
      "epoch: 54, batch: 11, loss: 0.15422143042087555\n",
      "epoch: 54, batch: 12, loss: 0.21972866356372833\n",
      "epoch: 54, batch: 13, loss: 0.09187224507331848\n",
      "epoch: 54, batch: 14, loss: 0.020869247615337372\n",
      "epoch: 54, batch: 15, loss: 0.03458046913146973\n",
      "epoch: 54, batch: 16, loss: 0.029859071597456932\n",
      "epoch: 54, batch: 17, loss: 0.10624760389328003\n",
      "epoch: 54, batch: 18, loss: 0.20113499462604523\n",
      "epoch: 54, batch: 19, loss: 0.03469965606927872\n",
      "epoch: 54, batch: 20, loss: 0.1392187625169754\n",
      "epoch: 54, batch: 21, loss: 0.0915895327925682\n",
      "epoch: 54, batch: 22, loss: 0.08297964185476303\n",
      "epoch: 54, batch: 23, loss: 0.05139806866645813\n",
      "epoch: 54, batch: 24, loss: 0.04897545650601387\n",
      "epoch: 54, batch: 25, loss: 0.019473299384117126\n",
      "epoch: 54, batch: 26, loss: 0.05485904589295387\n",
      "epoch: 54, batch: 27, loss: 0.057113151997327805\n",
      "epoch: 54, batch: 28, loss: 0.7618160843849182\n",
      "epoch: 55, batch: 0, loss: 0.028760172426700592\n",
      "epoch: 55, batch: 1, loss: 0.09397734701633453\n",
      "epoch: 55, batch: 2, loss: 0.28635716438293457\n",
      "epoch: 55, batch: 3, loss: 0.11464875191450119\n",
      "epoch: 55, batch: 4, loss: 0.166251540184021\n",
      "epoch: 55, batch: 5, loss: 0.2529626190662384\n",
      "epoch: 55, batch: 6, loss: 0.07726045697927475\n",
      "epoch: 55, batch: 7, loss: 0.30459126830101013\n",
      "epoch: 55, batch: 8, loss: 0.18186905980110168\n",
      "epoch: 55, batch: 9, loss: 0.1837296336889267\n",
      "epoch: 55, batch: 10, loss: 0.02006308175623417\n",
      "epoch: 55, batch: 11, loss: 0.3201999068260193\n",
      "epoch: 55, batch: 12, loss: 0.01994411274790764\n",
      "epoch: 55, batch: 13, loss: 0.14128386974334717\n",
      "epoch: 55, batch: 14, loss: 0.1999598741531372\n",
      "epoch: 55, batch: 15, loss: 0.031575821340084076\n",
      "epoch: 55, batch: 16, loss: 0.08330168575048447\n",
      "epoch: 55, batch: 17, loss: 0.33777809143066406\n",
      "epoch: 55, batch: 18, loss: 0.16962380707263947\n",
      "epoch: 55, batch: 19, loss: 0.11424844712018967\n",
      "epoch: 55, batch: 20, loss: 0.08727146685123444\n",
      "epoch: 55, batch: 21, loss: 0.1138104572892189\n",
      "epoch: 55, batch: 22, loss: 0.11501915007829666\n",
      "epoch: 55, batch: 23, loss: 0.00606187991797924\n",
      "epoch: 55, batch: 24, loss: 0.07036788761615753\n",
      "epoch: 55, batch: 25, loss: 0.025381037965416908\n",
      "epoch: 55, batch: 26, loss: 0.0703381821513176\n",
      "epoch: 55, batch: 27, loss: 0.08665478229522705\n",
      "epoch: 55, batch: 28, loss: 0.1917603462934494\n",
      "epoch: 56, batch: 0, loss: 0.009057097136974335\n",
      "epoch: 56, batch: 1, loss: 0.02868065983057022\n",
      "epoch: 56, batch: 2, loss: 0.05179192125797272\n",
      "epoch: 56, batch: 3, loss: 0.013130665756762028\n",
      "epoch: 56, batch: 4, loss: 0.07926516979932785\n",
      "epoch: 56, batch: 5, loss: 0.17555390298366547\n",
      "epoch: 56, batch: 6, loss: 0.06141344830393791\n",
      "epoch: 56, batch: 7, loss: 0.0995221883058548\n",
      "epoch: 56, batch: 8, loss: 0.037345997989177704\n",
      "epoch: 56, batch: 9, loss: 0.056733034551143646\n",
      "epoch: 56, batch: 10, loss: 0.34768861532211304\n",
      "epoch: 56, batch: 11, loss: 0.03155931830406189\n",
      "epoch: 56, batch: 12, loss: 0.030617309734225273\n",
      "epoch: 56, batch: 13, loss: 0.008517161943018436\n",
      "epoch: 56, batch: 14, loss: 0.1309080868959427\n",
      "epoch: 56, batch: 15, loss: 0.03037033975124359\n",
      "epoch: 56, batch: 16, loss: 0.0741429254412651\n",
      "epoch: 56, batch: 17, loss: 0.02251925691962242\n",
      "epoch: 56, batch: 18, loss: 0.13072633743286133\n",
      "epoch: 56, batch: 19, loss: 0.025852112099528313\n",
      "epoch: 56, batch: 20, loss: 0.0700584352016449\n",
      "epoch: 56, batch: 21, loss: 0.03215384483337402\n",
      "epoch: 56, batch: 22, loss: 0.007951599545776844\n",
      "epoch: 56, batch: 23, loss: 0.08539614081382751\n",
      "epoch: 56, batch: 24, loss: 0.16414958238601685\n",
      "epoch: 56, batch: 25, loss: 0.023555640131235123\n",
      "epoch: 56, batch: 26, loss: 0.03454766049981117\n",
      "epoch: 56, batch: 27, loss: 0.009439817629754543\n",
      "epoch: 56, batch: 28, loss: 0.012600630521774292\n",
      "epoch: 57, batch: 0, loss: 0.017541037872433662\n",
      "epoch: 57, batch: 1, loss: 0.11584445834159851\n",
      "epoch: 57, batch: 2, loss: 0.02243095450103283\n",
      "epoch: 57, batch: 3, loss: 0.00820743665099144\n",
      "epoch: 57, batch: 4, loss: 0.018472978845238686\n",
      "epoch: 57, batch: 5, loss: 0.016446955502033234\n",
      "epoch: 57, batch: 6, loss: 0.06721728295087814\n",
      "epoch: 57, batch: 7, loss: 0.024646159261465073\n",
      "epoch: 57, batch: 8, loss: 0.008401434868574142\n",
      "epoch: 57, batch: 9, loss: 0.06090124323964119\n",
      "epoch: 57, batch: 10, loss: 0.0072108120657503605\n",
      "epoch: 57, batch: 11, loss: 0.006820141803473234\n",
      "epoch: 57, batch: 12, loss: 0.005922134965658188\n",
      "epoch: 57, batch: 13, loss: 0.005833924748003483\n",
      "epoch: 57, batch: 14, loss: 0.04614616930484772\n",
      "epoch: 57, batch: 15, loss: 0.003708438016474247\n",
      "epoch: 57, batch: 16, loss: 0.006287489086389542\n",
      "epoch: 57, batch: 17, loss: 0.011230075731873512\n",
      "epoch: 57, batch: 18, loss: 0.003352109109982848\n",
      "epoch: 57, batch: 19, loss: 0.058427974581718445\n",
      "epoch: 57, batch: 20, loss: 0.0037335173692554235\n",
      "epoch: 57, batch: 21, loss: 0.01761140115559101\n",
      "epoch: 57, batch: 22, loss: 0.005211980082094669\n",
      "epoch: 57, batch: 23, loss: 0.006160121876746416\n",
      "epoch: 57, batch: 24, loss: 0.017946211621165276\n",
      "epoch: 57, batch: 25, loss: 0.007865420542657375\n",
      "epoch: 57, batch: 26, loss: 0.06166141480207443\n",
      "epoch: 57, batch: 27, loss: 0.036508698016405106\n",
      "epoch: 57, batch: 28, loss: 0.4576528072357178\n",
      "epoch: 58, batch: 0, loss: 0.005002136807888746\n",
      "epoch: 58, batch: 1, loss: 0.004156595561653376\n",
      "epoch: 58, batch: 2, loss: 0.2950010895729065\n",
      "epoch: 58, batch: 3, loss: 0.12357909977436066\n",
      "epoch: 58, batch: 4, loss: 0.03360564634203911\n",
      "epoch: 58, batch: 5, loss: 0.3005332946777344\n",
      "epoch: 58, batch: 6, loss: 0.22170495986938477\n",
      "epoch: 58, batch: 7, loss: 0.1257825344800949\n",
      "epoch: 58, batch: 8, loss: 0.16478735208511353\n",
      "epoch: 58, batch: 9, loss: 0.012099329382181168\n",
      "epoch: 58, batch: 10, loss: 0.035532258450984955\n",
      "epoch: 58, batch: 11, loss: 0.025116844102740288\n",
      "epoch: 58, batch: 12, loss: 0.05714884400367737\n",
      "epoch: 58, batch: 13, loss: 0.04317334294319153\n",
      "epoch: 58, batch: 14, loss: 0.02243264764547348\n",
      "epoch: 58, batch: 15, loss: 0.20882515609264374\n",
      "epoch: 58, batch: 16, loss: 0.11305958032608032\n",
      "epoch: 58, batch: 17, loss: 0.08987242728471756\n",
      "epoch: 58, batch: 18, loss: 0.10446956753730774\n",
      "epoch: 58, batch: 19, loss: 0.014157078228890896\n",
      "epoch: 58, batch: 20, loss: 0.01517908088862896\n",
      "epoch: 58, batch: 21, loss: 0.13296663761138916\n",
      "epoch: 58, batch: 22, loss: 0.22760537266731262\n",
      "epoch: 58, batch: 23, loss: 0.026563899591565132\n",
      "epoch: 58, batch: 24, loss: 0.08302338421344757\n",
      "epoch: 58, batch: 25, loss: 0.003402957459911704\n",
      "epoch: 58, batch: 26, loss: 0.024168476462364197\n",
      "epoch: 58, batch: 27, loss: 0.05250873789191246\n",
      "epoch: 58, batch: 28, loss: 2.1745941638946533\n",
      "epoch: 59, batch: 0, loss: 0.008761966601014137\n",
      "epoch: 59, batch: 1, loss: 0.0638897567987442\n",
      "epoch: 59, batch: 2, loss: 0.2230639010667801\n",
      "epoch: 59, batch: 3, loss: 0.19486644864082336\n",
      "epoch: 59, batch: 4, loss: 0.24399544298648834\n",
      "epoch: 59, batch: 5, loss: 0.420074999332428\n",
      "epoch: 59, batch: 6, loss: 0.30046597123146057\n",
      "epoch: 59, batch: 7, loss: 0.15656445920467377\n",
      "epoch: 59, batch: 8, loss: 0.4893321990966797\n",
      "epoch: 59, batch: 9, loss: 0.29750844836235046\n",
      "epoch: 59, batch: 10, loss: 0.10106658190488815\n",
      "epoch: 59, batch: 11, loss: 0.17783524096012115\n",
      "epoch: 59, batch: 12, loss: 0.47973594069480896\n",
      "epoch: 59, batch: 13, loss: 0.1817389726638794\n",
      "epoch: 59, batch: 14, loss: 0.1769673228263855\n",
      "epoch: 59, batch: 15, loss: 0.11333844065666199\n",
      "epoch: 59, batch: 16, loss: 0.4449022710323334\n",
      "epoch: 59, batch: 17, loss: 0.22626365721225739\n",
      "epoch: 59, batch: 18, loss: 0.6146852970123291\n",
      "epoch: 59, batch: 19, loss: 0.17352703213691711\n",
      "epoch: 59, batch: 20, loss: 0.08653178811073303\n",
      "epoch: 59, batch: 21, loss: 0.16362734138965607\n",
      "epoch: 59, batch: 22, loss: 0.08044249564409256\n",
      "epoch: 59, batch: 23, loss: 0.13415157794952393\n",
      "epoch: 59, batch: 24, loss: 0.05273108929395676\n",
      "epoch: 59, batch: 25, loss: 0.10753842443227768\n",
      "epoch: 59, batch: 26, loss: 0.11730365455150604\n",
      "epoch: 59, batch: 27, loss: 0.09894351661205292\n",
      "epoch: 59, batch: 28, loss: 0.2003142386674881\n",
      "epoch: 60, batch: 0, loss: 0.23447273671627045\n",
      "epoch: 60, batch: 1, loss: 0.1206430047750473\n",
      "epoch: 60, batch: 2, loss: 0.1576870232820511\n",
      "epoch: 60, batch: 3, loss: 0.05446469411253929\n",
      "epoch: 60, batch: 4, loss: 0.047926921397447586\n",
      "epoch: 60, batch: 5, loss: 0.03010677732527256\n",
      "epoch: 60, batch: 6, loss: 0.030360672622919083\n",
      "epoch: 60, batch: 7, loss: 0.1569739133119583\n",
      "epoch: 60, batch: 8, loss: 0.03575913980603218\n",
      "epoch: 60, batch: 9, loss: 0.017869047820568085\n",
      "epoch: 60, batch: 10, loss: 0.00964154489338398\n",
      "epoch: 60, batch: 11, loss: 0.03931521251797676\n",
      "epoch: 60, batch: 12, loss: 0.013131709769368172\n",
      "epoch: 60, batch: 13, loss: 0.2078288495540619\n",
      "epoch: 60, batch: 14, loss: 0.006036465056240559\n",
      "epoch: 60, batch: 15, loss: 0.057631947100162506\n",
      "epoch: 60, batch: 16, loss: 0.013143663294613361\n",
      "epoch: 60, batch: 17, loss: 0.01887216605246067\n",
      "epoch: 60, batch: 18, loss: 0.264845609664917\n",
      "epoch: 60, batch: 19, loss: 0.18492580950260162\n",
      "epoch: 60, batch: 20, loss: 0.05585628002882004\n",
      "epoch: 60, batch: 21, loss: 0.05298919603228569\n",
      "epoch: 60, batch: 22, loss: 0.06216536834836006\n",
      "epoch: 60, batch: 23, loss: 0.03954945132136345\n",
      "epoch: 60, batch: 24, loss: 0.09168098866939545\n",
      "epoch: 60, batch: 25, loss: 0.06877440959215164\n",
      "epoch: 60, batch: 26, loss: 0.09269078075885773\n",
      "epoch: 60, batch: 27, loss: 0.023594049736857414\n",
      "epoch: 60, batch: 28, loss: 0.0923922210931778\n",
      "epoch: 61, batch: 0, loss: 0.02368689328432083\n",
      "epoch: 61, batch: 1, loss: 0.016160372644662857\n",
      "epoch: 61, batch: 2, loss: 0.006143943406641483\n",
      "epoch: 61, batch: 3, loss: 0.00741599639877677\n",
      "epoch: 61, batch: 4, loss: 0.029568245634436607\n",
      "epoch: 61, batch: 5, loss: 0.04747621715068817\n",
      "epoch: 61, batch: 6, loss: 0.012892789207398891\n",
      "epoch: 61, batch: 7, loss: 0.006980348844081163\n",
      "epoch: 61, batch: 8, loss: 0.003854215843603015\n",
      "epoch: 61, batch: 9, loss: 0.08602958917617798\n",
      "epoch: 61, batch: 10, loss: 0.004297888372093439\n",
      "epoch: 61, batch: 11, loss: 0.05570223554968834\n",
      "epoch: 61, batch: 12, loss: 0.25582829117774963\n",
      "epoch: 61, batch: 13, loss: 0.03754483163356781\n",
      "epoch: 61, batch: 14, loss: 0.08303684741258621\n",
      "epoch: 61, batch: 15, loss: 0.010626733303070068\n",
      "epoch: 61, batch: 16, loss: 0.02678985893726349\n",
      "epoch: 61, batch: 17, loss: 0.006114868447184563\n",
      "epoch: 61, batch: 18, loss: 0.012272398918867111\n",
      "epoch: 61, batch: 19, loss: 0.003226175671443343\n",
      "epoch: 61, batch: 20, loss: 0.004553343169391155\n",
      "epoch: 61, batch: 21, loss: 0.017895519733428955\n",
      "epoch: 61, batch: 22, loss: 0.018796877935528755\n",
      "epoch: 61, batch: 23, loss: 0.05482795089483261\n",
      "epoch: 61, batch: 24, loss: 0.08157975971698761\n",
      "epoch: 61, batch: 25, loss: 0.013046381063759327\n",
      "epoch: 61, batch: 26, loss: 0.0035507138818502426\n",
      "epoch: 61, batch: 27, loss: 0.0024209623225033283\n",
      "epoch: 61, batch: 28, loss: 0.007225445471704006\n",
      "epoch: 62, batch: 0, loss: 0.003403556765988469\n",
      "epoch: 62, batch: 1, loss: 0.0035421603824943304\n",
      "epoch: 62, batch: 2, loss: 0.01488896831870079\n",
      "epoch: 62, batch: 3, loss: 0.005003179423511028\n",
      "epoch: 62, batch: 4, loss: 0.014024692587554455\n",
      "epoch: 62, batch: 5, loss: 0.0022170799784362316\n",
      "epoch: 62, batch: 6, loss: 0.002510984428226948\n",
      "epoch: 62, batch: 7, loss: 0.001207261928357184\n",
      "epoch: 62, batch: 8, loss: 0.003011690452694893\n",
      "epoch: 62, batch: 9, loss: 0.003053057473152876\n",
      "epoch: 62, batch: 10, loss: 0.008794505149126053\n",
      "epoch: 62, batch: 11, loss: 0.08876139670610428\n",
      "epoch: 62, batch: 12, loss: 0.0029905594419687986\n",
      "epoch: 62, batch: 13, loss: 0.009988946840167046\n",
      "epoch: 62, batch: 14, loss: 0.004808055702596903\n",
      "epoch: 62, batch: 15, loss: 0.00243677431717515\n",
      "epoch: 62, batch: 16, loss: 0.01255636103451252\n",
      "epoch: 62, batch: 17, loss: 0.0011285529471933842\n",
      "epoch: 62, batch: 18, loss: 0.015862464904785156\n",
      "epoch: 62, batch: 19, loss: 0.0020645069889724255\n",
      "epoch: 62, batch: 20, loss: 0.005478926468640566\n",
      "epoch: 62, batch: 21, loss: 0.0014892296167090535\n",
      "epoch: 62, batch: 22, loss: 0.11924656480550766\n",
      "epoch: 62, batch: 23, loss: 0.01246495358645916\n",
      "epoch: 62, batch: 24, loss: 0.0030435228254646063\n",
      "epoch: 62, batch: 25, loss: 0.0018531912937760353\n",
      "epoch: 62, batch: 26, loss: 0.0015071911038830876\n",
      "epoch: 62, batch: 27, loss: 0.0009677161579020321\n",
      "epoch: 62, batch: 28, loss: 0.0706128180027008\n",
      "epoch: 63, batch: 0, loss: 0.003589881816878915\n",
      "epoch: 63, batch: 1, loss: 0.005503717809915543\n",
      "epoch: 63, batch: 2, loss: 0.002107424195855856\n",
      "epoch: 63, batch: 3, loss: 0.0034162988886237144\n",
      "epoch: 63, batch: 4, loss: 0.004346393048763275\n",
      "epoch: 63, batch: 5, loss: 0.008319329470396042\n",
      "epoch: 63, batch: 6, loss: 0.002029110910370946\n",
      "epoch: 63, batch: 7, loss: 0.004706273321062326\n",
      "epoch: 63, batch: 8, loss: 0.04221922531723976\n",
      "epoch: 63, batch: 9, loss: 0.1166226714849472\n",
      "epoch: 63, batch: 10, loss: 0.005754279438406229\n",
      "epoch: 63, batch: 11, loss: 0.0024555569980293512\n",
      "epoch: 63, batch: 12, loss: 0.014275448396801949\n",
      "epoch: 63, batch: 13, loss: 0.002424983773380518\n",
      "epoch: 63, batch: 14, loss: 0.0012872865190729499\n",
      "epoch: 63, batch: 15, loss: 0.0030848125461488962\n",
      "epoch: 63, batch: 16, loss: 0.004602786619216204\n",
      "epoch: 63, batch: 17, loss: 0.03873428329825401\n",
      "epoch: 63, batch: 18, loss: 0.02699739672243595\n",
      "epoch: 63, batch: 19, loss: 0.051924820989370346\n",
      "epoch: 63, batch: 20, loss: 0.0018745511770248413\n",
      "epoch: 63, batch: 21, loss: 0.006723953410983086\n",
      "epoch: 63, batch: 22, loss: 0.004746072925627232\n",
      "epoch: 63, batch: 23, loss: 0.0031305430456995964\n",
      "epoch: 63, batch: 24, loss: 0.018121860921382904\n",
      "epoch: 63, batch: 25, loss: 0.003403958398848772\n",
      "epoch: 63, batch: 26, loss: 0.004016157705336809\n",
      "epoch: 63, batch: 27, loss: 0.02104215696454048\n",
      "epoch: 63, batch: 28, loss: 0.020029336214065552\n",
      "epoch: 64, batch: 0, loss: 0.001441670348867774\n",
      "epoch: 64, batch: 1, loss: 0.006424342282116413\n",
      "epoch: 64, batch: 2, loss: 0.008859953843057156\n",
      "epoch: 64, batch: 3, loss: 0.004763891454786062\n",
      "epoch: 64, batch: 4, loss: 0.02837355062365532\n",
      "epoch: 64, batch: 5, loss: 0.003879708703607321\n",
      "epoch: 64, batch: 6, loss: 0.0020705736242234707\n",
      "epoch: 64, batch: 7, loss: 0.0039244117215275764\n",
      "epoch: 64, batch: 8, loss: 0.0014057389926165342\n",
      "epoch: 64, batch: 9, loss: 0.0318542942404747\n",
      "epoch: 64, batch: 10, loss: 0.001460885046981275\n",
      "epoch: 64, batch: 11, loss: 0.00678366981446743\n",
      "epoch: 64, batch: 12, loss: 0.0017728963866829872\n",
      "epoch: 64, batch: 13, loss: 0.0037523051723837852\n",
      "epoch: 64, batch: 14, loss: 0.002988704713061452\n",
      "epoch: 64, batch: 15, loss: 0.004860679153352976\n",
      "epoch: 64, batch: 16, loss: 0.006452037487179041\n",
      "epoch: 64, batch: 17, loss: 0.0015399453695863485\n",
      "epoch: 64, batch: 18, loss: 0.002225588308647275\n",
      "epoch: 64, batch: 19, loss: 0.001716237049549818\n",
      "epoch: 64, batch: 20, loss: 0.002028858521953225\n",
      "epoch: 64, batch: 21, loss: 0.0008007250144146383\n",
      "epoch: 64, batch: 22, loss: 0.003406178206205368\n",
      "epoch: 64, batch: 23, loss: 0.0015607894165441394\n",
      "epoch: 64, batch: 24, loss: 0.0008882963447831571\n",
      "epoch: 64, batch: 25, loss: 0.012190253473818302\n",
      "epoch: 64, batch: 26, loss: 0.002060790080577135\n",
      "epoch: 64, batch: 27, loss: 0.006497519090771675\n",
      "epoch: 64, batch: 28, loss: 0.06654208898544312\n",
      "epoch: 65, batch: 0, loss: 0.00028391199884936213\n",
      "epoch: 65, batch: 1, loss: 0.0004750097286887467\n",
      "epoch: 65, batch: 2, loss: 0.001055086962878704\n",
      "epoch: 65, batch: 3, loss: 0.0005740871420130134\n",
      "epoch: 65, batch: 4, loss: 0.0013946605613455176\n",
      "epoch: 65, batch: 5, loss: 0.0009624162339605391\n",
      "epoch: 65, batch: 6, loss: 0.004332571290433407\n",
      "epoch: 65, batch: 7, loss: 0.001220498001202941\n",
      "epoch: 65, batch: 8, loss: 0.0021352767944335938\n",
      "epoch: 65, batch: 9, loss: 0.0020259965676814318\n",
      "epoch: 65, batch: 10, loss: 0.008805385790765285\n",
      "epoch: 65, batch: 11, loss: 0.0006871983059681952\n",
      "epoch: 65, batch: 12, loss: 0.001001983298920095\n",
      "epoch: 65, batch: 13, loss: 0.050534289330244064\n",
      "epoch: 65, batch: 14, loss: 0.01906954124569893\n",
      "epoch: 65, batch: 15, loss: 0.04061325639486313\n",
      "epoch: 65, batch: 16, loss: 0.01302835438400507\n",
      "epoch: 65, batch: 17, loss: 0.0010297392727807164\n",
      "epoch: 65, batch: 18, loss: 0.0028785844333469868\n",
      "epoch: 65, batch: 19, loss: 0.001343784388154745\n",
      "epoch: 65, batch: 20, loss: 0.0031952117569744587\n",
      "epoch: 65, batch: 21, loss: 0.00491596944630146\n",
      "epoch: 65, batch: 22, loss: 0.0008385384571738541\n",
      "epoch: 65, batch: 23, loss: 0.001758553204126656\n",
      "epoch: 65, batch: 24, loss: 0.04288068041205406\n",
      "epoch: 65, batch: 25, loss: 0.002040485618636012\n",
      "epoch: 65, batch: 26, loss: 0.004427870735526085\n",
      "epoch: 65, batch: 27, loss: 0.002839456545189023\n",
      "epoch: 65, batch: 28, loss: 1.219726324081421\n",
      "epoch: 66, batch: 0, loss: 0.03508579730987549\n",
      "epoch: 66, batch: 1, loss: 0.004088331945240498\n",
      "epoch: 66, batch: 2, loss: 0.009322432801127434\n",
      "epoch: 66, batch: 3, loss: 0.3943551778793335\n",
      "epoch: 66, batch: 4, loss: 0.20671358704566956\n",
      "epoch: 66, batch: 5, loss: 0.07402287423610687\n",
      "epoch: 66, batch: 6, loss: 0.7052834033966064\n",
      "epoch: 66, batch: 7, loss: 0.6713177561759949\n",
      "epoch: 66, batch: 8, loss: 0.9399605989456177\n",
      "epoch: 66, batch: 9, loss: 0.34910669922828674\n",
      "epoch: 66, batch: 10, loss: 0.07126934826374054\n",
      "epoch: 66, batch: 11, loss: 0.05071331933140755\n",
      "epoch: 66, batch: 12, loss: 0.16718804836273193\n",
      "epoch: 66, batch: 13, loss: 0.23811699450016022\n",
      "epoch: 66, batch: 14, loss: 0.23696967959403992\n",
      "epoch: 66, batch: 15, loss: 0.5893856287002563\n",
      "epoch: 66, batch: 16, loss: 0.44729840755462646\n",
      "epoch: 66, batch: 17, loss: 0.20746366679668427\n",
      "epoch: 66, batch: 18, loss: 0.13550616800785065\n",
      "epoch: 66, batch: 19, loss: 0.027642233297228813\n",
      "epoch: 66, batch: 20, loss: 0.3112729787826538\n",
      "epoch: 66, batch: 21, loss: 0.4288340210914612\n",
      "epoch: 66, batch: 22, loss: 0.2695309519767761\n",
      "epoch: 66, batch: 23, loss: 0.345425009727478\n",
      "epoch: 66, batch: 24, loss: 0.09830597043037415\n",
      "epoch: 66, batch: 25, loss: 0.11896643787622452\n",
      "epoch: 66, batch: 26, loss: 0.11816775798797607\n",
      "epoch: 66, batch: 27, loss: 0.11071114242076874\n",
      "epoch: 66, batch: 28, loss: 0.378139853477478\n",
      "epoch: 67, batch: 0, loss: 0.15138955414295197\n",
      "epoch: 67, batch: 1, loss: 0.0250313151627779\n",
      "epoch: 67, batch: 2, loss: 0.02788437157869339\n",
      "epoch: 67, batch: 3, loss: 0.08095035701990128\n",
      "epoch: 67, batch: 4, loss: 0.15913867950439453\n",
      "epoch: 67, batch: 5, loss: 0.22423294186592102\n",
      "epoch: 67, batch: 6, loss: 0.12097226828336716\n",
      "epoch: 67, batch: 7, loss: 0.054802920669317245\n",
      "epoch: 67, batch: 8, loss: 0.42805808782577515\n",
      "epoch: 67, batch: 9, loss: 0.15675655007362366\n",
      "epoch: 67, batch: 10, loss: 0.05901449918746948\n",
      "epoch: 67, batch: 11, loss: 0.03073069266974926\n",
      "epoch: 67, batch: 12, loss: 0.10867747664451599\n",
      "epoch: 67, batch: 13, loss: 0.08129174262285233\n",
      "epoch: 67, batch: 14, loss: 0.25848594307899475\n",
      "epoch: 67, batch: 15, loss: 0.1739729940891266\n",
      "epoch: 67, batch: 16, loss: 0.0508439838886261\n",
      "epoch: 67, batch: 17, loss: 0.11283688992261887\n",
      "epoch: 67, batch: 18, loss: 0.04166029021143913\n",
      "epoch: 67, batch: 19, loss: 0.24955637753009796\n",
      "epoch: 67, batch: 20, loss: 0.2659090459346771\n",
      "epoch: 67, batch: 21, loss: 0.14103323221206665\n",
      "epoch: 67, batch: 22, loss: 0.14603526890277863\n",
      "epoch: 67, batch: 23, loss: 0.07753048092126846\n",
      "epoch: 67, batch: 24, loss: 0.12026987969875336\n",
      "epoch: 67, batch: 25, loss: 0.20988158881664276\n",
      "epoch: 67, batch: 26, loss: 0.11750689148902893\n",
      "epoch: 67, batch: 27, loss: 0.05908878147602081\n",
      "epoch: 67, batch: 28, loss: 0.10695075243711472\n",
      "epoch: 68, batch: 0, loss: 0.1775026023387909\n",
      "epoch: 68, batch: 1, loss: 0.01584750786423683\n",
      "epoch: 68, batch: 2, loss: 0.02961103245615959\n",
      "epoch: 68, batch: 3, loss: 0.024999812245368958\n",
      "epoch: 68, batch: 4, loss: 0.043321240693330765\n",
      "epoch: 68, batch: 5, loss: 0.06072408705949783\n",
      "epoch: 68, batch: 6, loss: 0.022464638575911522\n",
      "epoch: 68, batch: 7, loss: 0.09619808197021484\n",
      "epoch: 68, batch: 8, loss: 0.009426313452422619\n",
      "epoch: 68, batch: 9, loss: 0.07724379748106003\n",
      "epoch: 68, batch: 10, loss: 0.05910544842481613\n",
      "epoch: 68, batch: 11, loss: 0.014703821390867233\n",
      "epoch: 68, batch: 12, loss: 0.02255830727517605\n",
      "epoch: 68, batch: 13, loss: 0.03620312735438347\n",
      "epoch: 68, batch: 14, loss: 0.05203692242503166\n",
      "epoch: 68, batch: 15, loss: 0.015857957303524017\n",
      "epoch: 68, batch: 16, loss: 0.011604364961385727\n",
      "epoch: 68, batch: 17, loss: 0.029606137424707413\n",
      "epoch: 68, batch: 18, loss: 0.05035772547125816\n",
      "epoch: 68, batch: 19, loss: 0.04457616060972214\n",
      "epoch: 68, batch: 20, loss: 0.01373019628226757\n",
      "epoch: 68, batch: 21, loss: 0.02358907461166382\n",
      "epoch: 68, batch: 22, loss: 0.02995423972606659\n",
      "epoch: 68, batch: 23, loss: 0.0857556089758873\n",
      "epoch: 68, batch: 24, loss: 0.008041762746870518\n",
      "epoch: 68, batch: 25, loss: 0.005286695435643196\n",
      "epoch: 68, batch: 26, loss: 0.05601978674530983\n",
      "epoch: 68, batch: 27, loss: 0.01111613493412733\n",
      "epoch: 68, batch: 28, loss: 0.15307781100273132\n",
      "epoch: 69, batch: 0, loss: 0.021848946809768677\n",
      "epoch: 69, batch: 1, loss: 0.010484431870281696\n",
      "epoch: 69, batch: 2, loss: 0.012296921573579311\n",
      "epoch: 69, batch: 3, loss: 0.014344826340675354\n",
      "epoch: 69, batch: 4, loss: 0.004951118491590023\n",
      "epoch: 69, batch: 5, loss: 0.008168324828147888\n",
      "epoch: 69, batch: 6, loss: 0.01989835873246193\n",
      "epoch: 69, batch: 7, loss: 0.002516659442335367\n",
      "epoch: 69, batch: 8, loss: 0.0054230112582445145\n",
      "epoch: 69, batch: 9, loss: 0.016833780333399773\n",
      "epoch: 69, batch: 10, loss: 0.04281451925635338\n",
      "epoch: 69, batch: 11, loss: 0.02015838772058487\n",
      "epoch: 69, batch: 12, loss: 0.0019865348003804684\n",
      "epoch: 69, batch: 13, loss: 0.006077190395444632\n",
      "epoch: 69, batch: 14, loss: 0.1620517373085022\n",
      "epoch: 69, batch: 15, loss: 0.003563461359590292\n",
      "epoch: 69, batch: 16, loss: 0.06229438632726669\n",
      "epoch: 69, batch: 17, loss: 0.004250859376043081\n",
      "epoch: 69, batch: 18, loss: 0.003975891973823309\n",
      "epoch: 69, batch: 19, loss: 0.02458072640001774\n",
      "epoch: 69, batch: 20, loss: 0.026509705930948257\n",
      "epoch: 69, batch: 21, loss: 0.005025974940508604\n",
      "epoch: 69, batch: 22, loss: 0.009122682735323906\n",
      "epoch: 69, batch: 23, loss: 0.002151273423805833\n",
      "epoch: 69, batch: 24, loss: 0.10546661913394928\n",
      "epoch: 69, batch: 25, loss: 0.040235478430986404\n",
      "epoch: 69, batch: 26, loss: 0.03423502296209335\n",
      "epoch: 69, batch: 27, loss: 0.01229801308363676\n",
      "epoch: 69, batch: 28, loss: 0.02104443497955799\n",
      "epoch: 70, batch: 0, loss: 0.006158951669931412\n",
      "epoch: 70, batch: 1, loss: 0.003506386186927557\n",
      "epoch: 70, batch: 2, loss: 0.003613003995269537\n",
      "epoch: 70, batch: 3, loss: 0.05457093194127083\n",
      "epoch: 70, batch: 4, loss: 0.029477953910827637\n",
      "epoch: 70, batch: 5, loss: 0.008622081018984318\n",
      "epoch: 70, batch: 6, loss: 0.0017835478065535426\n",
      "epoch: 70, batch: 7, loss: 0.003051038598641753\n",
      "epoch: 70, batch: 8, loss: 0.0057578906416893005\n",
      "epoch: 70, batch: 9, loss: 0.023338166996836662\n",
      "epoch: 70, batch: 10, loss: 0.011192080564796925\n",
      "epoch: 70, batch: 11, loss: 0.007204338908195496\n",
      "epoch: 70, batch: 12, loss: 0.14544793963432312\n",
      "epoch: 70, batch: 13, loss: 0.0030261704232543707\n",
      "epoch: 70, batch: 14, loss: 0.0015600800979882479\n",
      "epoch: 70, batch: 15, loss: 0.006099525839090347\n",
      "epoch: 70, batch: 16, loss: 0.00456252321600914\n",
      "epoch: 70, batch: 17, loss: 0.013075640425086021\n",
      "epoch: 70, batch: 18, loss: 0.006356719881296158\n",
      "epoch: 70, batch: 19, loss: 0.0029518890660256147\n",
      "epoch: 70, batch: 20, loss: 0.002888317918404937\n",
      "epoch: 70, batch: 21, loss: 0.0038686254993081093\n",
      "epoch: 70, batch: 22, loss: 0.003810612251982093\n",
      "epoch: 70, batch: 23, loss: 0.008142026141285896\n",
      "epoch: 70, batch: 24, loss: 0.00256658555008471\n",
      "epoch: 70, batch: 25, loss: 0.005166868679225445\n",
      "epoch: 70, batch: 26, loss: 0.0010061371140182018\n",
      "epoch: 70, batch: 27, loss: 0.007876979187130928\n",
      "epoch: 70, batch: 28, loss: 0.7446292638778687\n",
      "epoch: 71, batch: 0, loss: 0.003411397570744157\n",
      "epoch: 71, batch: 1, loss: 0.01269343588501215\n",
      "epoch: 71, batch: 2, loss: 0.016743555665016174\n",
      "epoch: 71, batch: 3, loss: 0.04839693382382393\n",
      "epoch: 71, batch: 4, loss: 0.08542510122060776\n",
      "epoch: 71, batch: 5, loss: 0.7241635918617249\n",
      "epoch: 71, batch: 6, loss: 0.23772025108337402\n",
      "epoch: 71, batch: 7, loss: 0.1840810328722\n",
      "epoch: 71, batch: 8, loss: 0.11259952932596207\n",
      "epoch: 71, batch: 9, loss: 0.47801879048347473\n",
      "epoch: 71, batch: 10, loss: 0.08381854742765427\n",
      "epoch: 71, batch: 11, loss: 0.15131030976772308\n",
      "epoch: 71, batch: 12, loss: 0.032962504774332047\n",
      "epoch: 71, batch: 13, loss: 0.08970657736063004\n",
      "epoch: 71, batch: 14, loss: 0.050142139196395874\n",
      "epoch: 71, batch: 15, loss: 0.1710970550775528\n",
      "epoch: 71, batch: 16, loss: 0.09023036062717438\n",
      "epoch: 71, batch: 17, loss: 0.2167254239320755\n",
      "epoch: 71, batch: 18, loss: 0.3743252754211426\n",
      "epoch: 71, batch: 19, loss: 0.2941192388534546\n",
      "epoch: 71, batch: 20, loss: 0.08458155393600464\n",
      "epoch: 71, batch: 21, loss: 0.031591176986694336\n",
      "epoch: 71, batch: 22, loss: 0.012931594625115395\n",
      "epoch: 71, batch: 23, loss: 0.055963076651096344\n",
      "epoch: 71, batch: 24, loss: 0.09692016243934631\n",
      "epoch: 71, batch: 25, loss: 0.024975618347525597\n",
      "epoch: 71, batch: 26, loss: 0.0240298081189394\n",
      "epoch: 71, batch: 27, loss: 0.1539989411830902\n",
      "epoch: 71, batch: 28, loss: 0.10248604416847229\n",
      "epoch: 72, batch: 0, loss: 0.12313367426395416\n",
      "epoch: 72, batch: 1, loss: 0.04598616063594818\n",
      "epoch: 72, batch: 2, loss: 0.029292216524481773\n",
      "epoch: 72, batch: 3, loss: 0.04916955530643463\n",
      "epoch: 72, batch: 4, loss: 0.02640027552843094\n",
      "epoch: 72, batch: 5, loss: 0.01678803376853466\n",
      "epoch: 72, batch: 6, loss: 0.05653414502739906\n",
      "epoch: 72, batch: 7, loss: 0.08103129267692566\n",
      "epoch: 72, batch: 8, loss: 0.019352613016963005\n",
      "epoch: 72, batch: 9, loss: 0.043444886803627014\n",
      "epoch: 72, batch: 10, loss: 0.0040224394761025906\n",
      "epoch: 72, batch: 11, loss: 0.07259613275527954\n",
      "epoch: 72, batch: 12, loss: 0.03648034483194351\n",
      "epoch: 72, batch: 13, loss: 0.02191178873181343\n",
      "epoch: 72, batch: 14, loss: 0.009374279528856277\n",
      "epoch: 72, batch: 15, loss: 0.08647684752941132\n",
      "epoch: 72, batch: 16, loss: 0.01536748930811882\n",
      "epoch: 72, batch: 17, loss: 0.015563559718430042\n",
      "epoch: 72, batch: 18, loss: 0.009827135130763054\n",
      "epoch: 72, batch: 19, loss: 0.0051943594589829445\n",
      "epoch: 72, batch: 20, loss: 0.030054545029997826\n",
      "epoch: 72, batch: 21, loss: 0.07159129530191422\n",
      "epoch: 72, batch: 22, loss: 0.010300811380147934\n",
      "epoch: 72, batch: 23, loss: 0.006589398253709078\n",
      "epoch: 72, batch: 24, loss: 0.0033414396457374096\n",
      "epoch: 72, batch: 25, loss: 0.029754649847745895\n",
      "epoch: 72, batch: 26, loss: 0.09034090489149094\n",
      "epoch: 72, batch: 27, loss: 0.15033143758773804\n",
      "epoch: 72, batch: 28, loss: 0.009107496589422226\n",
      "epoch: 73, batch: 0, loss: 0.001199732651002705\n",
      "epoch: 73, batch: 1, loss: 0.021923860535025597\n",
      "epoch: 73, batch: 2, loss: 0.003495942335575819\n",
      "epoch: 73, batch: 3, loss: 0.0028264557477086782\n",
      "epoch: 73, batch: 4, loss: 0.0008982927538454533\n",
      "epoch: 73, batch: 5, loss: 0.009528419002890587\n",
      "epoch: 73, batch: 6, loss: 0.007359261158853769\n",
      "epoch: 73, batch: 7, loss: 0.0030357022769749165\n",
      "epoch: 73, batch: 8, loss: 0.00395148154348135\n",
      "epoch: 73, batch: 9, loss: 0.0022625643759965897\n",
      "epoch: 73, batch: 10, loss: 0.0071397945284843445\n",
      "epoch: 73, batch: 11, loss: 0.09109141677618027\n",
      "epoch: 73, batch: 12, loss: 0.008044932968914509\n",
      "epoch: 73, batch: 13, loss: 0.010112973861396313\n",
      "epoch: 73, batch: 14, loss: 0.0015972289256751537\n",
      "epoch: 73, batch: 15, loss: 0.004730284214019775\n",
      "epoch: 73, batch: 16, loss: 0.006898907478898764\n",
      "epoch: 73, batch: 17, loss: 0.008995319716632366\n",
      "epoch: 73, batch: 18, loss: 0.0006350085022859275\n",
      "epoch: 73, batch: 19, loss: 0.0038657262921333313\n",
      "epoch: 73, batch: 20, loss: 0.05941329896450043\n",
      "epoch: 73, batch: 21, loss: 0.021023983135819435\n",
      "epoch: 73, batch: 22, loss: 0.022528687492012978\n",
      "epoch: 73, batch: 23, loss: 0.017559846863150597\n",
      "epoch: 73, batch: 24, loss: 0.004974753130227327\n",
      "epoch: 73, batch: 25, loss: 0.00531899044290185\n",
      "epoch: 73, batch: 26, loss: 0.0032156233210116625\n",
      "epoch: 73, batch: 27, loss: 0.001813902985304594\n",
      "epoch: 73, batch: 28, loss: 0.021304622292518616\n",
      "epoch: 74, batch: 0, loss: 0.005002771038562059\n",
      "epoch: 74, batch: 1, loss: 0.0025289414916187525\n",
      "epoch: 74, batch: 2, loss: 0.0041381362825632095\n",
      "epoch: 74, batch: 3, loss: 0.004121909383684397\n",
      "epoch: 74, batch: 4, loss: 0.0013059582561254501\n",
      "epoch: 74, batch: 5, loss: 0.003078310750424862\n",
      "epoch: 74, batch: 6, loss: 0.007162798196077347\n",
      "epoch: 74, batch: 7, loss: 0.001174801611341536\n",
      "epoch: 74, batch: 8, loss: 0.005906162783503532\n",
      "epoch: 74, batch: 9, loss: 0.002628149464726448\n",
      "epoch: 74, batch: 10, loss: 0.0004495075554586947\n",
      "epoch: 74, batch: 11, loss: 0.001159587176516652\n",
      "epoch: 74, batch: 12, loss: 0.002742202254012227\n",
      "epoch: 74, batch: 13, loss: 0.0014968643663451076\n",
      "epoch: 74, batch: 14, loss: 0.0008449103333987296\n",
      "epoch: 74, batch: 15, loss: 0.0009697737405076623\n",
      "epoch: 74, batch: 16, loss: 0.00116949703078717\n",
      "epoch: 74, batch: 17, loss: 0.0018939023138955235\n",
      "epoch: 74, batch: 18, loss: 0.005142814014106989\n",
      "epoch: 74, batch: 19, loss: 0.0007159414235502481\n",
      "epoch: 74, batch: 20, loss: 0.001259543001651764\n",
      "epoch: 74, batch: 21, loss: 0.0018335366621613503\n",
      "epoch: 74, batch: 22, loss: 0.008562070317566395\n",
      "epoch: 74, batch: 23, loss: 0.001449207658879459\n",
      "epoch: 74, batch: 24, loss: 0.00245962617918849\n",
      "epoch: 74, batch: 25, loss: 0.0038262889720499516\n",
      "epoch: 74, batch: 26, loss: 0.038223884999752045\n",
      "epoch: 74, batch: 27, loss: 0.025122620165348053\n",
      "epoch: 74, batch: 28, loss: 0.014445062726736069\n",
      "epoch: 75, batch: 0, loss: 0.0007061741198413074\n",
      "epoch: 75, batch: 1, loss: 0.0009443447343073785\n",
      "epoch: 75, batch: 2, loss: 0.00027774673071689904\n",
      "epoch: 75, batch: 3, loss: 0.0016531149158254266\n",
      "epoch: 75, batch: 4, loss: 0.00039717432809993625\n",
      "epoch: 75, batch: 5, loss: 0.018754780292510986\n",
      "epoch: 75, batch: 6, loss: 0.0025832015089690685\n",
      "epoch: 75, batch: 7, loss: 0.024469610303640366\n",
      "epoch: 75, batch: 8, loss: 0.002718866104260087\n",
      "epoch: 75, batch: 9, loss: 0.016846688464283943\n",
      "epoch: 75, batch: 10, loss: 0.0008627927163615823\n",
      "epoch: 75, batch: 11, loss: 0.0009438205161131918\n",
      "epoch: 75, batch: 12, loss: 0.0015385516453534365\n",
      "epoch: 75, batch: 13, loss: 0.0012805135920643806\n",
      "epoch: 75, batch: 14, loss: 0.001755677629262209\n",
      "epoch: 75, batch: 15, loss: 0.0023087323643267155\n",
      "epoch: 75, batch: 16, loss: 0.0009912133682519197\n",
      "epoch: 75, batch: 17, loss: 0.0021559824235737324\n",
      "epoch: 75, batch: 18, loss: 0.004122926853597164\n",
      "epoch: 75, batch: 19, loss: 0.0018278532661497593\n",
      "epoch: 75, batch: 20, loss: 0.0026878807693719864\n",
      "epoch: 75, batch: 21, loss: 0.0011874256888404489\n",
      "epoch: 75, batch: 22, loss: 0.00040910934330895543\n",
      "epoch: 75, batch: 23, loss: 0.0005685723735950887\n",
      "epoch: 75, batch: 24, loss: 0.0008201932068914175\n",
      "epoch: 75, batch: 25, loss: 0.00017850587028078735\n",
      "epoch: 75, batch: 26, loss: 0.006448512431234121\n",
      "epoch: 75, batch: 27, loss: 0.0012888108612969518\n",
      "epoch: 75, batch: 28, loss: 0.17541728913784027\n",
      "epoch: 76, batch: 0, loss: 0.00048043718561530113\n",
      "epoch: 76, batch: 1, loss: 0.003272045636549592\n",
      "epoch: 76, batch: 2, loss: 0.0090916957706213\n",
      "epoch: 76, batch: 3, loss: 0.0037984109949320555\n",
      "epoch: 76, batch: 4, loss: 0.06564252078533173\n",
      "epoch: 76, batch: 5, loss: 0.0032544517889618874\n",
      "epoch: 76, batch: 6, loss: 0.0549735501408577\n",
      "epoch: 76, batch: 7, loss: 0.0237025897949934\n",
      "epoch: 76, batch: 8, loss: 0.021939365193247795\n",
      "epoch: 76, batch: 9, loss: 0.01621863804757595\n",
      "epoch: 76, batch: 10, loss: 0.21080662310123444\n",
      "epoch: 76, batch: 11, loss: 0.005629978608340025\n",
      "epoch: 76, batch: 12, loss: 0.01701393350958824\n",
      "epoch: 76, batch: 13, loss: 0.047323234379291534\n",
      "epoch: 76, batch: 14, loss: 0.0023846710100769997\n",
      "epoch: 76, batch: 15, loss: 0.0013634564820677042\n",
      "epoch: 76, batch: 16, loss: 0.004496115259826183\n",
      "epoch: 76, batch: 17, loss: 0.04230247065424919\n",
      "epoch: 76, batch: 18, loss: 0.03469513729214668\n",
      "epoch: 76, batch: 19, loss: 0.007513025775551796\n",
      "epoch: 76, batch: 20, loss: 0.006977601442486048\n",
      "epoch: 76, batch: 21, loss: 0.009432594291865826\n",
      "epoch: 76, batch: 22, loss: 0.01193100493401289\n",
      "epoch: 76, batch: 23, loss: 0.002510407008230686\n",
      "epoch: 76, batch: 24, loss: 0.010487047024071217\n",
      "epoch: 76, batch: 25, loss: 0.0012754579074680805\n",
      "epoch: 76, batch: 26, loss: 0.004291401710361242\n",
      "epoch: 76, batch: 27, loss: 0.0032680262811481953\n",
      "epoch: 76, batch: 28, loss: 0.010493025183677673\n",
      "epoch: 77, batch: 0, loss: 0.04662158340215683\n",
      "epoch: 77, batch: 1, loss: 0.004969756118953228\n",
      "epoch: 77, batch: 2, loss: 0.0019527622498571873\n",
      "epoch: 77, batch: 3, loss: 0.0027959668077528477\n",
      "epoch: 77, batch: 4, loss: 0.0070716929621994495\n",
      "epoch: 77, batch: 5, loss: 0.002202975330874324\n",
      "epoch: 77, batch: 6, loss: 0.0056844232603907585\n",
      "epoch: 77, batch: 7, loss: 0.002429689047858119\n",
      "epoch: 77, batch: 8, loss: 0.001646960387006402\n",
      "epoch: 77, batch: 9, loss: 0.03532927855849266\n",
      "epoch: 77, batch: 10, loss: 0.03803003579378128\n",
      "epoch: 77, batch: 11, loss: 0.0034024675842374563\n",
      "epoch: 77, batch: 12, loss: 0.0017642604652792215\n",
      "epoch: 77, batch: 13, loss: 0.0025759872514754534\n",
      "epoch: 77, batch: 14, loss: 0.003190646879374981\n",
      "epoch: 77, batch: 15, loss: 0.0009157706517726183\n",
      "epoch: 77, batch: 16, loss: 0.00847529899328947\n",
      "epoch: 77, batch: 17, loss: 0.0010055998573079705\n",
      "epoch: 77, batch: 18, loss: 0.006064685061573982\n",
      "epoch: 77, batch: 19, loss: 0.007292208261787891\n",
      "epoch: 77, batch: 20, loss: 0.0011061892146244645\n",
      "epoch: 77, batch: 21, loss: 0.001408394193276763\n",
      "epoch: 77, batch: 22, loss: 0.006505205295979977\n",
      "epoch: 77, batch: 23, loss: 0.0012125496286898851\n",
      "epoch: 77, batch: 24, loss: 0.008304485119879246\n",
      "epoch: 77, batch: 25, loss: 0.00491495244204998\n",
      "epoch: 77, batch: 26, loss: 0.0007907501421868801\n",
      "epoch: 77, batch: 27, loss: 0.00485144043341279\n",
      "epoch: 77, batch: 28, loss: 0.00012442973093129694\n",
      "epoch: 78, batch: 0, loss: 0.0006892316159792244\n",
      "epoch: 78, batch: 1, loss: 0.005414765328168869\n",
      "epoch: 78, batch: 2, loss: 0.016858039423823357\n",
      "epoch: 78, batch: 3, loss: 0.029295925050973892\n",
      "epoch: 78, batch: 4, loss: 0.0018418062245473266\n",
      "epoch: 78, batch: 5, loss: 0.0006538222660310566\n",
      "epoch: 78, batch: 6, loss: 0.0008631682139821351\n",
      "epoch: 78, batch: 7, loss: 0.002146701095625758\n",
      "epoch: 78, batch: 8, loss: 0.0007945730467326939\n",
      "epoch: 78, batch: 9, loss: 0.004343590699136257\n",
      "epoch: 78, batch: 10, loss: 0.0004803434421774\n",
      "epoch: 78, batch: 11, loss: 0.0006662146770395339\n",
      "epoch: 78, batch: 12, loss: 0.0013951016589999199\n",
      "epoch: 78, batch: 13, loss: 0.0004050684510730207\n",
      "epoch: 78, batch: 14, loss: 0.0005874263006262481\n",
      "epoch: 78, batch: 15, loss: 0.00032444181852042675\n",
      "epoch: 78, batch: 16, loss: 0.0006415559910237789\n",
      "epoch: 78, batch: 17, loss: 0.0007147510186769068\n",
      "epoch: 78, batch: 18, loss: 0.000496861117426306\n",
      "epoch: 78, batch: 19, loss: 0.00039625453064218163\n",
      "epoch: 78, batch: 20, loss: 0.00015159943723119795\n",
      "epoch: 78, batch: 21, loss: 0.0010855650762096047\n",
      "epoch: 78, batch: 22, loss: 0.0037910565733909607\n",
      "epoch: 78, batch: 23, loss: 0.0003850046487059444\n",
      "epoch: 78, batch: 24, loss: 0.057185254991054535\n",
      "epoch: 78, batch: 25, loss: 0.0009951385436579585\n",
      "epoch: 78, batch: 26, loss: 0.005456265993416309\n",
      "epoch: 78, batch: 27, loss: 0.00163845915812999\n",
      "epoch: 78, batch: 28, loss: 0.003007429651916027\n",
      "epoch: 79, batch: 0, loss: 0.001906427089124918\n",
      "epoch: 79, batch: 1, loss: 0.0004576650680974126\n",
      "epoch: 79, batch: 2, loss: 0.0008894421625882387\n",
      "epoch: 79, batch: 3, loss: 0.0023733924608677626\n",
      "epoch: 79, batch: 4, loss: 0.000280016683973372\n",
      "epoch: 79, batch: 5, loss: 0.00045667262747883797\n",
      "epoch: 79, batch: 6, loss: 0.0016742973821237683\n",
      "epoch: 79, batch: 7, loss: 0.00234988983720541\n",
      "epoch: 79, batch: 8, loss: 0.0003617884358391166\n",
      "epoch: 79, batch: 9, loss: 0.0007547003333456814\n",
      "epoch: 79, batch: 10, loss: 0.017694750800728798\n",
      "epoch: 79, batch: 11, loss: 0.000526716117747128\n",
      "epoch: 79, batch: 12, loss: 0.0014568476472049952\n",
      "epoch: 79, batch: 13, loss: 0.003933717496693134\n",
      "epoch: 79, batch: 14, loss: 0.0012967849615961313\n",
      "epoch: 79, batch: 15, loss: 0.0005958411493338645\n",
      "epoch: 79, batch: 16, loss: 0.0009631472639739513\n",
      "epoch: 79, batch: 17, loss: 0.0010846717050299048\n",
      "epoch: 79, batch: 18, loss: 0.0003898831782862544\n",
      "epoch: 79, batch: 19, loss: 0.000496993656270206\n",
      "epoch: 79, batch: 20, loss: 0.00033744488609954715\n",
      "epoch: 79, batch: 21, loss: 0.00037524948129430413\n",
      "epoch: 79, batch: 22, loss: 0.00038916306220926344\n",
      "epoch: 79, batch: 23, loss: 0.056530922651290894\n",
      "epoch: 79, batch: 24, loss: 0.010158253833651543\n",
      "epoch: 79, batch: 25, loss: 0.0003109367680735886\n",
      "epoch: 79, batch: 26, loss: 0.0005324996309354901\n",
      "epoch: 79, batch: 27, loss: 0.0003290910099167377\n",
      "epoch: 79, batch: 28, loss: 0.272112637758255\n",
      "epoch: 80, batch: 0, loss: 0.0072091384790837765\n",
      "epoch: 80, batch: 1, loss: 0.0006761654512956738\n",
      "epoch: 80, batch: 2, loss: 0.0021167146041989326\n",
      "epoch: 80, batch: 3, loss: 0.00034397447598166764\n",
      "epoch: 80, batch: 4, loss: 0.00732822623103857\n",
      "epoch: 80, batch: 5, loss: 0.027267709374427795\n",
      "epoch: 80, batch: 6, loss: 0.004545297008007765\n",
      "epoch: 80, batch: 7, loss: 0.27480873465538025\n",
      "epoch: 80, batch: 8, loss: 0.0008785375393927097\n",
      "epoch: 80, batch: 9, loss: 0.06265676021575928\n",
      "epoch: 80, batch: 10, loss: 0.022915402427315712\n",
      "epoch: 80, batch: 11, loss: 0.011513467878103256\n",
      "epoch: 80, batch: 12, loss: 0.0015662502264603972\n",
      "epoch: 80, batch: 13, loss: 0.00691411504521966\n",
      "epoch: 80, batch: 14, loss: 0.006992105394601822\n",
      "epoch: 80, batch: 15, loss: 0.04856694117188454\n",
      "epoch: 80, batch: 16, loss: 0.0022151966113597155\n",
      "epoch: 80, batch: 17, loss: 0.016865810379385948\n",
      "epoch: 80, batch: 18, loss: 0.024428419768810272\n",
      "epoch: 80, batch: 19, loss: 0.024821776896715164\n",
      "epoch: 80, batch: 20, loss: 0.003465784713625908\n",
      "epoch: 80, batch: 21, loss: 0.001050323247909546\n",
      "epoch: 80, batch: 22, loss: 0.011080878786742687\n",
      "epoch: 80, batch: 23, loss: 0.008055147714912891\n",
      "epoch: 80, batch: 24, loss: 0.00643444387242198\n",
      "epoch: 80, batch: 25, loss: 0.18612830340862274\n",
      "epoch: 80, batch: 26, loss: 0.016931449994444847\n",
      "epoch: 80, batch: 27, loss: 0.06447010487318039\n",
      "epoch: 80, batch: 28, loss: 0.8137800097465515\n",
      "epoch: 81, batch: 0, loss: 0.0010555017506703734\n",
      "epoch: 81, batch: 1, loss: 0.015538332052528858\n",
      "epoch: 81, batch: 2, loss: 0.014115169644355774\n",
      "epoch: 81, batch: 3, loss: 0.004838144406676292\n",
      "epoch: 81, batch: 4, loss: 0.05573735013604164\n",
      "epoch: 81, batch: 5, loss: 0.6684917211532593\n",
      "epoch: 81, batch: 6, loss: 0.03292008116841316\n",
      "epoch: 81, batch: 7, loss: 0.11657692492008209\n",
      "epoch: 81, batch: 8, loss: 0.29642894864082336\n",
      "epoch: 81, batch: 9, loss: 0.8044183850288391\n",
      "epoch: 81, batch: 10, loss: 0.0951286256313324\n",
      "epoch: 81, batch: 11, loss: 0.09750639647245407\n",
      "epoch: 81, batch: 12, loss: 0.03679219260811806\n",
      "epoch: 81, batch: 13, loss: 0.20537668466567993\n",
      "epoch: 81, batch: 14, loss: 0.1616785079240799\n",
      "epoch: 81, batch: 15, loss: 0.14666028320789337\n",
      "epoch: 81, batch: 16, loss: 0.29272347688674927\n",
      "epoch: 81, batch: 17, loss: 0.2920665740966797\n",
      "epoch: 81, batch: 18, loss: 0.03159105405211449\n",
      "epoch: 81, batch: 19, loss: 0.08813879638910294\n",
      "epoch: 81, batch: 20, loss: 0.02930893376469612\n",
      "epoch: 81, batch: 21, loss: 0.12746483087539673\n",
      "epoch: 81, batch: 22, loss: 0.10066324472427368\n",
      "epoch: 81, batch: 23, loss: 0.4309762120246887\n",
      "epoch: 81, batch: 24, loss: 0.24139727652072906\n",
      "epoch: 81, batch: 25, loss: 0.16131195425987244\n",
      "epoch: 81, batch: 26, loss: 0.2823132574558258\n",
      "epoch: 81, batch: 27, loss: 0.05269843339920044\n",
      "epoch: 81, batch: 28, loss: 0.008967412635684013\n",
      "epoch: 82, batch: 0, loss: 0.04197797551751137\n",
      "epoch: 82, batch: 1, loss: 0.016321338713169098\n",
      "epoch: 82, batch: 2, loss: 0.08948695659637451\n",
      "epoch: 82, batch: 3, loss: 0.17788632214069366\n",
      "epoch: 82, batch: 4, loss: 0.07433655858039856\n",
      "epoch: 82, batch: 5, loss: 0.07398637384176254\n",
      "epoch: 82, batch: 6, loss: 0.022894462570548058\n",
      "epoch: 82, batch: 7, loss: 0.11421354115009308\n",
      "epoch: 82, batch: 8, loss: 0.10938175022602081\n",
      "epoch: 82, batch: 9, loss: 0.10008088499307632\n",
      "epoch: 82, batch: 10, loss: 0.027079086750745773\n",
      "epoch: 82, batch: 11, loss: 0.1099819540977478\n",
      "epoch: 82, batch: 12, loss: 0.10191037505865097\n",
      "epoch: 82, batch: 13, loss: 0.005817535798996687\n",
      "epoch: 82, batch: 14, loss: 0.011278492398560047\n",
      "epoch: 82, batch: 15, loss: 0.00410235533490777\n",
      "epoch: 82, batch: 16, loss: 0.03568940609693527\n",
      "epoch: 82, batch: 17, loss: 0.033062275499105453\n",
      "epoch: 82, batch: 18, loss: 0.03103230893611908\n",
      "epoch: 82, batch: 19, loss: 0.11219242960214615\n",
      "epoch: 82, batch: 20, loss: 0.06553143262863159\n",
      "epoch: 82, batch: 21, loss: 0.010004907846450806\n",
      "epoch: 82, batch: 22, loss: 0.012619384564459324\n",
      "epoch: 82, batch: 23, loss: 0.00883552711457014\n",
      "epoch: 82, batch: 24, loss: 0.016642039641737938\n",
      "epoch: 82, batch: 25, loss: 0.047966379672288895\n",
      "epoch: 82, batch: 26, loss: 0.0926615372300148\n",
      "epoch: 82, batch: 27, loss: 0.021781999617815018\n",
      "epoch: 82, batch: 28, loss: 2.378899097442627\n",
      "epoch: 83, batch: 0, loss: 0.011930214241147041\n",
      "epoch: 83, batch: 1, loss: 0.018551338464021683\n",
      "epoch: 83, batch: 2, loss: 0.2984040379524231\n",
      "epoch: 83, batch: 3, loss: 0.3760303854942322\n",
      "epoch: 83, batch: 4, loss: 0.10886628180742264\n",
      "epoch: 83, batch: 5, loss: 0.3074497580528259\n",
      "epoch: 83, batch: 6, loss: 0.16635090112686157\n",
      "epoch: 83, batch: 7, loss: 0.05821407958865166\n",
      "epoch: 83, batch: 8, loss: 0.2607952654361725\n",
      "epoch: 83, batch: 9, loss: 0.532888650894165\n",
      "epoch: 83, batch: 10, loss: 0.11538511514663696\n",
      "epoch: 83, batch: 11, loss: 0.09696318209171295\n",
      "epoch: 83, batch: 12, loss: 0.08957676589488983\n",
      "epoch: 83, batch: 13, loss: 0.034090131521224976\n",
      "epoch: 83, batch: 14, loss: 0.1293536126613617\n",
      "epoch: 83, batch: 15, loss: 0.061203718185424805\n",
      "epoch: 83, batch: 16, loss: 0.16654466092586517\n",
      "epoch: 83, batch: 17, loss: 0.03347088024020195\n",
      "epoch: 83, batch: 18, loss: 0.13028493523597717\n",
      "epoch: 83, batch: 19, loss: 0.0806516483426094\n",
      "epoch: 83, batch: 20, loss: 0.31488141417503357\n",
      "epoch: 83, batch: 21, loss: 0.02203579992055893\n",
      "epoch: 83, batch: 22, loss: 0.04395538568496704\n",
      "epoch: 83, batch: 23, loss: 0.13971151411533356\n",
      "epoch: 83, batch: 24, loss: 0.10533744841814041\n",
      "epoch: 83, batch: 25, loss: 0.2606829106807709\n",
      "epoch: 83, batch: 26, loss: 0.18028342723846436\n",
      "epoch: 83, batch: 27, loss: 0.1068262904882431\n",
      "epoch: 83, batch: 28, loss: 0.046624019742012024\n",
      "epoch: 84, batch: 0, loss: 0.011308899149298668\n",
      "epoch: 84, batch: 1, loss: 0.02350611239671707\n",
      "epoch: 84, batch: 2, loss: 0.1185184121131897\n",
      "epoch: 84, batch: 3, loss: 0.21923382580280304\n",
      "epoch: 84, batch: 4, loss: 0.09188159555196762\n",
      "epoch: 84, batch: 5, loss: 0.05495709553360939\n",
      "epoch: 84, batch: 6, loss: 0.2291889637708664\n",
      "epoch: 84, batch: 7, loss: 0.1194896250963211\n",
      "epoch: 84, batch: 8, loss: 0.007920396514236927\n",
      "epoch: 84, batch: 9, loss: 0.015089431777596474\n",
      "epoch: 84, batch: 10, loss: 0.15834800899028778\n",
      "epoch: 84, batch: 11, loss: 0.05368775874376297\n",
      "epoch: 84, batch: 12, loss: 0.021668175235390663\n",
      "epoch: 84, batch: 13, loss: 0.022632885724306107\n",
      "epoch: 84, batch: 14, loss: 0.2009810209274292\n",
      "epoch: 84, batch: 15, loss: 0.08794752508401871\n",
      "epoch: 84, batch: 16, loss: 0.021642113104462624\n",
      "epoch: 84, batch: 17, loss: 0.020593903958797455\n",
      "epoch: 84, batch: 18, loss: 0.013429220765829086\n",
      "epoch: 84, batch: 19, loss: 0.08895362168550491\n",
      "epoch: 84, batch: 20, loss: 0.12218127399682999\n",
      "epoch: 84, batch: 21, loss: 0.012833585031330585\n",
      "epoch: 84, batch: 22, loss: 0.020133797079324722\n",
      "epoch: 84, batch: 23, loss: 0.07842105627059937\n",
      "epoch: 84, batch: 24, loss: 0.01691325381398201\n",
      "epoch: 84, batch: 25, loss: 0.19393572211265564\n",
      "epoch: 84, batch: 26, loss: 0.01311630941927433\n",
      "epoch: 84, batch: 27, loss: 0.011536889709532261\n",
      "epoch: 84, batch: 28, loss: 0.09916108101606369\n",
      "epoch: 85, batch: 0, loss: 0.025995716452598572\n",
      "epoch: 85, batch: 1, loss: 0.013132869265973568\n",
      "epoch: 85, batch: 2, loss: 0.006999216973781586\n",
      "epoch: 85, batch: 3, loss: 0.004708618391305208\n",
      "epoch: 85, batch: 4, loss: 0.025304587557911873\n",
      "epoch: 85, batch: 5, loss: 0.06858861446380615\n",
      "epoch: 85, batch: 6, loss: 0.017283687368035316\n",
      "epoch: 85, batch: 7, loss: 0.01790027506649494\n",
      "epoch: 85, batch: 8, loss: 0.015748996287584305\n",
      "epoch: 85, batch: 9, loss: 0.019856851547956467\n",
      "epoch: 85, batch: 10, loss: 0.04367997124791145\n",
      "epoch: 85, batch: 11, loss: 0.07821138203144073\n",
      "epoch: 85, batch: 12, loss: 0.014791970141232014\n",
      "epoch: 85, batch: 13, loss: 0.018361695110797882\n",
      "epoch: 85, batch: 14, loss: 0.0025051815900951624\n",
      "epoch: 85, batch: 15, loss: 0.0029465644620358944\n",
      "epoch: 85, batch: 16, loss: 0.03162665665149689\n",
      "epoch: 85, batch: 17, loss: 0.05636024475097656\n",
      "epoch: 85, batch: 18, loss: 0.009036429226398468\n",
      "epoch: 85, batch: 19, loss: 0.003398255445063114\n",
      "epoch: 85, batch: 20, loss: 0.014060952700674534\n",
      "epoch: 85, batch: 21, loss: 0.04622810706496239\n",
      "epoch: 85, batch: 22, loss: 0.0027193287387490273\n",
      "epoch: 85, batch: 23, loss: 0.016477201133966446\n",
      "epoch: 85, batch: 24, loss: 0.016270194202661514\n",
      "epoch: 85, batch: 25, loss: 0.004100786987692118\n",
      "epoch: 85, batch: 26, loss: 0.030193477869033813\n",
      "epoch: 85, batch: 27, loss: 0.057554904371500015\n",
      "epoch: 85, batch: 28, loss: 0.03180399537086487\n",
      "epoch: 86, batch: 0, loss: 0.001811561407521367\n",
      "epoch: 86, batch: 1, loss: 0.0013491775607690215\n",
      "epoch: 86, batch: 2, loss: 0.016433555632829666\n",
      "epoch: 86, batch: 3, loss: 0.014702261425554752\n",
      "epoch: 86, batch: 4, loss: 0.01280292496085167\n",
      "epoch: 86, batch: 5, loss: 0.003963272552937269\n",
      "epoch: 86, batch: 6, loss: 0.0034127049148082733\n",
      "epoch: 86, batch: 7, loss: 0.024229224771261215\n",
      "epoch: 86, batch: 8, loss: 0.006227221805602312\n",
      "epoch: 86, batch: 9, loss: 0.0032343247439712286\n",
      "epoch: 86, batch: 10, loss: 0.0023405011743307114\n",
      "epoch: 86, batch: 11, loss: 0.006223158445209265\n",
      "epoch: 86, batch: 12, loss: 0.004214990418404341\n",
      "epoch: 86, batch: 13, loss: 0.022436397150158882\n",
      "epoch: 86, batch: 14, loss: 0.013395671732723713\n",
      "epoch: 86, batch: 15, loss: 0.00563611788675189\n",
      "epoch: 86, batch: 16, loss: 0.003557241056114435\n",
      "epoch: 86, batch: 17, loss: 0.008547823876142502\n",
      "epoch: 86, batch: 18, loss: 0.0015365732833743095\n",
      "epoch: 86, batch: 19, loss: 0.053343515843153\n",
      "epoch: 86, batch: 20, loss: 0.004367067478597164\n",
      "epoch: 86, batch: 21, loss: 0.02313050627708435\n",
      "epoch: 86, batch: 22, loss: 0.0030702303629368544\n",
      "epoch: 86, batch: 23, loss: 0.002370876260101795\n",
      "epoch: 86, batch: 24, loss: 0.005155378021299839\n",
      "epoch: 86, batch: 25, loss: 0.0014714907156303525\n",
      "epoch: 86, batch: 26, loss: 0.0005644335760734975\n",
      "epoch: 86, batch: 27, loss: 0.005124050658196211\n",
      "epoch: 86, batch: 28, loss: 0.10408081859350204\n",
      "epoch: 87, batch: 0, loss: 0.0006134049617685378\n",
      "epoch: 87, batch: 1, loss: 0.000764074211474508\n",
      "epoch: 87, batch: 2, loss: 0.019740929827094078\n",
      "epoch: 87, batch: 3, loss: 0.0010657940292730927\n",
      "epoch: 87, batch: 4, loss: 0.005812595132738352\n",
      "epoch: 87, batch: 5, loss: 0.001285372767597437\n",
      "epoch: 87, batch: 6, loss: 0.015091298148036003\n",
      "epoch: 87, batch: 7, loss: 0.03272359445691109\n",
      "epoch: 87, batch: 8, loss: 0.004907663445919752\n",
      "epoch: 87, batch: 9, loss: 0.013181131333112717\n",
      "epoch: 87, batch: 10, loss: 0.0008595808758400381\n",
      "epoch: 87, batch: 11, loss: 0.014002228155732155\n",
      "epoch: 87, batch: 12, loss: 0.03655001521110535\n",
      "epoch: 87, batch: 13, loss: 0.002555838553234935\n",
      "epoch: 87, batch: 14, loss: 0.0006845351890660822\n",
      "epoch: 87, batch: 15, loss: 0.0030627306550741196\n",
      "epoch: 87, batch: 16, loss: 0.0031370429787784815\n",
      "epoch: 87, batch: 17, loss: 0.023393701761960983\n",
      "epoch: 87, batch: 18, loss: 0.007627058308571577\n",
      "epoch: 87, batch: 19, loss: 0.0032420409843325615\n",
      "epoch: 87, batch: 20, loss: 0.0031181892845779657\n",
      "epoch: 87, batch: 21, loss: 0.011554965749382973\n",
      "epoch: 87, batch: 22, loss: 0.11650354415178299\n",
      "epoch: 87, batch: 23, loss: 0.008082796819508076\n",
      "epoch: 87, batch: 24, loss: 0.017450185492634773\n",
      "epoch: 87, batch: 25, loss: 0.0076380702666938305\n",
      "epoch: 87, batch: 26, loss: 0.0014235706767067313\n",
      "epoch: 87, batch: 27, loss: 0.0007053517620079219\n",
      "epoch: 87, batch: 28, loss: 0.7035105228424072\n",
      "epoch: 88, batch: 0, loss: 0.04497823119163513\n",
      "epoch: 88, batch: 1, loss: 0.012861724011600018\n",
      "epoch: 88, batch: 2, loss: 0.15547673404216766\n",
      "epoch: 88, batch: 3, loss: 0.14016932249069214\n",
      "epoch: 88, batch: 4, loss: 0.03915458545088768\n",
      "epoch: 88, batch: 5, loss: 0.04107236862182617\n",
      "epoch: 88, batch: 6, loss: 0.23217402398586273\n",
      "epoch: 88, batch: 7, loss: 0.10940203815698624\n",
      "epoch: 88, batch: 8, loss: 0.2876439690589905\n",
      "epoch: 88, batch: 9, loss: 0.08315853774547577\n",
      "epoch: 88, batch: 10, loss: 0.08207391202449799\n",
      "epoch: 88, batch: 11, loss: 0.0942782312631607\n",
      "epoch: 88, batch: 12, loss: 0.023007646203041077\n",
      "epoch: 88, batch: 13, loss: 0.2572755217552185\n",
      "epoch: 88, batch: 14, loss: 0.15416236221790314\n",
      "epoch: 88, batch: 15, loss: 0.025037139654159546\n",
      "epoch: 88, batch: 16, loss: 0.032638028264045715\n",
      "epoch: 88, batch: 17, loss: 0.16505342721939087\n",
      "epoch: 88, batch: 18, loss: 0.1220153346657753\n",
      "epoch: 88, batch: 19, loss: 0.20633243024349213\n",
      "epoch: 88, batch: 20, loss: 0.025997448712587357\n",
      "epoch: 88, batch: 21, loss: 0.18770349025726318\n",
      "epoch: 88, batch: 22, loss: 0.019584983587265015\n",
      "epoch: 88, batch: 23, loss: 0.015703516080975533\n",
      "epoch: 88, batch: 24, loss: 0.03597583994269371\n",
      "epoch: 88, batch: 25, loss: 0.10892140865325928\n",
      "epoch: 88, batch: 26, loss: 0.020798973739147186\n",
      "epoch: 88, batch: 27, loss: 0.07760340720415115\n",
      "epoch: 88, batch: 28, loss: 0.013869316317141056\n",
      "epoch: 89, batch: 0, loss: 0.0239862110465765\n",
      "epoch: 89, batch: 1, loss: 0.004590658936649561\n",
      "epoch: 89, batch: 2, loss: 0.038322243839502335\n",
      "epoch: 89, batch: 3, loss: 0.07026702165603638\n",
      "epoch: 89, batch: 4, loss: 0.005299814976751804\n",
      "epoch: 89, batch: 5, loss: 0.005030904430896044\n",
      "epoch: 89, batch: 6, loss: 0.013603209517896175\n",
      "epoch: 89, batch: 7, loss: 0.08104114234447479\n",
      "epoch: 89, batch: 8, loss: 0.014716236852109432\n",
      "epoch: 89, batch: 9, loss: 0.0031641172245144844\n",
      "epoch: 89, batch: 10, loss: 0.003997590392827988\n",
      "epoch: 89, batch: 11, loss: 0.038014378398656845\n",
      "epoch: 89, batch: 12, loss: 0.010220681317150593\n",
      "epoch: 89, batch: 13, loss: 0.016725776717066765\n",
      "epoch: 89, batch: 14, loss: 0.0036705879028886557\n",
      "epoch: 89, batch: 15, loss: 0.021608255803585052\n",
      "epoch: 89, batch: 16, loss: 0.01009643729776144\n",
      "epoch: 89, batch: 17, loss: 0.018882427364587784\n",
      "epoch: 89, batch: 18, loss: 0.003057521302253008\n",
      "epoch: 89, batch: 19, loss: 0.032910335808992386\n",
      "epoch: 89, batch: 20, loss: 0.030513599514961243\n",
      "epoch: 89, batch: 21, loss: 0.05569745600223541\n",
      "epoch: 89, batch: 22, loss: 0.05270686000585556\n",
      "epoch: 89, batch: 23, loss: 0.1433396190404892\n",
      "epoch: 89, batch: 24, loss: 0.07426629960536957\n",
      "epoch: 89, batch: 25, loss: 0.08326718211174011\n",
      "epoch: 89, batch: 26, loss: 0.007807550486177206\n",
      "epoch: 89, batch: 27, loss: 0.01416152622550726\n",
      "epoch: 89, batch: 28, loss: 1.3645601272583008\n",
      "epoch: 90, batch: 0, loss: 0.03612084314227104\n",
      "epoch: 90, batch: 1, loss: 0.10167419910430908\n",
      "epoch: 90, batch: 2, loss: 0.01362687163054943\n",
      "epoch: 90, batch: 3, loss: 0.4091029167175293\n",
      "epoch: 90, batch: 4, loss: 0.3090016841888428\n",
      "epoch: 90, batch: 5, loss: 0.5768056511878967\n",
      "epoch: 90, batch: 6, loss: 0.24972985684871674\n",
      "epoch: 90, batch: 7, loss: 0.7811963558197021\n",
      "epoch: 90, batch: 8, loss: 0.16345107555389404\n",
      "epoch: 90, batch: 9, loss: 0.3438039720058441\n",
      "epoch: 90, batch: 10, loss: 0.051096826791763306\n",
      "epoch: 90, batch: 11, loss: 1.0864909887313843\n",
      "epoch: 90, batch: 12, loss: 0.2540625035762787\n",
      "epoch: 90, batch: 13, loss: 0.4330345094203949\n",
      "epoch: 90, batch: 14, loss: 0.09638260304927826\n",
      "epoch: 90, batch: 15, loss: 0.04312312230467796\n",
      "epoch: 90, batch: 16, loss: 0.11256037652492523\n",
      "epoch: 90, batch: 17, loss: 0.07476025074720383\n",
      "epoch: 90, batch: 18, loss: 0.09856202453374863\n",
      "epoch: 90, batch: 19, loss: 0.32289910316467285\n",
      "epoch: 90, batch: 20, loss: 0.06876152753829956\n",
      "epoch: 90, batch: 21, loss: 0.14952434599399567\n",
      "epoch: 90, batch: 22, loss: 0.22298868000507355\n",
      "epoch: 90, batch: 23, loss: 0.2580825090408325\n",
      "epoch: 90, batch: 24, loss: 0.13426099717617035\n",
      "epoch: 90, batch: 25, loss: 0.18408046662807465\n",
      "epoch: 90, batch: 26, loss: 0.4052165448665619\n",
      "epoch: 90, batch: 27, loss: 0.3157126307487488\n",
      "epoch: 90, batch: 28, loss: 0.454860657453537\n",
      "epoch: 91, batch: 0, loss: 0.11213282495737076\n",
      "epoch: 91, batch: 1, loss: 0.2536636292934418\n",
      "epoch: 91, batch: 2, loss: 0.10205309092998505\n",
      "epoch: 91, batch: 3, loss: 0.10539201647043228\n",
      "epoch: 91, batch: 4, loss: 0.20451487600803375\n",
      "epoch: 91, batch: 5, loss: 0.1716928780078888\n",
      "epoch: 91, batch: 6, loss: 0.49718794226646423\n",
      "epoch: 91, batch: 7, loss: 0.08193989098072052\n",
      "epoch: 91, batch: 8, loss: 0.28477102518081665\n",
      "epoch: 91, batch: 9, loss: 0.04084854945540428\n",
      "epoch: 91, batch: 10, loss: 0.05823396518826485\n",
      "epoch: 91, batch: 11, loss: 0.05631747096776962\n",
      "epoch: 91, batch: 12, loss: 0.07176364958286285\n",
      "epoch: 91, batch: 13, loss: 0.023841509595513344\n",
      "epoch: 91, batch: 14, loss: 0.05648957937955856\n",
      "epoch: 91, batch: 15, loss: 0.05840124562382698\n",
      "epoch: 91, batch: 16, loss: 0.1465945690870285\n",
      "epoch: 91, batch: 17, loss: 0.08901435136795044\n",
      "epoch: 91, batch: 18, loss: 0.10870302468538284\n",
      "epoch: 91, batch: 19, loss: 0.04527006670832634\n",
      "epoch: 91, batch: 20, loss: 0.037332285195589066\n",
      "epoch: 91, batch: 21, loss: 0.026225630193948746\n",
      "epoch: 91, batch: 22, loss: 0.03775111213326454\n",
      "epoch: 91, batch: 23, loss: 0.19158494472503662\n",
      "epoch: 91, batch: 24, loss: 0.02923608385026455\n",
      "epoch: 91, batch: 25, loss: 0.03349391743540764\n",
      "epoch: 91, batch: 26, loss: 0.08597234636545181\n",
      "epoch: 91, batch: 27, loss: 0.07121684402227402\n",
      "epoch: 91, batch: 28, loss: 0.07137752324342728\n",
      "epoch: 92, batch: 0, loss: 0.015427101403474808\n",
      "epoch: 92, batch: 1, loss: 0.011322850361466408\n",
      "epoch: 92, batch: 2, loss: 0.025183802470564842\n",
      "epoch: 92, batch: 3, loss: 0.025122130289673805\n",
      "epoch: 92, batch: 4, loss: 0.05697406828403473\n",
      "epoch: 92, batch: 5, loss: 0.005168876610696316\n",
      "epoch: 92, batch: 6, loss: 0.014253118075430393\n",
      "epoch: 92, batch: 7, loss: 0.010537216439843178\n",
      "epoch: 92, batch: 8, loss: 0.04327993094921112\n",
      "epoch: 92, batch: 9, loss: 0.01834785006940365\n",
      "epoch: 92, batch: 10, loss: 0.0047339485026896\n",
      "epoch: 92, batch: 11, loss: 0.09738638252019882\n",
      "epoch: 92, batch: 12, loss: 0.041804905980825424\n",
      "epoch: 92, batch: 13, loss: 0.02922596037387848\n",
      "epoch: 92, batch: 14, loss: 0.011860192753374577\n",
      "epoch: 92, batch: 15, loss: 0.05283262953162193\n",
      "epoch: 92, batch: 16, loss: 0.034559544175863266\n",
      "epoch: 92, batch: 17, loss: 0.09564557671546936\n",
      "epoch: 92, batch: 18, loss: 0.018558699637651443\n",
      "epoch: 92, batch: 19, loss: 0.021473649889230728\n",
      "epoch: 92, batch: 20, loss: 0.006917604710906744\n",
      "epoch: 92, batch: 21, loss: 0.01697733625769615\n",
      "epoch: 92, batch: 22, loss: 0.018950950354337692\n",
      "epoch: 92, batch: 23, loss: 0.0025433399714529514\n",
      "epoch: 92, batch: 24, loss: 0.005566259380429983\n",
      "epoch: 92, batch: 25, loss: 0.006667692214250565\n",
      "epoch: 92, batch: 26, loss: 0.07042218744754791\n",
      "epoch: 92, batch: 27, loss: 0.00972081534564495\n",
      "epoch: 92, batch: 28, loss: 0.0003157680039294064\n",
      "epoch: 93, batch: 0, loss: 0.0023864731192588806\n",
      "epoch: 93, batch: 1, loss: 0.06260564923286438\n",
      "epoch: 93, batch: 2, loss: 0.011200536042451859\n",
      "epoch: 93, batch: 3, loss: 0.01974422298371792\n",
      "epoch: 93, batch: 4, loss: 0.012285515666007996\n",
      "epoch: 93, batch: 5, loss: 0.0027444276493042707\n",
      "epoch: 93, batch: 6, loss: 0.006691396702080965\n",
      "epoch: 93, batch: 7, loss: 0.09509086608886719\n",
      "epoch: 93, batch: 8, loss: 0.007576248608529568\n",
      "epoch: 93, batch: 9, loss: 0.0011553210206329823\n",
      "epoch: 93, batch: 10, loss: 0.0023266507778316736\n",
      "epoch: 93, batch: 11, loss: 0.0007054563029669225\n",
      "epoch: 93, batch: 12, loss: 0.0015179687179625034\n",
      "epoch: 93, batch: 13, loss: 0.030221128836274147\n",
      "epoch: 93, batch: 14, loss: 0.0029159728437662125\n",
      "epoch: 93, batch: 15, loss: 0.004905221983790398\n",
      "epoch: 93, batch: 16, loss: 0.008271528407931328\n",
      "epoch: 93, batch: 17, loss: 0.015045476146042347\n",
      "epoch: 93, batch: 18, loss: 0.006989617832005024\n",
      "epoch: 93, batch: 19, loss: 0.00647500716149807\n",
      "epoch: 93, batch: 20, loss: 0.00256171403452754\n",
      "epoch: 93, batch: 21, loss: 0.003280573058873415\n",
      "epoch: 93, batch: 22, loss: 0.051842182874679565\n",
      "epoch: 93, batch: 23, loss: 0.003657939378172159\n",
      "epoch: 93, batch: 24, loss: 0.0011681488249450922\n",
      "epoch: 93, batch: 25, loss: 0.0026221005246043205\n",
      "epoch: 93, batch: 26, loss: 0.002017283346503973\n",
      "epoch: 93, batch: 27, loss: 0.0008339443011209369\n",
      "epoch: 93, batch: 28, loss: 1.7553633451461792\n",
      "epoch: 94, batch: 0, loss: 0.0037773752119392157\n",
      "epoch: 94, batch: 1, loss: 0.011463597416877747\n",
      "epoch: 94, batch: 2, loss: 0.0152470413595438\n",
      "epoch: 94, batch: 3, loss: 0.027132194489240646\n",
      "epoch: 94, batch: 4, loss: 1.109482765197754\n",
      "epoch: 94, batch: 5, loss: 0.1352894902229309\n",
      "epoch: 94, batch: 6, loss: 0.43618085980415344\n",
      "epoch: 94, batch: 7, loss: 0.347063273191452\n",
      "epoch: 94, batch: 8, loss: 0.11107891798019409\n",
      "epoch: 94, batch: 9, loss: 0.21686115860939026\n",
      "epoch: 94, batch: 10, loss: 0.379624605178833\n",
      "epoch: 94, batch: 11, loss: 0.5181264877319336\n",
      "epoch: 94, batch: 12, loss: 0.16745887696743011\n",
      "epoch: 94, batch: 13, loss: 0.3830021619796753\n",
      "epoch: 94, batch: 14, loss: 0.08542202413082123\n",
      "epoch: 94, batch: 15, loss: 0.22230617702007294\n",
      "epoch: 94, batch: 16, loss: 0.4187820851802826\n",
      "epoch: 94, batch: 17, loss: 0.24177111685276031\n",
      "epoch: 94, batch: 18, loss: 0.051605187356472015\n",
      "epoch: 94, batch: 19, loss: 0.05134274438023567\n",
      "epoch: 94, batch: 20, loss: 0.25415799021720886\n",
      "epoch: 94, batch: 21, loss: 0.41889411211013794\n",
      "epoch: 94, batch: 22, loss: 0.0648515522480011\n",
      "epoch: 94, batch: 23, loss: 0.14459452033042908\n",
      "epoch: 94, batch: 24, loss: 0.023682190105319023\n",
      "epoch: 94, batch: 25, loss: 0.03571667522192001\n",
      "epoch: 94, batch: 26, loss: 0.3227226138114929\n",
      "epoch: 94, batch: 27, loss: 0.014527040533721447\n",
      "epoch: 94, batch: 28, loss: 0.2038748860359192\n",
      "epoch: 95, batch: 0, loss: 0.19895486533641815\n",
      "epoch: 95, batch: 1, loss: 0.03648106008768082\n",
      "epoch: 95, batch: 2, loss: 0.04179297387599945\n",
      "epoch: 95, batch: 3, loss: 0.055876702070236206\n",
      "epoch: 95, batch: 4, loss: 0.09710409492254257\n",
      "epoch: 95, batch: 5, loss: 0.06959809362888336\n",
      "epoch: 95, batch: 6, loss: 0.05396512150764465\n",
      "epoch: 95, batch: 7, loss: 0.04542640969157219\n",
      "epoch: 95, batch: 8, loss: 0.09020110964775085\n",
      "epoch: 95, batch: 9, loss: 0.06119059398770332\n",
      "epoch: 95, batch: 10, loss: 0.029978210106492043\n",
      "epoch: 95, batch: 11, loss: 0.1113121435046196\n",
      "epoch: 95, batch: 12, loss: 0.004680932965129614\n",
      "epoch: 95, batch: 13, loss: 0.016859881579875946\n",
      "epoch: 95, batch: 14, loss: 0.09633766859769821\n",
      "epoch: 95, batch: 15, loss: 0.10985877364873886\n",
      "epoch: 95, batch: 16, loss: 0.01274823397397995\n",
      "epoch: 95, batch: 17, loss: 0.044006966054439545\n",
      "epoch: 95, batch: 18, loss: 0.07218222320079803\n",
      "epoch: 95, batch: 19, loss: 0.0047413744032382965\n",
      "epoch: 95, batch: 20, loss: 0.03640592098236084\n",
      "epoch: 95, batch: 21, loss: 0.014730321243405342\n",
      "epoch: 95, batch: 22, loss: 0.026094496250152588\n",
      "epoch: 95, batch: 23, loss: 0.050860218703746796\n",
      "epoch: 95, batch: 24, loss: 0.008609429933130741\n",
      "epoch: 95, batch: 25, loss: 0.006038658320903778\n",
      "epoch: 95, batch: 26, loss: 0.006355605088174343\n",
      "epoch: 95, batch: 27, loss: 0.031088141724467278\n",
      "epoch: 95, batch: 28, loss: 0.17495885491371155\n",
      "epoch: 96, batch: 0, loss: 0.004301679786294699\n",
      "epoch: 96, batch: 1, loss: 0.012321311980485916\n",
      "epoch: 96, batch: 2, loss: 0.013196676969528198\n",
      "epoch: 96, batch: 3, loss: 0.0202262494713068\n",
      "epoch: 96, batch: 4, loss: 0.00948247779160738\n",
      "epoch: 96, batch: 5, loss: 0.027866899967193604\n",
      "epoch: 96, batch: 6, loss: 0.001766968984156847\n",
      "epoch: 96, batch: 7, loss: 0.10081376135349274\n",
      "epoch: 96, batch: 8, loss: 0.0077770971693098545\n",
      "epoch: 96, batch: 9, loss: 0.01280828844755888\n",
      "epoch: 96, batch: 10, loss: 0.20735487341880798\n",
      "epoch: 96, batch: 11, loss: 0.0171296875923872\n",
      "epoch: 96, batch: 12, loss: 0.015423513017594814\n",
      "epoch: 96, batch: 13, loss: 0.003518027951940894\n",
      "epoch: 96, batch: 14, loss: 0.05298558622598648\n",
      "epoch: 96, batch: 15, loss: 0.15754348039627075\n",
      "epoch: 96, batch: 16, loss: 0.015817582607269287\n",
      "epoch: 96, batch: 17, loss: 0.017548179253935814\n",
      "epoch: 96, batch: 18, loss: 0.012054060585796833\n",
      "epoch: 96, batch: 19, loss: 0.10330114513635635\n",
      "epoch: 96, batch: 20, loss: 0.015887519344687462\n",
      "epoch: 96, batch: 21, loss: 0.008180702105164528\n",
      "epoch: 96, batch: 22, loss: 0.01022286992520094\n",
      "epoch: 96, batch: 23, loss: 0.016945218667387962\n",
      "epoch: 96, batch: 24, loss: 0.02421894669532776\n",
      "epoch: 96, batch: 25, loss: 0.009218133054673672\n",
      "epoch: 96, batch: 26, loss: 0.005327342078089714\n",
      "epoch: 96, batch: 27, loss: 0.026135237887501717\n",
      "epoch: 96, batch: 28, loss: 0.48464542627334595\n",
      "epoch: 97, batch: 0, loss: 0.06974215060472488\n",
      "epoch: 97, batch: 1, loss: 0.002475027460604906\n",
      "epoch: 97, batch: 2, loss: 0.02164032869040966\n",
      "epoch: 97, batch: 3, loss: 0.05402549356222153\n",
      "epoch: 97, batch: 4, loss: 0.13600875437259674\n",
      "epoch: 97, batch: 5, loss: 0.19469290971755981\n",
      "epoch: 97, batch: 6, loss: 0.15215010941028595\n",
      "epoch: 97, batch: 7, loss: 0.10126449912786484\n",
      "epoch: 97, batch: 8, loss: 0.23321832716464996\n",
      "epoch: 97, batch: 9, loss: 0.5391417741775513\n",
      "epoch: 97, batch: 10, loss: 0.10962998867034912\n",
      "epoch: 97, batch: 11, loss: 0.2133246213197708\n",
      "epoch: 97, batch: 12, loss: 0.02398785389959812\n",
      "epoch: 97, batch: 13, loss: 0.09127369523048401\n",
      "epoch: 97, batch: 14, loss: 0.1040201410651207\n",
      "epoch: 97, batch: 15, loss: 0.007091892883181572\n",
      "epoch: 97, batch: 16, loss: 0.03583436459302902\n",
      "epoch: 97, batch: 17, loss: 0.13133424520492554\n",
      "epoch: 97, batch: 18, loss: 0.013470854610204697\n",
      "epoch: 97, batch: 19, loss: 0.044153228402137756\n",
      "epoch: 97, batch: 20, loss: 0.3606194257736206\n",
      "epoch: 97, batch: 21, loss: 0.013055047020316124\n",
      "epoch: 97, batch: 22, loss: 0.06675693392753601\n",
      "epoch: 97, batch: 23, loss: 0.05653233826160431\n",
      "epoch: 97, batch: 24, loss: 0.14141938090324402\n",
      "epoch: 97, batch: 25, loss: 0.007075256202369928\n",
      "epoch: 97, batch: 26, loss: 0.03397553414106369\n",
      "epoch: 97, batch: 27, loss: 0.1352582722902298\n",
      "epoch: 97, batch: 28, loss: 1.7397432327270508\n",
      "epoch: 98, batch: 0, loss: 0.004866572096943855\n",
      "epoch: 98, batch: 1, loss: 0.06171702593564987\n",
      "epoch: 98, batch: 2, loss: 0.04136435687541962\n",
      "epoch: 98, batch: 3, loss: 0.13517513871192932\n",
      "epoch: 98, batch: 4, loss: 0.19123391807079315\n",
      "epoch: 98, batch: 5, loss: 0.2812116742134094\n",
      "epoch: 98, batch: 6, loss: 0.051442451775074005\n",
      "epoch: 98, batch: 7, loss: 0.05870785936713219\n",
      "epoch: 98, batch: 8, loss: 0.029122602194547653\n",
      "epoch: 98, batch: 9, loss: 0.2807137966156006\n",
      "epoch: 98, batch: 10, loss: 0.10497187823057175\n",
      "epoch: 98, batch: 11, loss: 0.07898116856813431\n",
      "epoch: 98, batch: 12, loss: 0.0686115175485611\n",
      "epoch: 98, batch: 13, loss: 0.041428420692682266\n",
      "epoch: 98, batch: 14, loss: 0.06402906030416489\n",
      "epoch: 98, batch: 15, loss: 0.042971450835466385\n",
      "epoch: 98, batch: 16, loss: 0.1932802051305771\n",
      "epoch: 98, batch: 17, loss: 0.03730151429772377\n",
      "epoch: 98, batch: 18, loss: 0.1692279726266861\n",
      "epoch: 98, batch: 19, loss: 0.10216164588928223\n",
      "epoch: 98, batch: 20, loss: 0.07406792789697647\n",
      "epoch: 98, batch: 21, loss: 0.030248889699578285\n",
      "epoch: 98, batch: 22, loss: 0.0755556970834732\n",
      "epoch: 98, batch: 23, loss: 0.12444029748439789\n",
      "epoch: 98, batch: 24, loss: 0.031001949682831764\n",
      "epoch: 98, batch: 25, loss: 0.06505319476127625\n",
      "epoch: 98, batch: 26, loss: 0.03073202259838581\n",
      "epoch: 98, batch: 27, loss: 0.017157336696982384\n",
      "epoch: 98, batch: 28, loss: 0.023963402956724167\n",
      "epoch: 99, batch: 0, loss: 0.017333529889583588\n",
      "epoch: 99, batch: 1, loss: 0.13634945452213287\n",
      "epoch: 99, batch: 2, loss: 0.003041850635781884\n",
      "epoch: 99, batch: 3, loss: 0.015542536042630672\n",
      "epoch: 99, batch: 4, loss: 0.02238323912024498\n",
      "epoch: 99, batch: 5, loss: 0.011900655925273895\n",
      "epoch: 99, batch: 6, loss: 0.013862424530088902\n",
      "epoch: 99, batch: 7, loss: 0.053869739174842834\n",
      "epoch: 99, batch: 8, loss: 0.0031422434840351343\n",
      "epoch: 99, batch: 9, loss: 0.014502517879009247\n",
      "epoch: 99, batch: 10, loss: 0.020378073677420616\n",
      "epoch: 99, batch: 11, loss: 0.02490677870810032\n",
      "epoch: 99, batch: 12, loss: 0.03798958286643028\n",
      "epoch: 99, batch: 13, loss: 0.00436966260895133\n",
      "epoch: 99, batch: 14, loss: 0.10379208624362946\n",
      "epoch: 99, batch: 15, loss: 0.030053311958909035\n",
      "epoch: 99, batch: 16, loss: 0.0022819514852017164\n",
      "epoch: 99, batch: 17, loss: 0.027116689831018448\n",
      "epoch: 99, batch: 18, loss: 0.002854586113244295\n",
      "epoch: 99, batch: 19, loss: 0.010614058002829552\n",
      "epoch: 99, batch: 20, loss: 0.001176736899651587\n",
      "epoch: 99, batch: 21, loss: 0.15812747180461884\n",
      "epoch: 99, batch: 22, loss: 0.002452454064041376\n",
      "epoch: 99, batch: 23, loss: 0.008371408097445965\n",
      "epoch: 99, batch: 24, loss: 0.01721501164138317\n",
      "epoch: 99, batch: 25, loss: 0.004730910528451204\n",
      "epoch: 99, batch: 26, loss: 0.007004896178841591\n",
      "epoch: 99, batch: 27, loss: 0.025249633938074112\n",
      "epoch: 99, batch: 28, loss: 0.0260182972997427\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    model_demo.train()\n",
    "    model_demo.to(device)\n",
    "    for i, (images, labels) in enumerate(MESSIDOR_Centerlized_train_loader):\n",
    "        images = images.to(device,torch.float32)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model_demo(images)\n",
    "        loss_value = loss(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        print('epoch: {}, batch: {}, loss: {}'.format(epoch, i, loss_value.item()))\n",
    "    if epoch % 1 == 0:\n",
    "        torch.save(model_demo.state_dict(), os.path.join(model_save_path, 'model_{}.pth'.format(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6366666666666667\n",
      "f1 score: 0.5353231339862357\n"
     ]
    }
   ],
   "source": [
    "# test model accuracy and f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "model_demo.eval()\n",
    "model_demo.to(device)\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for i, (images, labels) in enumerate(MESSIDOR_Centerlized_test_loader):\n",
    "    images = images.to(device,torch.float32)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model_demo(images)\n",
    "    outputs = torch.argmax(outputs, dim=1)\n",
    "    y_true.append(labels.cpu().numpy())\n",
    "    y_pred.append(outputs.cpu().numpy())\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "print('accuracy: {}'.format(np.mean(y_true == y_pred)))\n",
    "print('f1 score: {}'.format(f1_score(y_true, y_pred, average='macro')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NRDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87bd6fbd7d8ef9673d07d349db42fc09bfd843c87ffc320c73f522404c723ede"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
